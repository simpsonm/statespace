\documentclass{article}

\usepackage{JASA_manu} %formats document like ASA wants
\usepackage{jasa_harvard} %formats citations like ASA wants
\usepackage{amssymb, amsmath, amsthm, graphics, color, fullpage}
%\usepackage[authoryear]{natbib} %numbers instead of authoryear for [1] instead of [1980]

\newtheorem{alg}{Algorithm}
\newtheorem{thm}{Theorem}[subsection]
\newtheorem{prop}[thm]{Proposition}
\newtheorem{cor}[thm]{Corollary}
\newtheorem{lem}[thm]{Lemma}

\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator{\B}{B}
\DeclareMathOperator{\vech}{vech}
\DeclareMathOperator{\vect}{vec}

\graphicspath{{plots/}}
\newcommand{\matt}[1]{{\color{red} Matt: #1}}
\newcommand{\jarad}[1]{{\color{red} Jarad: #1}}


\begin{document}


\title{Ancillarity-Sufficiency or not; Interweaving to Improve Markov Chain Monte Carlo (MCMC) Estimation of the Dynamic Linear Model (DLM)}
\author{Matt Simpson}
\maketitle

\begin{abstract}
In DLMs, MCMC sampling can often be very slow for accurately estimating the posterior density --- especially for longer time series. In particular, in some regions of the parameter space the standard data augmentation algorithm can mix very slowly. Using some of the insights from the data augmentation for multilevel models literature, we explore several alternative data augmentations for a general class of DLMs and we show that no ``practical'' centered parameterization (or sufficient augmentation in the terminology of \citeasnoun{yu2011center}) exists. In addition, we utilize these augmentations to construct several interweaving algorithms --- though we cannot construct an ancillary-sufficient interweaving algorithm (ASIS) since no sufficient augmentation exists, we find two ancillary augmentations and are able to construct a componentwise interweaving algorithm (CIS) that uses ASIS for each model parameter conditional on the rest. Using the local level DLM, we show how to construct several of these algorithms and conduct a simulation study in order to discern their properties. We find that several algorithms that outperform the usual ``state sampler'' for many values of the population parameters, though there is room for improvement.
\end{abstract}


\section{Introduction}\label{sec:Intro}

Ever since the seminal article by \citeasnoun{tanner1987calculation}, data augmentation has become a common strategy for constructing MCMC algorithms to sample from intractable probability distributions. Suppose $p(\phi|y)$ is the target density, in this case the posterior distribution of some parameter $\phi$ given data $y$. We use $p(.)$ to denote the probability density of the enclosed random variables. Then the data augmentation (DA) algorithm adds a data augmentation $\theta$ with joint distribution $p(\phi,\theta|y)$ such that $\int_{\Theta}p(\phi,\theta|y)d\theta = p(\phi|y)$. The DA algorithm is similar to a Gibbs sampler, except it constructs a Markov chain for $\phi$ instead of $(\phi, \theta)$. In the DA algorithm, the $k+1$'st state of $\phi$ is obtained from the $k$'th state as follows (we implicitly condition on the data $y$ in all algorithms and only superscript the previous and new draws of the model parameters of interest):
\begin{alg}Data Augmentation.\label{alg:DA}
  \begin{align*}
  [\theta|\phi^{(k)}] \to [\phi^{(k+1)}|\theta]
\end{align*}
\end{alg} 
\noindent Here $[\theta|\phi^{(k)}]$ means a draw of $\theta$ from $p(\theta|\phi^{(k)},y)$ and $[\phi^{(k+1)}|\theta]$ means a draw from $p(\phi|\theta,y)$. The DA, $\theta$, need not be interesting in any scientific sense --- it can be viewed purely as a computational construct. However for cases where the DA is intrinsically interesting, the DA algorithm does incidentally obtain joint draws from $p(\phi,\theta|y)$ and in that sense can be viewed as a Gibbs sampler. For our purposes, $\theta$ is a nuisance parameter.

The EM algorithm of \citeasnoun{dempster1977maximum} and its variants are closely analogous to DA algorithms --- specifically the DA algorithm can be viewed as a stochastic version of the EM algorithm. In fact there is a long history of using methods typically used to speed up the EM algorithm to speed up DA algorithm and vice versa; \citeasnoun{van2010cross} shows how much overlap in the two literatures exists. The main advantage of DA and EM algorithms is their ease of implementation, but much of this work is necessary because DA and EM algorithms can often be prohibitively slow. One well known method of improving mixing and convergence in MCMC samplers is reparameterizing the model. Most of the work in some way focuses on what are called centered and noncentered parameterizations. For example \citeasnoun{papaspiliopoulos2007general} is a good summary. In our general notation where $\phi$ is the parameter, $\theta$ is the DA and $y$ is the data, the parameterization $(\phi,\theta)$ is a {\it centered parameterization} (CP) if $p(y|\theta,\phi)=p(y|\theta)$. The parameterization is a {\it noncentered parameterization} (NCP) if $p(\theta|\phi)=p(\theta)$. When $(\phi,\theta)$ is a CP, $\theta$ is called a {\it centered augmentation} (CA) for $\phi$ and when $(\phi,\theta)$ is a NCP, $\theta$ is called a {\it noncentered augmentation} (NCA) for $\phi$. A centered augmentation is sometimes called a {\it sufficient augmentation} (SA) and a noncentered augmentation is sometimes called an {\it ancillary augmentation} (AA)\cite{yu2011center}. Like \citeasnoun{yu2011center}, we prefer the latter terminology because it immediately suggests the intuition that a sufficient augmentation is like a sufficient statistic while an ancillary augmentation is like an ancillary statistic and hence Basu's theorem suggests that they are conditionally independent given $\phi$. 

The key reasoning behind the emphasis on SAs and AAs is that typically when the DA algorithm based on the SA has nice mixing and convergence properties the DA algorithm based on the AA has poor mixing and convergence properties and vice-versa. This property suggests that there might be a way to combine the two DA algorithms or the two underlying parameterizations in order to construct an improved sampler. Some work focuses on using partially noncentered parameterizations that are a sort of bridge between the CP and NCP, e.g. \citeasnoun{papaspiliopoulos2007general} for general hierarchical models and \citeasnoun{fruhwirth2004efficient} in the context of a particular DLM --- a dynamic univariate regression with a stationary AR(1) coefficient. Another suggestion by \citeasnoun{papaspiliopoulos2007general} is to alternate between the two augmentations within a Gibbs sampler. Suppose we have a second distinct DA $\gamma$ such that $\int_\Gamma p(\phi,\gamma|y)d\gamma = p(\phi|y)$. Then the {\it alternating} algorithm for sampling from $p(\phi|y)$ is as follows:
\begin{alg}Alternating.\label{alg:Alt} \\
  \begin{center}
    \begin{tabular}{lllllll}
  $[\theta|\phi^{(k)}]$& $\to$& $[\phi|\theta]$& $\to$& $[\gamma|\phi]$& $\to$& $[\phi^{(k+1)}|\gamma]$
    \end{tabular}
  \end{center}
\end{alg}
\noindent One iteration of the alternating algorithm consists of one iteration of the DA algorithm based on $\theta$ to obtain an intermediate value of $\phi$, followed by one iteration of the DA algorithm based on $\gamma$ started at the intermediate value of $\phi$. 

Recall that a typical problem with slow MCMC is that there is high autocorrelation in the Markov chain for $\phi$, $\{\phi^{(k)}\}_{k=1}^K$, leading to imprecise estimates of $\mathrm{E}[f(\phi)|y]$ for some function $f$ integrable with respect to the posterior of $\phi$. Our goal is to reduce this dependence. In the usual DA algorithm (Algorithm \ref{alg:DA}) when $\phi$ and $\theta$ are highly dependent in the joint posterior the draws from $p(\theta|\phi,y)$ and then from $p(\phi|\theta,y)$ will hardly move the chain which results in high autocorrelation. In an alternating algorithm, there are essentially two chances to substantially move the chain -- one for $\theta$ in the draws from $p(\theta|\phi,y)$ and from $p(\phi|\theta,y)$ and one for $\gamma$ in the draws from $p(\gamma|\phi,y)$ and from $p(\phi|\gamma,y)$.  In particular, when $\theta$ is an SA and $\gamma$ is an AA or vice versa, then it is often the case that there is low dependence either between $\phi$ and $\theta$ or between $\phi$ and $\gamma$. As a result, either steps 1 and 2 or steps 3 and 4 will substantially move the chain in the alternating algorithm, which limits how poorly the algorithm can perform.

One recent advance that is similar to an alternating strategy is the notion of {\it interweaving} the two DAs together \cite{yu2011center}. Suppose that given $(\phi,\theta,\gamma,y)$ we further require that they have a full joint but possibly singular distribution and that the conditional distribution $\mu_y$ of $(\phi,\theta,\gamma|y)$ is defined almost everywhere such that for any measurable $A\in \Phi$, $\int_{\Theta \times \Gamma \times A}d\mu_y = \int_Ap(\phi|y)d\phi$. Then a general interweaving strategy (GIS) is an MCMC algorithm that obtains $\phi^{(k+1)}$ from $\phi^{(k)}$ as follows:
\begin{alg}GIS.\label{alg:GIS}
  \begin{align*}
    [\theta|\phi^{(k)}] \to [\gamma|\theta] \to [\phi^{(k+1)}|\gamma].
  \end{align*}
\end{alg}
\noindent The GIS algorithm obtains the $k+1$st iteration of the parameter vector $\phi$ from the $k$th iteration in three steps. First, it draws the DA $\theta$ conditional on $\phi^{(k)}$ (and the data). Next, it draws the DA $\gamma$ conditional on $\theta$. Finally, it draws $\phi^{(k+1)}$ conditional on $\gamma$. This looks similar to the usual DA algorithm, except a second DA is ``weaved'' in between the draw of the first DA and of the parameter vector. Step two of the GIS algorithm is typically accomplished by sampling $\phi|\theta,y$ and then $\gamma|\theta,\phi,y$. In addition, $\gamma$ and $\theta$ are often, but not always, one-to-one transformations of each other conditional on $(\phi,y)$, i.e. $\gamma = M(\theta;\phi,y)$ where $M(.;\phi,y)$ is a one-to-one function. This is the source of the potential singularity in $\mu_y$. If we expand out step two, then the algorithm becomes:
\begin{alg}GIS expanded.\label{alg:GIS2}\\
  \begin{center}
    \begin{tabular}{lllllll}
      $[\theta|\phi^{(k)}]$& $\to$& $[\phi|\theta]$& $\to $&$[\gamma|\theta,\phi]$& $\to$& $[\phi^{(k+1)}|\gamma]$
    \end{tabular}
  \end{center}
\noindent \end{alg}
When $\gamma$ is a one-to-one transformation of $\theta$, step three is an update $\gamma=M(\theta;\phi,y)$. The key difference between GIS and the correpsonding alternating algorithm (Algorithm \ref{alg:Alt}) can be seen in step three of Algorithm \ref{alg:GIS2}: instead of drawing from $p(\gamma|\phi,y)$, the GIS algorithm draws from $p(\gamma|\theta,\phi,y)$, ``weaving'' the two DAs together, while the alternating algorithm keeps them separate.

\citeasnoun{yu2011center} call a GIS approach where one of the DAs is an SA and the other is an AA an {\it ancillary sufficient interweaving strategy}, or an ASIS. They show that the GIS algorithm has a geometric rate of convergence no worse than the worst of the two underlying DA algorithms and in some cases better than the the corresponding alternating algorithm. In particular, their Theorem 1 suggests that the weaker the dependence between two data augumentations in the posterior, the more efficient the GIS algorithm. With a posteriori independent data augmentations, the GIS algorithm will even obtain iid draws from the posterior density of the model parameter. This helps motivate their focus on ASIS --- conditional on the model parameter, an SA and an AA are independent under the conditions of Basu's theorem \cite{basu1955statistics}, which suggests that the dependence between the two DAs will be limited in the posterior. In fact, when the prior on $\phi$ is nice in some sense, \citeasnoun{yu2011center} show that the ASIS algorithm is the same as the optimal parameter expanded data augmentation (PX-DA) algorithm of \citeasnoun{liu1999parameter}, which is closely related to certain reparameterization techniques  \cite{hobert2008theoretical}. Their results suggest that ASIS and interweaving generally is a promising approach to improve the speed of MCMC in a variety of models no matter what region of the parameter space the posterior is concentrated. 

To gain some intuition about why interweaving works, we can first make a direct comparison to the alternating algorithm through the expanded version of the GIS algorithm (Algorithm \ref{alg:GIS2}). Like the alternating algorithm, there are two opportunities for the Markov chain to move in the GIS algorithm, one each for $\theta$ and $\gamma$. So when the two underlying DA algorithms perform poorly in opposite regions of the parameter space, like the alternating algorithm, either steps 1 and 2 or steps 3 and 4 will substantially move the chain, limiting how poor the GIS algorithm can perform. In addition, \citeasnoun{yu2011center} show that the GIS algorithm is often much more efficient than the alternating algorithm. The key is that when the posterior dependence between the two DAs is low, step 2 in Algorithm \ref{alg:GIS} (i.e. steps 2 and 3 in Algorithm \ref{alg:GIS2}) is enough to almost completely break the dependence in the chain. For the alternating algorithm, it is typically not feasible to find a data augmentation such that step 2 or step 3 of Algorithm \ref{alg:Alt} completely breaks the dependence in the chain --- this would require finding a DA such that the model parameter and the DA are essentially independent which, in turn, would likely mean that drawing from the conditional posterior of the parameter given the DA is nearly as difficult as drawing from the marginal posterior of the model parameter.

The particular method of interweaving discussed above is called a GIS or a {\it global} interweaving strategy since interweaving occurs globally across the entire parameter vector. It is possible to define a {\it componentwise} interweaving strategy (CIS) that interweaves within specific steps of a Gibbs sampler as well. A CIS algorithm for $\phi=(\phi_1, \phi_2)$ essentially employs interweaving for each block of $\phi$ separately, e.g.
\begin{alg}CIS.\label{alg:CIS}\\
  \begin{center}
    \begin{tabular}{llllll}
      $[\theta_1|\phi_1^{(k)},\phi_2^{(k)}]$ & $\to$  & $[\gamma_1|\phi_2^{(k)},\theta_1]$ & $\to$ & $[\phi_1^{(k+1)}|\phi_2^{(k)},\gamma_1]$ &$\to$ \\
      $[\theta_2|\phi_1^{(k+1)},\phi_2^{(k)},\gamma_1]$ &$\to$ & $[\gamma_2|\phi_1^{(k+1)},\theta_2]$ & $\to$ & $[\phi_2^{(k+1)}|\phi_1^{(k+1)},\gamma_2]$ &
    \end{tabular}
  \end{center}
\noindent \end{alg}
where $\theta_i$ and $\gamma_i$ are distinct data augmentations for $i=1$ and $i=2$, but potentially $\gamma_1=\theta_2$  or $\gamma_2=\theta_1$. The first line draws $\phi_1$ conditional on $\phi_2$ using interweaving in a Gibbs step, while the second line does the same for $\phi_2$ conditional on $\phi_1$. The algorithm can easily be extended to greater than two blocks within $\phi$. The main attraction of CIS is that it is often easier to find an AA--SA pair of DAs for $\phi_1$ conditional on $\phi_2$ and another pair for $\phi_2$ conditional on $\phi_1$ than it is to find and AA--SA pair for $\phi=(\phi_1,\phi_2)$ jointly. 

Most of the work on constructing and using DAs has focused on multilevel models --- e.g. \citeasnoun{van2001art} and \citeasnoun{papaspiliopoulos2007general}, but relatively little attention has been paid to time series models despite strong similarities between some time series models and the hierarchical models typically studied. We seek to improve DA schemes in a particular class of models --- linear, Gaussian statespace models, a.k.a. dynamic linear models (DLMs). Most of the existing literature focuses on non-Gaussian statespace models --- in particular the stochastic volatility model (see \citeasnoun{shephard1996statistical} for a summary), but few directly work with the class of DLMs we consider. In \citeasnoun{pitt1999analytic}, the authors analytically study convergence in the AR(1) plus noise model, but assume the observation and system variances are constant throughout. \citeasnoun{strickland2008parameterisation} considers reparameterization of the stochastic volatility and stochastic conditional duration models. \citeasnoun{fruhwirth2008heston} also considers reparameterizations of the stochastic volatility model while \citeasnoun{kastner2013ancillarity} applies ASIS in order to estimate the model. \citeasnoun{bos2006inference} consider a class of DLMs where the variances are time-dependent and follow a stochastic volatility process and show how a reparameterization can improve MCMC estimation. In the non-Gaussian Ornstein--Uhlenbeck stochastic volatility process, \citeasnoun{roberts2004bayesian} explores several alternate parameterizations. \citeasnoun{fruhwirth2003bayesian} directly applies several reparameterization techniques to a particular DLM -- a dynamic regression model with stationary AR(1) regression coefficient-- but focuses on estimation of the regression coefficient process.

The rest of the paper is organized as follows. In Section \ref{sec:DLMs} we introduce the dynamic linear model, discuss the subclass of DLMs we consider, and explore some of the key properties of the model. Section \ref{sec:DAs} explores several possible DAs for our class of DLMs, including several new DAs, and shows that any SA for the DLM is likely to be difficult to use. Section \ref{sec:Algs} discusses the various MCMC strategies available for the DLM, including several DA algorithms, alternating algorithms, and interweaving algorithms. Section \ref{sec:LLM} applies these algorithms to a particular DLM --- the local level model --- and discusses some interesting problems which arise during the construction of these algorithms before using a simulation to empirically examine how well various algorithms perform across different regions of the parameter space. Finally, Section \ref{sec:Discuss} discusses these results and what they might mean for more general DLMs.

\section{Dynamic linear models} \label{sec:DLMs} 

The general dynamic linear model is well studied \cite{harrison1999bayesian,petris2009dynamic,prado2010time} and is defined as
\begin{align}
y_t &= F_t\theta_t + v_t && v_t \stackrel{ind}{\sim} N_k(0,V_t) && (\mbox{observation equation}) \label{dlmtdobseq}\\
 \theta_t &= G_t\theta_{t-1} + w_t && w_t \stackrel{ind}{\sim} N_p(0,W_t) && (\mbox{system equation}) \label{dlmtdsyseq}
\end{align}
where $N_d(\mu,\Sigma)$ is a $d$-dimensional multivariate normal distribution with mean $\mu$ and covariance $\Sigma$ and the observation errors, $v_{1:T}$, and system disturbances, $w_{1:T}$, are assumed independent. The observed data is $y_{1:T} = (y_1',y_2,\cdots y_T')'$ while $\theta_{0:T}=(\theta_0',\theta_1',\theta_2',\cdots \theta_T')'$ is called the latent states and is the usual DA for this model. However, we will treat $\theta_0$ as a model parameter and $\theta_{1:T}$ as the DA. For each $t=1,2,\cdots,T$, $F_t$ is a $k\times p$ matrix and $G_t$ is a $p\times p$ matrix. Let $\phi$ denote the vector of unknown parameters in the model. Then possibly $F_{t}$, $G_{t}$, $V_{t}$, and $W_{t}$ are all functions of $\phi$ for $t=1,2,\cdots,T$. 

The subclass of DLMs we will focus on sets $V_t=V$ and $W_t=W$ and treats $F_{t}$ and $G_{t}$ as known for all $t$. Our results can be extended when $V_t$ or $W_t$ is time-varying or when $F_t$ or $G_t$ depend on unknown parameters, but we ignore those cases for simplicity. When $\phi=(\theta_0,V,W)$ is our unknown parameter vector and we can write the model as
\begin{align}
  y_t|\theta_{0:T},V,W \stackrel{ind}{\sim} & N(F_t\theta_t,V) &
  \theta_t|\theta_{0:t-1},V,W  \sim & N(G_t\theta_{t-1},W) \label{dlmbotheqs}
\end{align}
for $t=1,2,\cdots T$. To complete the model specification in a Bayesian context, we need priors on $\theta_0$, $V$, and $W$. We will use the standard conditionally conjugate approach and assume that they are mutually independent a priori and that $\theta_0 \sim N(m_0, C_0)$, $V \sim IW(\Lambda_V, \lambda_V)$ and $W \sim IW(\Lambda_W, \lambda_W)$ where $m_0$, $C_0$, $\Lambda_V$, $\lambda_V$, $\Lambda_W$, and $\lambda_W$ are known hyperparameters and $IW(\Lambda, \lambda)$ denotes the inverse Wishart distribution with degrees of freedom $\lambda$ and positive definite scale matrix $\Lambda$. Then we can write the full joint distribution of $(V,W,\theta_{0:T},y_{1:T})$ is
\begin{align}
  p(&V,W,\theta_{0:T},y_{1:T}) \propto \exp\left[-\frac{1}{2}(\theta_0-m_0)'C_0^{-1}(\theta_0-m_0)\right] \nonumber\\
  &\times   |V|^{-(\lambda_V + k + T + 2)/2}\exp\left[-\frac{1}{2}\tr\left(\Lambda_VV^{-1}\right)\right] \exp\left[-\frac{1}{2}\sum_{t=1}^T(y_t - F_t\theta_t)'V^{-1}(y_t - F_t\theta_t)\right] \nonumber\\
   & \times |W|^{-(\lambda_W + p + T + 2)/2}\exp\left[-\frac{1}{2}\tr\left(\Lambda_WW^{-1}\right)\right]\exp\left[-\frac{1}{2}\sum_{t=1}^T(\theta_t-G_t\theta_{t-1})'W^{-1}(\theta_t-G_t\theta_{t-1})\right]\label{dlmjoint}
 \end{align}
where $\tr(.)$ is the matrix trace operator.

From equation \eqref{dlmbotheqs} we can rewrite the model by recursive substitution:
\begin{align*}
  y_t &= v_t + F_t\left(w_t + G_tw_{t-1} + G_tG_{t-1}w_{t-2} + ... + G_tG_{t-1}\cdots G_{2}w_1 + G_tG_{t-1}\cdots G_1\theta_0\right).
\end{align*}
Here we see that $\theta_0$ is given a special status relative to the other elements of the data augmentation which helps motivate treating it as a model parameter rather than part of the DA. Now each $y_t$ is a linear combination of normal random variables conditional on $\phi=(\theta_0,V,W)$, so after marginalizing out $\theta_{1:T}$, $y_{1:T}$ has a normal distribution such that
\begin{align*}
  \mathrm{E}[y_t|\phi] =  F_t\left[\prod_{s=t}^1G_s\right]\theta_0,\qquad
  \mathrm{Var}[y_t|\phi] =  V + F_tH_tWH_t'F_t',\qquad
  \mathrm{Cov}[y_s,y_t|\phi] = F_sH_sWH_t'F_t'
\end{align*}
where $\prod_{s=t}^1G_s = G_tG_{t-1}\cdots G_1$ and $H_t = I_p + G_t + G_tG_{t-1} + \cdots + G_tG_{t-1}\cdots G_2$. Next define $D_t = F_tG_tG_{t-1}\cdots G_1$. Then let
\begin{align*}
D_{Tp\times Tk} &= \begin{bmatrix} 
D_1 & 0 & \ddots & 0\\
0 & D_2 & \ddots & 0\\
\ddots & \ddots & \ddots & \ddots\\
0 & 0 & \ddots & D_T 
\end{bmatrix}, &
\tilde{V}_{Tk\times Tk} & = \begin{bmatrix} 
V & 0 & \ddots & 0\\
0 & V & \ddots & 0\\
\ddots & \ddots & \ddots & \ddots\\
0 & 0 & \ddots & V 
\end{bmatrix},
\intertext{ }
\mu_{Tp\times 1} &= \begin{bmatrix} \theta_0 \\ \theta_0 \\ \vdots \\ \theta_0\end{bmatrix}, & \tilde{W}_{Tp\times Tp} &= \begin{bmatrix} F_1H_1 \\ F_2H_2 \\ \vdots \\ F_TH_T \end{bmatrix} W \begin{bmatrix} H_1'F_1' & H_2'F_2' & \hdots H_T'F_T' \end{bmatrix}.
\end{align*} 
Now we have the data model for $y_{1:T}$ without any data augmentation:
\begin{align}
  y_{1:T} \stackrel{ind}{\sim} N_{k}(D\mu, \tilde{V} + \tilde{W}) \label{margmodel}
\end{align}
for $t=1,2,\cdots,T$. Given a prior $p(\phi)$, the posterior density we are interested in is $p(\phi|y_{1:T})\propto p(y_{1:T}|\phi)p(\phi)$.

Equation \eqref{dlmbotheqs} motivates a strong analogy with a commonly studied hierarchical model:
\begin{align*}
  y_{ij}|\beta_{1:J} \stackrel{ind}{\sim} & N(X_{ij}\beta_j,V) &
  \beta_j \stackrel{ind}{\sim} & N(Z_j\lambda,W)
\end{align*}
for $i=1,2,\cdots,I_j$ and $j=1,2,\cdots,J$. Here, $ij$ indicates observation $i$ within group $j$. The response vector $y_{ij}$ is related to the matrix of covariates $X_{ij}$ through the group-specific regression coefficient $\beta_j$ while the group specific regression coefficient is related to the group-level matrix of covariates $Z_j$ through the group level regression coefficient $\lambda$. There are three key differences between this model and the class of DLMs we consider. First, in the DLM $I_j=1$ for $j=1,2,\cdots J$ so that each observation comes from its own group. Second, the $y_{1j}$'s are no longer exchangeable and instead exhibit a temporal ordering. Finally, the $\beta_j$'s are given a special kind of dependence by forcing the mean of the distribution of $\beta_j$ to depend on $\beta_{j-1}$ instead of $\lambda$, where we define $\beta_0=\lambda$. This combined with equation \eqref{margmodel} helps motiviate our decision to treat $\theta_0$ as a model parameter rather than part of the DA --- it is analogous to the top level mean parameter in a hierarchical regression model and in addition $\theta_0$ requires its own prior distribution rather than having an implicit prior in the construction of the model, like $\theta_{1:T}$ in the DLM or $\beta_{1:J}$ is the hierarchical model.

\section{Augmenting the DLM}\label{sec:DAs}
The latent states $\theta_{1:T}$ defined in the definition of the DLM form the usual DA for use in DA algorithms to estimate the model. The only restriction on any given DA is that the joint posterior of the model parameter and the DA is such that if we integrate out the DA, we obtain the desired marginal posterior for the parameter. This leaves wide range of possibilities for alternate DAs to use the the MCMC sampling algorithm, as long as the resulting full conditional distributions of the DA and the model parameter are both easy to sample from. We will explore several alternatives found through manipulating $\theta_{0:T}$ in intuitive ways. The purpose of these constructions is primarily to use as grist for the interweaving mill, but each new DA will also implicitly define a new base DA algorithm.

\subsection{The scaled disturbances} 

The next step is to apply the ideas of interweaving to sampling from the posterior of the dynamic linear model. \citeasnoun{papaspiliopoulos2007general} note that typically the usual parameterization results in an SA for the parameter $\phi$. All that would be necessary for an ASIS algorithm, then, is to construct an AA for $\phi$. We immediately run into a problem because the standard DA for a DLM is the latent states $\theta_{0:T}$. From equation \eqref{dlmbotheqs} and \eqref{dlmbotheqs} we see that $V$ is in the observation equation so that $\theta_{0:T}$ is not an SA for $(V,W)$ while $W$ is in the system equation so that $\theta_{0:T}$ is not an AA for $(V,W)$ either. In order to find an SA we need to somehow move $V$ from the observation equation to the system equation while leaving $W$ in the system equation. We also need to find an AA by somehow moving $W$ from the system equation to the observation equation while leaving $V$ in the observation equation. A naive thing to try is to condition on the disturbances instead of the states and see if the disturbances for an SA or an AA for $(V,W)$. The disturbances $w_{0:T}$ are defined by $w_t = \theta_t - G_t\theta_{t-1}$ for $t=1,,2,\cdots,T$ and and $w_0=\theta_0$. However it is easy to see that the conditional distributions $p(V,W|\theta_{0:T},y_{1:T})$ and $p(V,W|w_{0:T},y_{1:T})$ are identical (we omit these details) so the DA algorithm based on the $w_t$'s is identical to the algorithm based on the $\theta_t$'s.

\citeasnoun{papaspiliopoulos2007general} suggest that in order to obtain an ancillary augmentation for a variance parameter, we must center the sufficient augmentation and scale it  by the square root of that parameter. Based on this intuition, note that if we hold $V$ constant then $\theta_{0:T}$ is an SA for $W$ from equation \eqref{dlmbotheqs}, i.e. we say $\theta_{0:T}$ is an SA for $W$ given $V$, or for $W|V$. Similarly $\theta_{0:T}$ is an AA for $V|W$. This suggests that if we center and scale $\theta_{t}$ by $W$ appropriately for all $t$ we'll have an ancillary augmentation for $V$ and $W$ jointly. In fact this follows \citeasnoun{papaspiliopoulos2007general}'s suggestion to construct a pivotal quantity in order to find an ancillary augmentation. The upshot is that we need to appropriately scale the disturbances, $w_t = \theta_t - G_t\theta_{t-1}$, to create the scaled disturbances (SDs).

In the general DLM, the disturbances are vectors so to define the scaled disturbances let $L_W$ denote the Cholesky decomposition of $W$, i.e. the lower triangle matrix $L_W$ such that $L_WL_W' =W$. Then we will define the scaled disturbances $\gamma_{0:T}$ by $\gamma_0=\theta_0$ and $\gamma_t = L_W^{-1}(\theta_t-G_t\theta_{t-1})$ for $t=1,2,\cdots,T$. There are actually $p!$ different versions of the scaled disturbances depending on how we order the elements of $\theta_t$, as \citeasnoun{meng1998fast} note for EM algorithms in a different class of models. We will sidestep the issue of the best ordering of the latent states. No matter which ordering is chosen, we can confirm our intuition that the scaled disturbances are an AA for $V$ and $W$ jointly. The reverse transformation is defined recursively by $\theta_0=\gamma_0$ and $\theta_t=L_W\gamma_t + G_t\theta_{t-1}$ for $t=1,2,\cdots,T$. Then the Jacobian is block lower triangular with the identity matrix and $T$ copies of $L_W$ along the diagonal blocks, so $|J| = |L_W|^T=|W|^{T/2}$. Then from equation \eqref{dlmjoint} we can write the full joint distribution of $(V,W,\gamma_{0:T},y_{1:T})$ as
 \begin{align}
  p(&V,W,\gamma_{0:T},y_{1:T}) \propto \exp\left[-\frac{1}{2}(\gamma_0-m_0)'C_0^{-1}(\gamma_0-m_0)\right] \exp\left[-\frac{1}{2}\gamma_t'\gamma_t\right] \nonumber\\
  &\times |W|^{-(\lambda_W + p + T + 2)/2} |V|^{-(\lambda_V + k + T + 2)/2} \exp\left[-\frac{1}{2}tr\left(\Lambda_WW^{-1}\right)\right]  \nonumber\\
  &\times \exp\left[-\frac{1}{2}\left(tr\left(\Lambda_VV^{-1}\right) + \sum_{t=1}^T\left[y_t-F_t\theta_t(\gamma_{0:T},W)\right]'V^{-1}\left[y_t-F_t\theta_t(\gamma_{0:T},W)\right]\right)\right] \label{dlmdistjoint}
 \end{align}
where $\theta_t(\gamma_{0:T},W)$ denotes the recursive back transformation defined by the scaled disturbances. So ultimately under the scaled disturbance parameterization we can write the model as
\begin{align}
  y_t|\gamma_{0:T},V,W & \stackrel{ind}{\sim} N\left(F_t\theta_t(\gamma_{0:T},W), V\right)\nonumber\\
  \gamma_t & \stackrel{iid}{\sim}N(0,I_p) \label{dlmdistmodel}
\end{align}
for $t=1,2,\cdots,T$ where $I_p$ is the $p\times p$ identity matrix. Neither $V$ nor $W$ are in the system equation so the scaled disturbances are an AA for $(V,W)$. This parameterization is well known, e.g. \citeasnoun{fruhwirth2004efficient} use it in a dynamic regression model with stationary regression coefficient and the disturbance smoother of \citeasnoun{koopman1993disturbance} finds the conditional posterior of the scaled disturbances given the model parameters and the data. 

\subsection{The scaled errors}\label{sec:scalederrors}
The scaled disturbances immediately suggest an analogous augmentation using the scaled errors (SEs), i.e. $v_t=y_t - F_t\theta_t$ appropriately scaled by observation level covariance matrix $V$. Let $L_V$ denote the Cholesky decomposition of $V$, that is $L_VL_V'=V$, then we can define a version of the scaled errors (this time depending on how we order the elements of the vector $y_t$) as $\psi_t = L_V^{-1}(y_t - F_t\theta_t)$ for $t=1,2,\cdots,T$ and $\psi_0 = \theta_0$. 

It is not straightforward to write down the model in terms of $\psi_{0:T}$ instead of $\theta_{0:T}$ and determine $p(\psi_{0:T}|V,W)$. When $dim(y_t)=k=p=dim(\theta_t)$, $F_t$ is $p\times p$ and is invertible for $t=1,2,\cdots,T$, $\psi_{0:T}$ is a one-to-one transformation of $\theta_{0:T}$ and the problem is easier. This restriction is not necessary --- $\theta_t$, $y_t$ or both could be augmented in order to construct an $\tilde{F}_t$ which is square and invertible using a more complicated data augmentation scheme, but we pass over this issue until the discussion section (Section \ref{sec:Discuss}) and assume that $F_t$ is $k\times k$ and invertible from now on. Given this assumption, $\theta_t = F_t^{-1}(y_t - L_V\psi_t)$ for $t=1,2,\cdots,T$ while $\theta_0=\psi_0$. The Jacobian of this transformation is block diagonal with a single copy of the identity matrix and the $F_t^{-1}L_V$'s along the diagonal, so $|J|=(\prod_{t=1}^T|F_t|^{-1})|V|^{T/2}$. Then from equation \eqref{dlmjoint} we can write the joint distribution of $(V, W, \psi_{0:T}, y_{1:T})$ as
\begin{align}
    p(&V,W,\psi_{0:T},y_{1:T}) \propto \exp\left[-\frac{1}{2}(\psi_0-m_0)'C_0^{-1}(\psi_0-m_0)\right] \exp\left[-\frac{1}{2}\sum_{t=1}^T\psi_t'\psi_t\right] \nonumber\\
  &\times |V|^{-(\lambda_V + p + 2)/2}\exp\left[-\frac{1}{2}tr\left(\Lambda_VV^{-1}\right)\right]  \times |W|^{-(\lambda_W + p + T + 2)/2} \nonumber\\
   & \exp\left[-\frac{1}{2}\left(tr\left(\Lambda_WW^{-1}\right) + (y_t - \mu_t)'(F_tWF_t')^{-1}(y_t-\mu_t)\right)\right]\label{dlmerrorjoint}
\end{align}
where we define $\mu_1 = L_V\psi_1 + F_1G_1\psi_0$ and for $t=2,3,\cdots,T$, $\mu_t =L_V\psi_t + F_tG_tF_{t-1}^{-1}(y_{t-1} - L_{V}\psi_{t-1})$. The $|F_t|^{-1}$'s have been absorbed into the normalizing constant, but if the $F_t$'s depended on some unknown parameter then we could not do this and as a result would have to take them into account in the Gibbs step for that parameter. Now we can write the model in terms of the scaled error parameterization:
\begin{align*}
  y_t|V,W,\psi_{0:T},y_{1:t-1} &\sim N(\mu_t, F_tWF_t')\\
  \psi_t & \stackrel{iid}{\sim} N(0,I_k)
\end{align*}
for $t=1,2,\cdots,T$ where $I_k$ is the $k\times k$ identity matrix. Now we see immediately that the scaled errors are also an AA for $(V,W)$ since neither $V$ nor $W$ are in the system equation of this model. However, both $V$ and $W$ are in the observation equation so that $\psi_{0:T}$ is not an SA for $(V,W)$ or for either covariance matrix conditional on the other.

\subsection{The ``wrongly-scaled'' DAs}
We can, however, find a couple more useful DAs to use as grist for the interweaving mill. The scaled disturbances are defined by $\gamma_t = L_W^{-1}(\theta_t - G_t\theta_{t-1})$  and the scaled errors are defined by $\psi_t = L_V^{-1}(y_t - \theta_t)$ for $t=1,2,\cdots,T$ where $L_WL_W' = W$ and $L_VL_V' = V$. Now define $\tilde{\gamma}_t=L_V^{-1}(\theta_t - G_t\theta_{t-1})$ and $\tilde{\psi}_t=L_W^{-1}(y_t - \theta_t)$ for $t=1,2,\cdots,T$ and $\tilde{\psi}_0=\tilde{\gamma}_0=\theta_0$. In other words, the ``tilde'' versions of the scaled disturbances and the scaled errors are scaled by the ``wrong'' Cholesky decomposition, hence we call them the wrongly-scaled disturbances (W-SDs) and the wrongly-scaled errors (W-SEs) respectively. 

First consider the wrongly-scaled disturbances, i.e. $\tilde{\gamma}_t = L_V^{-1}L_W\gamma_t= L_V^{-1}(\theta_t-G_t\theta_{t-1})$ for $t=1,2,\cdots,T$ and $\tilde{\gamma_0}=\gamma_0=\theta_0$. The reverse transformation is $\gamma_t = L_W^{-1}L_V\tilde{\gamma}_t$ and the Jacobian is block diagonal with $L_W^{-1}L_V$ along the diagonal. Thus $|J|=|L_W|^{-T}|L_V|^T=|W|^{-T/2}|V|^{T/2}$. Then from equation \eqref{dlmdistjoint} we can write the joint distribution of $(V,W,\tilde{\gamma}_{0:T},y_{1:T})$ as
 \begin{align}
  p(&V,W,\tilde{\gamma}_{0:T},y_{1:T}) \propto \exp\left[-\frac{1}{2}(\tilde{\gamma}_0-m_0)'C_0^{-1}(\tilde{\gamma}_0-m_0)\right] |V|^{-(\lambda_V + p + 2)/2}\exp\left[-\frac{1}{2}tr\left(\Lambda_VV^{-1}\right)\right]  \nonumber\\
  &\times  \exp\left[-\frac{1}{2}\sum_{t=1}^T\left(y_t - F_t\theta_t(\tilde{\gamma}_{0:T},L_V)\right)'V^{-1}\left(y_t - F_t\theta_t(\tilde{\gamma}_{0:T},L_V)\right)\right]\nonumber\\
   & \times |W|^{-(\lambda_W + p + T + 2)/2}\exp\left[-\frac{1}{2}tr\left(\Lambda_WW^{-1}\right)\right] \exp\left[-\frac{1}{2}\sum_{t=1}^T\tilde{\gamma}_t'(L_V^{-1}W(L_V^{-1})')^{-1}\tilde{\gamma}_t\right]\label{dlmdisttildejoint}
 \end{align}
where $\theta_t(\tilde{\gamma}_{0:T},L_V)$ denotes the transformation from $\tilde{\gamma}_{0:T}$ to $\theta_{0:T}$ defined by the wrongly-scaled disturbances. Then under $\tilde{\gamma}_{0:T}$ we can write the model as
\begin{align*}
  y_t|\tilde{\gamma}_{0:T},V,W & \stackrel{ind}{\sim} N\left(F_t\theta_t(\tilde{\gamma}_{0:T},L_V), V\right)\\
  \tilde{\gamma}_t & \stackrel{ind}{\sim}N(0,L_V^{-1}W(L_V^{-1})')
\end{align*}
for $t=1,2,\cdots,T$. Since $L_V$ is the Cholesky decomposition of $V$, the observation equation does not contain $W$. So $\tilde{\gamma}_{0:T}$ is an SA for $W|V$. Note also that since $W$ and $L_V$ are both in the system equation, $\tilde{\gamma}_{0:T}$ is not an AA for $V|W$ nor for $W|V$. 

Now consider the wrongly-scaled errors, i.e. $\tilde{\psi}_t=L_W^{-1}L_V\psi_t=L_W^{-1}(y_t - \theta_t)$ for $t=1,2,\cdots,T$ and $\tilde{\psi}_0=\psi_0=\theta_0$. Then $\psi_t = L_V^{-1}L_W\tilde{\psi}_t$ and the Jacobian is block diagonal with $L_V^{-1}L_W$ along the diagonal. So $|J|=|V|^{-T/2}|W|^{T/2}$ and from equation \eqref{dlmerrorjoint} we can write the joint distribution of $(V, W, \tilde{\psi}_{0:T}, y_{1:T})$ as
\begin{align}
    p(&V,W,\tilde{\psi}_{0:T},y_{1:T}) \propto \exp\left[-\frac{1}{2}(\tilde{\psi}_0-m_0)'C_0^{-1}(\tilde{\psi}_0-m_0)\right] \nonumber\\
   &\times |V|^{-(\lambda_V + p + T + 2)/2}\exp\left[-\frac{1}{2}tr\left(\Lambda_VV^{-1}\right)\right] \exp\left[-\frac{1}{2}\sum_{t=1}^T\tilde{\psi}_t'(L_W^{-1}V(L_W^{-1})')^{-1}\tilde{\psi}_t\right] \nonumber\\
    & \times |W|^{-(\lambda_W + p + 2)/2}\exp\left[-\frac{1}{2}tr\left(\Lambda_WW^{-1}\right)\right]\exp\left[-\frac{1}{2}\sum_{t=1}^T(y_t - \tilde{\mu}_t)'(F_tWF_t')^{-1}(y_t-\tilde{\mu}_t)\right]\label{dlmerrortildejoint}
 \end{align}
where we define $\tilde{\mu}_1 = L_W\tilde{\psi}_1 - F_1G_1\tilde{\psi_0}$ and for $t=2,3,\cdots,T$ $\tilde{\mu}_t =L_W\tilde{\psi}_t - F_tG_tF_{t-1}^{-1}(y_{t-1} - L_{W}\tilde{\psi}_{t-1})$ In terms of $\tilde{\psi}_{0:T}$, the model is then:
 \begin{align*}
   y_t|V,W,\tilde{\psi}_{0:T},y_{1:t-1} &\sim N(\tilde{\mu}_t, F_tWF_t')\\
   \tilde{\psi}_t & \stackrel{iid}{\sim} N(0,L_W^{-1}V(L_W^{-1})')
\end{align*}
for $t=1,2,\cdots,T$. Since $\tilde{\mu}_t$ only depends on $W$ (through $L_W$) and not on $V$, $V$ is absent from the observation equation. Thus $\tilde{\psi}_{0:T}$ is an SA for $V|W$. Once again, since both $W$ and $V$ are in the system equation $\tilde{\psi}_{0:T}$ is not an AA for either $V$ or $W$.

\subsection{The elusive search for a sufficient augmentation}

Having found two ancillary augmentations for the DLM, we would like to find a sufficient augmentation in order to construct an ASIS for sampling from the posterior distribution. It turns out that this is no easy task. The following lemma clarifies just where the difficulty lies.

\begin{lem}\label{noSA}
Suppose $\eta$ is an SA for the DLM such that conditional on $\phi$, $\eta$ and $y$ are joint normally distributed, that is 
\begin{align*}
 \left. \begin{bmatrix}\eta \\ y \end{bmatrix}\right|\phi \sim N\left(\begin{bmatrix} \alpha_\eta \\ D\mu \end{bmatrix}, \begin{bmatrix} 
   \Omega_\eta & \Omega_{y,\eta}' \\
   \Omega_{y,\eta} & \tilde{V} + \tilde{W} \end{bmatrix}\right).
\end{align*}
Then $\tilde{\eta}=\Omega_{y,\eta}'\Omega_{\eta}^{-1}\eta$ is also an SA and
\[
\tilde{\eta}|\phi \sim N(D\mu,\tilde{V} + \tilde{W} - \Sigma)
\]
where $\Sigma=\Omega_{y,\eta}'\Omega_{\eta}^{-1}\Omega_{y,\eta}$, and $\tilde{V} + \tilde{W} - \Sigma$ is functionally independent of $\phi$, and conditional posterior of $\phi$ given $\tilde{\eta}$ can be written as
\[
p(\phi|\tilde{\eta},y) \propto p(\phi)\propto |\tilde{V} + \tilde{W} - \Sigma|^{-1/2}\exp\left[-\frac{1}{2}(\tilde{\eta} - D\mu + b)'(\tilde{V} + \tilde{W} - \Sigma)^{-1}(\tilde{\eta} - D\mu + b)\right].
\]
\end{lem}
To prove this lemma, first the normality assumption implies
\begin{align*}
  y|\eta,\phi &\sim N(D\mu + \Omega_{y,\eta}'\Omega_\eta^{-1}(\eta - \alpha_\eta), \tilde{V} + \tilde{W} - \Omega_{y,\eta}'\Omega_{\eta}^{-1}\Omega_{y,\eta})\\
  \eta|\phi &\sim N(\alpha_\eta, \Omega_\eta).
\end{align*}
Now for $\eta$ to be a sufficient augmentation we need $D\mu + \Omega_{y,\eta}'\Omega_\eta^{-1}(\eta - \alpha_\eta)$ and $\tilde{V} + \tilde{W} - \Omega_{y,\eta}'\Omega_{\eta}^{-1}\Omega_{y,\eta}$
to be independent of $\phi$. This requires that
\begin{align*}
  D\mu - \Omega_{y,\eta}'\Omega_\eta^{-1}\alpha_\eta + \Omega_{y,\eta}'\Omega_\eta^{-1}\eta  = b + A\eta
\end{align*}
where $A=\Omega_{y,\eta}'\Omega_\eta^{-1}$ and $b=D\mu - A\alpha_\eta$ must both be free of $\phi$. This also implies that $A\alpha_\eta = D\mu - b$.

Then using the second equation, we now require $\Sigma = \tilde{V} + \tilde{W} - A\Omega_{\eta}A'$ free of $\phi$ which in turn implies that $\Omega_{\eta,y}$ must not be the zero matrix. This gives $A\Omega_{\eta}A' = \tilde{V} + \tilde{W} - \Sigma$. Consider $\tilde{\eta}=A\eta$, which is also a sufficient augmentation since it is just a linear transformation by a constant matrix. Then we have
\begin{align*}
y|\tilde{\eta},\phi & \sim N(b + \tilde{\eta}, \Sigma)\\
\tilde{\eta}|\phi & \sim N(D\mu - b, \tilde{V} + \tilde{W} - \Sigma)
\end{align*}
with $b$ and $\Sigma$ free of $\phi$. Thus the posterior density of $\phi$ given $\tilde{\eta}$ can be written as
\begin{align*}
  p(\phi|\tilde{\eta}, y) &\propto p(y|\tilde{\eta},\phi)p(\tilde{\eta}|\phi)p(\phi) \propto p(\tilde{\eta}|\phi)p(\phi) \\
&\propto |\tilde{V} + \tilde{W} - \Sigma|^{-1/2}\exp\left[-\frac{1}{2}(\tilde{\eta} - D\mu + b)'(\tilde{V} + \tilde{W} - \Sigma)^{-1}(\tilde{\eta} - D\mu + b)\right]. \qed
\end{align*}
The posterior desity we wish to sample from is similar to $p(\phi|\tilde{\eta},y)$, except it has $\Sigma$ equal to the zero matrix and $b$ equal to the zero vector. Using $\eta$ instead of $\tilde{\eta}$ will not result in a simpler density $p(\phi|\eta,y)$. This conditional posterior can be written as
\begin{align*}
p(\phi|\eta,y) &\propto p(\phi) |\Omega_{\eta}|^{-1/2}\exp\left[-\frac{1}{2}(\eta - \alpha_{\eta})'(\Omega_{\eta})^{-1}(\eta - \alpha_{\eta})\right]\\
p(\phi|\eta,y) &\propto p(\phi) |A(\tilde{V} + \tilde{W} - \Sigma)A'|^{-1/2}\exp\left[-\frac{1}{2}(A\eta - D\mu + b)'A[A(\tilde{V} + \tilde{W} - \Sigma)A']^{-1}A'(A\eta - D\mu + b)\right]\\
\end{align*}
where again $A$, $\Sigma$ and $b$ are free of $\phi$. This density is even more complicated than $p(\phi|\tilde{\eta},y)$ unless $A=\Omega_{\eta,y}'\Omega_\eta^{-1}$ is invertible, in which case they are the same density. The upshot is that once we find an SA, in order to use it we must obtain draws from a density that appears just as hard to sample from as the posterior density we are already trying to approximate.

Lemma \ref{noSA} does not quite rule out the existence of a useful SA --- in particular relaxing the joint normality assumption might yield something worthwhile --- but the lemma does suggest that it will be difficult to find one. This result brings to mind \citeasnoun{van2001art}'s contention that there is an art to constructing data augmentation algorithms --- our goal is not only to find an MCMC algorithm that has nice convergence and mixing properties, but also one that is easy to implement. This second criteria is much more difficult to quantify. 

The problem we run into is unlikely to be unique to the time series setting but rather seems driven by trying to find an SA for a pair of variances, one on the data level and the other on the latent data level. For example, in a hierarchical model we expect there to be similar problems finding an SA when both the observational and hierarchical variance are unknown. There is a similar problem while trying to find two data augmentations that are independent in the posterior which, by \citeasnoun{yu2011center}'s Theorem 1, would guarantee an interweaving algorithm that yields iid draws from the posterior distribution of the model parameters. We omit the details, but unsurprisingly after making similar assumptions about the nature of the DAs in the DLM, the conditional posterior of $\phi$ ends of being either identical to or just as complicated as the marginal posterior of $\phi$. We also expect this problem to carry over to hierarchical models.

\section{MCMC Strategies for the DLM}\label{sec:Algs}

\subsection{Base algorithms}\label{sec:Algs:base}
Using any of the DAs introduced in Section \ref{sec:DAs}, we can construct several DA algorithms (Algorithm \ref{alg:DA}), which we call {\it base algorithms}. A well known method to estimate the parameters in a DLM uses the DA algorithm using the latent states $\theta_{0:T}$ as the DA \cite{fruhwirth1994data,carter1994gibbs}. We are calling this algorithm the {\it state sampler}. In order to construct this algorithm, we need two pieces --- the conditional posterior of $V$ and $W$ given $\theta_{0:T}$ and the conditional posterior of $\theta_{0:T}$ given $V$ and $W$. The density $p(\theta_{0:T}|V,W,y_{1:T})$ is multivariate normal, and any algorithm that obtains a random draw from it is called a simulation smoother in the literature. One commonly used simulation smoother is the forward filtering, backward sampling algorithm (FFBS) \cite{fruhwirth1994data,carter1994gibbs} which uses the Kalman filter, but there are several alternatives including \citeasnoun{koopman1993disturbance} and \citeasnoun{de1995simulation}. The smoothers introduced in \citeasnoun{mccausland2011simulation} and \citeasnoun{rue2001fast}, dubbed ``all without a loop'' smoothing (AWOL) by \citeasnoun{kastner2013ancillarity} are particularly efficient. Both methods exploit the tridiagonal structure of the precision matrix of the joint normal distribution for $\theta_{0:T}$ in order to speed up matrix computations. 

The method of \citeasnoun{rue2001fast} exploits this structure in order to quickly compute a Cholesky decomposition of the precision matrix and as a result is also called the Cholesky factor algorithm (CFA). \citeasnoun{mccausland2011simulation}, on the other hand, exploits this structure in order to break up the random draw from $p(\theta_{0:T}|V,W,y_{1:T})$ into $T+1$ steps. The tridiagonal precision matrix ensures that $p(\theta_{t}|\theta_{t+1:T},V,W,y_{1:T}) = p(\theta_{t}|\theta_{t+1},V,W,y_{1:T})$ for $t=0,1,\cdots,T-1$. Then the algorithm initializes with a draw from $p(\theta_T|V,W,y_{1:T})$, then draws recursively from $p(\theta_{t}|\theta_{t+1:T}|V,W,y_{1:T})$ for $t=T-1,T-2,\cdots,0$. In effect, this algorithm takes the Cholesky decomposition and simulation steps of the CFA algorithm and mixes their sub-steps together.  As a result, we call this the mixed Cholesky factor algorithm (MCFA). The upshot for computational efficiency is that instead of working with a $(T+1)p\times (T+1)p$ precision matrix the MCFA works with $T+1$ distinct $p\times p$ precision matricies which often, but not always, speeds up the computation relative to the CFA \cite{mccausland2011simulation}. We omit the details of this algorithm in the context of the DLM, but they can be found in the supplementary materials.

\jarad{Maybe we need a better name for the MCFA. The original authors didn't name the algorithm and just want to refer to it with MMP, which is the first letters of each of their last names, but I'd like an intuitive name that points out the connection to and differences from the CFA algorithm.}

In order to complete the state sampler, we need to obtain a draw from $p(V,W|\theta_{0:T},y_{1:T})$. From equation \ref{dlmjoint} it is easy to see that $V$ and $W$ have independent inverse Wishart distributions conditional on $\theta_{0:T}$ and $y_{1:T}$. In particular
\begin{align*}
  V|\theta_{0:T},y_{1:T} &\sim IW\left(\Lambda_V + \sum_{t=1}^Tv_tv_t',\lambda_V + T\right), &
  W|\theta_{0:T},y_{1:T} &\sim IW\left(\Lambda_W + \sum_{t=1}^Tw_tw_t',\lambda_{W} + T\right) %\label{eq:VW|theta}
\end{align*}
where $v_t = y_t - F_t\theta_t$ and $w_t = \theta_t - G_t\theta_{t-1}$.

As we will show in Section \ref{sec:LLMest}, the Markov chain constructed using the state sampler can mix poorly in some regions of the parameter space. For example, in the univariate local level model ($F_t=G_t=1$ for $t=1,2,\cdots,T$) and similar models it is known that if the variance of the latent states is too small relative to the variance of the data, mixing will be poor for $W$ \cite{fruhwirth2004efficient}.

Next, we can use the scaled disturbances, $\gamma_{0:T}$, in order to construct a second DA algorithm called the {\it scaled disturbance sampler}. In the smoothing step, we need to obtain a draw from $p(\gamma_{0:T}|V,W,y_{1:T})$, which is proportional to equation \eqref{dlmdistjoint}. This density is also Gaussian but does not have a tridagonal precision matrix. As a result, in order to obtain a draw from the conditional posterior of $\gamma_{0:T}$, we use the MCFA to instead draw from $p(\theta_{0:T}|V,W,y_{1:T})$, then use the definition of the scaled disturbances in order to transform from $\theta_{0:T}$ to $\gamma_{0:T}$. The density $p(V,W|\gamma_{0:T},y_{1:T})$ is also proportional to \eqref{dlmdistjoint}, but it is rather complicated and does not appear easy to draw from. It is easy to see that $V|W,\gamma_{0:T},y_{1:T} \sim IW\left(\Lambda_V + \sum_{t=1}^Tv_tv_t',\lambda_V + T\right)$ where again $v_t = y_t - F_t\theta_t$. It is not easy to draw from $p(W|\gamma_{0:T},y_{1:T})$ so we abandon drawing $V$ and $W$ jointly. However, the density $p(W|V,\gamma_{0:T},y_{1:T})$ is simpler and, at least in the local level model, can be efficiently sampled from (Section \ref{sec:LLM}). As a result, the scaled disturbance sampler has three steps instead of the two of the usual DA algorithm (Algorithm \ref{alg:DA}). In this algorithm, we draw $V$ before $W$, i.e. $[\gamma_{0:T}|V^{(k)},W^{(k)}] \to [V^{(k+1)}|W^{(k)},\gamma_{0:T}] \to [W^{(k+1)}|V^{(k+1)},\gamma_{0:T}]$. Note that in order to draw $\gamma_{0:T}$, we first draw $\theta_{0:T}$ and transform, and that the draw of $V$ is the same whether we condition on $\gamma_{0:T}$ or $\theta_{0:T}$. As a result, in the scaled disturbance sampler we wait to transform from $\theta_{0:T}$ to $\gamma_{0:T}$ until just before the $W$ step, which reduces the computational cost of the algorithm.

The DA algorithm based on on the scaled errors, $\psi_{0:T}$, is called the {\it scaled error sampler} and is similar to the scaled disturbance sampler with a couple of key differences. The conditional densities we are interested in are all proportional to equation \eqref{dlmerrorjoint}. First, the simulation smoothing step the scaled error sampler can be accomplished directly with the MCFA because the precision matrix of the conditional posterior of $\psi_{0:T}$ retains the necessary tridiagonal structure. Once again, the draw of $V$ and $W$ has to be broken up into two steps. The full conditional distribution of $W$ is inverse Wishart, that is $W|V,\psi_{0:T},y_{1:T} \sim IW\left(\Lambda_W + \sum_{t=1}^Tw_tw_t',\lambda_{W} + T\right)$ where once again $w_t = \theta_t - G_t\theta_{t-1}$.The density of $V|W,\psi_{0:T},y_{1:T}$ is in the same class as that of $W|V,\gamma_{0:T},y_{1:T}$. In fact there is a strong symmetry here --- the joint conditional posterior of $(V,W)$ given $\gamma_{0:T}$ is from the same family of densities as that of $(W,V)$ given $\psi_{0:T}$ so that $V$ and $W$ essentially switch places when we condition of $\psi_{0:T}$ instead of $\gamma_{0:T}$. We again draw $V$ before $W$ so that the scaled-error sampler looks very similar to the scaled disturbance sampler: $[\psi_{0:T}|V^{(k)},W^{(k)}] \to [V^{(k+1)}|W^{(k)},\psi_{0:T}] \to [W^{(k+1)}|V^{(k+1)},\psi_{0:T}]$.

The wrongly-scaled DA algorithms are close analogues to their correctly scaled cousins. Starting with the {\it wrongly-scaled disturbance sampler}, we can obtain the required full conditionals from equation \eqref{dlmdisttildejoint}. The simulation smoothing step to draw from $p(\tilde{\gamma}_{0:T}|V,W,y_{1:T})$ is similar to that of the scaled disturbance sampler --- the density is Gaussian, but the precision matrix is not tridiagonal, so we draw $\theta_{0:T}$ using the MCFA and trandform to obtain a draw of $\tilde{\gamma}_{0:T}$. The density of $V,W|\tilde{gamma}_{0:T},y_{1:T}$ is too complicated to draw from directly, as was the case when we used the scaled disturbances. In this case, the full conditional distribution of $W$ is the same as its distribution when we condition on the states, i.e. $W|V,\tilde{\gamma}_{0:T},y_{1:T} \sim \sim IW\left(\Lambda_W + \sum_{t=1}^Tw_tw_t',\lambda_{W} + T\right)$ with $w_t = \theta_t - G_t\theta_{t-1}$ as before, and $\theta_{0:T}$ a function of $V$ and $\tilde{\gamma}_{0:T}$. The density for $V|\tilde{\gamma}_{0:T},y_{1:T}$ is once again difficult to draw from, but that of $V|W,\tilde{\gamma}_{0:T},y_{1:T}$ is easier to work with, especially in the local level example from Section \ref{sec:LLM}. So in the wrongly-scaled disturbance sampler, we also draw $(V,W)$ in two steps: $[\tilde{\gamma}_{0:T}|V^{(k)},W^{(k)}] \to [V^{(k+1)}|W^{(k)},\tilde{\gamma}_{0:T}] \to [W^{(k+1)}|V^{(k+1)},\tilde{\gamma}_{0:T}]$.

The {\it wrongly-scaled error sampler} depends on equation \eqref{dlmerrortildejoint} for its full conditionals, and is closely related to both the wrongly-scaled disturbance sampler and the scaled error sampler. The density of $\tilde{\psi}_{0:T}|V,W,y_{1:T}$ is Gaussian with a tridiagonal precision matrix, so the simulation smoothing step can be accomplished using the MCFA. The density $p(V,W|\tilde{\psi}_{0:T},y_{1:T})$ is from the same class as $p(W,V|\tilde{\gamma}_{0:T},y_{1:T})$ so that $V$ and $W$ essentially switch places when we condition on $\tilde{\psi}_{0:T}$ instead of $\tilde{\gamma}_{0:T}$, much like in the correctly scaled case. In particular, $V|W,\tilde{\psi}_{0:T},y_{1:T} \sim IW\left(\Lambda_V + \sum_{t=1}^Tv_tv_t',\lambda_V + T\right)$ where $v_t = y_t - F_t\theta_t$ and $\theta_{0:T}$ is a function of $W$, $\tilde{\psi_{0:T}}$ and $y_{1:T}$. The density of $W|V,\tilde{psi}_{0:T},y_{1:T}$ is from the same class as that of $V|W,\tilde{gamma}_{0:T},y_{1:T}$. So we once again draw $V$ and $W$ separately, i.e. $[\tilde{\psi}_{0:T}|V^{(k)},W^{(k)}] \to [V^{(k+1)}|W^{(k)},\tilde{\psi}_{0:T}] \to [W^{(k+1)}|V^{(k+1)},\tilde{\psi}_{0:T}]$.

The densities $p(V,W|\gamma_{0:T},y_{1:T})$ and $p(V,W|\tilde{\psi}_{0:T}$ are both complex to work with and both imply the same full conditional inverse Wishart distribution for $V$, but they differ in their treatment of $W$. Because of the symmetry between the correctly and wrongly scaled versions of each density, the same can be said for $p(V,W|\tilde{\gamma}_{0:T},y_{1:T})$ and $p(V,W|\psi_{0:T},y_{1:T})$. In Section \ref{sec:LLM}, we will show how closely the two distributions are related in the local level model. Now given these five DA algorithms, we can move on to alternating and interweaving algorithms which combine two or more of the various DAs in interesting ways.

\subsection{Alternating algorithms}\label{sec:Algs:alt}
Recall that an alternating algorithm is an MCMC algorithm in which one iteration is composed of a single iteration of one DA algorithm followed by a signle iteration of another DA algorithm, as in Algorithm \ref{alg:Alt}. Using the full conditional distributions defined in Section \ref{sec:Algs:base}, we have enough information to construct several alternating algorithms based on any two of the DA algorithms defined there. For example, the {\it State-Dist alternating sampler} which alternates between the states and the scaled disturbances, obtains the $k+1$'st iteration of $(V,W)$ from the $k$'th as follows:
\begin{align*}
&[\theta_{0:T}|V^{(k)},W^{(k)}] \to [V^{(k+0.5)},W^{(k+0.5)}|\theta_{0:T}] \to\\ 
&
[\gamma_{0:T}|V^{(k+0.5)},W^{(k+0.5)}] \to [V^{(k+1)}|W^{(k+0.5)},\gamma_{0:T}] \to [W^{(k+1)}|V^{(k+1)},\gamma_{0:T}].
\end{align*}
The first line is an iteration of the state sampler while the second line is an iteration of the scaled disturbance sampler. No additional work is necessary to link up the two iterations --- we simply plug in the values of $V$ and $W$ obtained from the state sampler iteration into the draw of $\gamma_{0:T}$ from step one of the scaled disturbance sampler iteration.

Each other alternating algorithm is analogous and can be constructed without any additional complications. There is a question of what order to use the base algorithms within an alternating algorithm which could in principle affect the congergence properties of the alternating algorithm. In practice this typically is not important. There is one additional wrinkle added by consider alternating algorithms which combine more than two base samplers. This class of samplers is not any more comlicated other than adding a couple extra steps. For example, the {\it State-Dist-Error alternating sampler} which alternates between the states, the scaled errors, and the scaled disturbances is as follows:
\begin{align*}
&[\theta_{0:T}|V^{(k)},W^{(k)}] \to [V^{(k+1/3)},W^{(k+1/3)}|\theta_{0:T}] \to\\ 
&
[\gamma_{0:T}|V^{(k+1/3)},W^{(k+1/3)}] \to [V^{(k+2/3)}|W^{(k+1/3)},\gamma_{0:T}] \to [W^{(k+2/3)}|V^{(k+2/3)},\gamma_{0:T}]\to \\
[\psi_{0:T}|V^{(k+2/3)},W^{(k+2/3)}] \to [V^{(k+1)}|W^{(k+2/3)},\psi_{0:T}] \to [W^{(k+1)}|V^{(k+1)},\psi_{0:T}].
\end{align*}
Once again, each of the required conditional distributions are defined in Section \ref{sec:Algs:base} so there is no real extra difficult.

The naming convention we use for these algorithms is to list each DA in the order in which they appear in the alteranting sampler, separated by hyphens. The scaled disturbances we shorten to ``Dist'', the scaled errors we shorten to ``Error'', and the wrongly-scaled version of each we write as ``Wdist'' and ``Werror'' respectively. So, for example, the alternating sampler which alternates between the scaled disturbances and the wrongly-scaled disturbances, in that order, we call the {\it Dist-Wdist alternating sampler} or {\it Dist-Wdist Alt}. The main purpose of these algorithm is to use as a baseline for evaluating the GIS algorithms based on the same sets of DAs.

\subsection{GIS Algorithms}\label{sec:Algs:GIS}
We can use the various DAs of Section \ref{sec:DAs} in order to construct interweaving algorithms in addition to the alternating algorithms of the previous section. Recall that a general interweaving strategy (GIS) is an algorithm that draws first from the full conditional distribution of a DA, then draws from the conditional distribution of a new DA given the old DA and the data, then draws from the full conditional distribution of the model parameters given the new DA, in other words Algorithm \ref{alg:GIS}. Given the full conditional distributions listed in Section \ref{sec:Algs:base}, the only additional ingredients we need are the densities of, for example, $p(\gamma_{0:T}|\theta_{0:T},y_{1:T})$ and $p(\psi_{0:T}|\theta_{0:T},y_{1:T})$. In practice, it is easier to obtain a joint draw of, e.g., $(V,W,\gamma_{0:T}|\theta_{0:T},y_{1:T})$, i.e. to use the extended version of the GIS algorithm, Algorithm \ref{alg:GIS2}.

So the only additional requirement in order to construct a GIS algorithm is to use the definitions of the various available DAs in order to perform the one-to-one transformations from any one DA to another. For example, in the {\it State-Dist GIS sampler} we obtain $(V^{(k+1)},W^{(k+1)})$ from $(V^{(k)},W^{(k)})$ as follows:
\begin{align*}
&[\theta_{0:T}|V^{(k)},W^{(k)}] \to [W^{(k+0.5)},V^{(k+0.5)}|\theta_{0:T}] \to\\
&[\gamma_{0:T}|V^{(k+0.5)},W^{(k+0.5)},\theta_{0:T}] \to [V^{(k+1)}|W^{(k+0.5)},\gamma_{0:T}] \to [W^{(k+1)}|V^{(k+1)},\gamma_{0:T}].
\end{align*}
Here, the first step of the second line is not a proper random draw --- rather, we transform $\theta_{0:T}$ to $\gamma_{0:T}$ by means of the defining equations for $\gamma_{0:T}$: $\gamma_0=\theta_0$ and $\gamma_t = L_W^{-1}(\theta_t - G_t\theta_{t-1})$ for $t=1,2,\cdots,T$ where $L_W$ is the Cholesky decomposition of $W$. 

There are often some small improvements that can be made simply by thinking clearly about what the GIS algorithm is doing. For example in the above version of the State-Dist GIS sampler, the draw of $V$ in step two of line one and the draw of $V$ in step two of line two are redundant --- they come from the same distribution and only the last one is ever used in later steps. As a result, we can remove the second draw in order to save computational time:
\begin{align*}
&[\theta_{0:T}|V^{(k)},W^{(k)}] \to [W^{(k+0.5)},V^{(k+1)}|\theta_{0:T}] \to\\
&[\gamma_{0:T}|V^{(k+1)},W^{(k+0.5)},\theta_{0:T}] \to 
[W^{(k+1)}|V^{(k+1)},\gamma_{0:T}].
\end{align*}

The naming convention for GIS algorithms is similar to that of alternating algorithms --- DAs appear in the name in the order that they appear in the algorithm, separated by hyphens, e.g. a GIS algorithm based on the states, scaled disturbances and scaled errors, in that order, would be called the {\it State-Dist-Error GIS sampler}. There is no additional difficulty encountered by using a GIS with greater than two DAs --- the required conditional distributions are still defined in Section \ref{sec:Algs:base} and the definitions of the various DAs should allow for the one-to-one transformation from any DA to another DA to be defined.  Also like alternating algorithms, the performance of GIS algorithms may depend on the order in which the DAs are used. \citeasnoun{yu2011center} note that this tends not to make much difference, which is consistent with our own experience.

\subsection{CIS algorithms}\label{sec:Algs:CIS}
Recall that a component interweaving strategy (CIS) is an MCMC algorithm that uses GIS in a Gibbs step for part of the parameter vector and GIS in another Gibbs step for the other part of the parameter vector, i.e. Algorithm \ref{alg:CIS}. The advantage of using CIS is that it is sometimes possible to find an AA-SA pair of DAs for each part of the parameter vector rather even when no such pair of DAs exist for the entire parameter vector. To wit, from Section \ref{sec:DAs} we know that the scaled disturbances and the wrongly-scaled disturbances form an AA-SA pair for $W|V$ while the scaled errors and the wrongly-scaled errors form an AA-SA pair for $V|W$. 

A CIS sampler based on these AA-SA pairs obtains $(V^{(k+1)},W^{(k+1)})$ from $(V^{(k)},W^{(k)})$ as follows:
\begin{align*}
&[\psi_{0:T}|V^{(k)},W^{(k)}] \to [V^{(k+0.5)}|W^{(k)},\psi_{0:T}] \to [\tilde{\psi}_{0:T}|V^{(k+0.5)},W^{(k)},\psi_{0:T}] \to [V^{(k+1)}|W^{(k)},\tilde{\psi}_{0:T}]\to\\
&[\gamma_{0:T}|V^{(k+1)},W^{(k)}] \to [W^{(k+0.5)}|V^{(k)},\gamma_{0:T}] \to [\tilde{\gamma}_{0:T}|V^{(k+1)},W^{(k+0.5)},\gamma_{0:T}]\to [W^{(k+1)}|V^{(k+1)},\tilde{\gamma}_{0:T}].
\end{align*}
The first line is a Gibbs step in order to draw $V$. The first step of that line runs the usual simulation smoothing step for $\psi_{0:T}$ discussed in Section \ref{sec:Algs:base}. The second step draws from the complicated full conditional of $V$ given $\psi_{0:T}$. The third step is simply a transformation from $\psi_{0:T}$ to $\tilde{\psi}_{0:T}$ given by the definition of the two DAs. The last step is the same inverse Wishart draw as in the state sampler and in wrongly-scaled error sampler from Section \ref{sec:Algs:base}. The second line is a Gibbs step in order to draw $W$. The first step is the usual simulation smoother for $\gamma_{0:T}$ from Section \ref{sec:Algs:base}. The second step draws $W$ from its complicated full conditional given $\gamma_{0:T}$. The third step is once again a transformation step, obtained from the defintions of $\gamma_{0:T}$ and $\tilde{\gamma}_{0:T}$. The last step draws $W$ from the same inverse Wishart distribution that shows up in the state sampler and in the wrongly-scaled disturbance sampler. 

Notice that each time one of the wrongly-scaled DAs appears in the CIS sampler above, it would make no difference if the states were used instead despite the fact that we know from Section \ref{sec:DAs} the states are only an SA for $W|V$ but not for $V|W$. Using this fact, switching the order in which the DAs are used in the Gibbs step for $V$, and switching the order in which the Gibbs steps for $V$ and $W$ are performed we obtain a slightly different version of the CIS sampler:
\begin{align*}
&[\gamma_{0:T}|V^{(k)},W^{(k)}] \to [W^{(k+0.5)}|V^{(k)},\gamma_{0:T}] \to [\theta_{0:T}|V^{(k)},W^{(k+0.5)},\gamma_{0:T}]\to [W^{(k+1)}|V^{(k)},\theta_{0:T}]\to\\
&[\theta_{0:T}|V^{(k)},W^{(k+1)}] \to [V^{(k+0.5)}|W^{(k+1)},\theta_{0:T}] \to [\psi_{0:T}|V^{(k+0.5)},W^{(k+1)},\theta_{0:T}] \to [V^{(k+1)}|W^{(k+1)},\psi_{0:T}].
\end{align*}
Since the draw of $V$ is from the same density whether we condition of $\theta_{0:T}$ or $\gamma_{0:T}$ and similar for $W$ given $\theta_{0:T}$ or $\psi_{0:T}$, we can rearrange the steps of this algorithm to obtain the {\it Dist-Error GIS sampler} which interweaves between the scaled disturbances and the scaled errors:
\begin{align*}
&[\gamma_{0:T}|V^{(k)},W^{(k)}] \to [V^{(k+0.5)}|W^{(k)},\gamma_{0:T}] \to[W^{(k+0.5)}|V^{(k+0.5)},\gamma_{0:T}] \to \\
&[\psi_{0:T}|V^{(k+0.5)},W^{(k+0.5)}]\to [V^{(k+1)}|W^{(k+0.5)},\psi_{0:T}]\to [W^{(k+1)}|V^{(k+1)},\psi_{0:T}].
\end{align*}
As a result, since in most cases simply rearranging the steps of an MCMC sampler does little to impact the convergence and mixing properties of the sampler, we expect the CIS and Dist-Error GIS samplers to perform about the same along this axis so that computational cost per iteration is the only real difference between the two.

In our original defintion of the CIS sampler for the DLM we used the scaled disturbances as the AA for $W$ and the scaled errors and the AA for $V$. We could have reversed this or use the same AA for both $V$ and $W$ since both the scaled errors and scaled disturbances are AAs for $(V,W)$. Consider the version where we reverse the steps where AAs are used, as below:
\begin{align*}
&[\gamma_{0:T}|V^{(k)},W^{(k)}] \to [V^{(k+0.5)}|W^{(k)},\gamma_{0:T}] \to [\tilde{\psi}_{0:T}|V^{(k+0.5)},W^{(k)},\gamma_{0:T}] \to [V^{(k+1)}|W^{(k)},\tilde{\psi}_{0:T}]\to\\
&[\psi_{0:T}|V^{(k+1)},W^{(k)}]\to [W^{(k+0.5)}|V^{(k+1)},\psi_{0:T}] \to [\tilde{\gamma}_{0:T}|V^{(k+1)},W^{(k+0.5)},\psi_{0:T}] \to [W^{(k+1)}|V^{(k+1)},\tilde{\gamma}_{0:T}].
\end{align*}
Here steps two and four of the first line draw $V$ from the same inverse Wishart distribution --- as if we conditioned on $\theta_{0:T}$ isntead of $\gamma_{0:T}$ or $\tilde{\psi}_{0:T}$. Similarly, steps two and four of the second line draw $W$ from the same inverse Wishart distribution, again as if we conditioned on $\theta_{0:T}$. So we can remove the extraneous steps and write this CIS sampler in a different form:
\begin{align*}
[\theta_{0:T}|V^{(k)},W^{(k)}] \to [V^{(k+1)}|W^{(k)},\theta_{0:T}] \to [\theta_{0:T}|V^{(k+1)},W^{(k)}]\to [W^{(k+1)}|V^{(k)},\theta_{0:T}].
\end{align*}
This algorithm is nearly identical to the state sampler since conditional on $\theta_{0:T}$, $V$ and $W$ are independent. The difference is that the sampler above breaks the correlation between $V$ and $W$ by drawing a new $\theta_{0:T}$ inbetween drawing $V$ and $W$. For this reason, we call the above algorithm the {\it staggered state sampler} or {\it StagState sampler} to distinguish it from the CIS sampler discussed above since the actual steps taken do not resemble a CIS algorithm at all.

Now that we have all of these possible samplers, we need to explore how well the perform. 

\clearpage

\bibliographystyle{ECA_jasa}  % proper bibliography style for ASA
\bibliography{dlmasis}
\end{document}




