\documentclass{article}
\usepackage{JASA_manu} %formats document like ASA wants
\usepackage{jasa_harvard} %formats citations like ASA wants
\usepackage{amssymb, amsmath, amsthm, graphics, graphicx, color, fullpage}
\usepackage{thmtools} %to format the Algorithm environment correctly
\usepackage{nameref, hyperref, cleveref} %for named references

% define algorithm environment
\declaretheoremstyle[
notefont=\bfseries, notebraces={}{},
bodyfont=\normalfont\itshape,
headformat=\NAME:\NOTE
]{nopar}
\declaretheorem[style=nopar, name=Algorithm, 
refname={Algorithm,Algorithms},
Refname={Algorithm,Algoritms},
numbered=no]{alg*}

\newtheorem{thm}{Theorem}[subsection]
\newtheorem{prop}[thm]{Proposition}
\newtheorem{cor}[thm]{Corollary}
\newtheorem{lem}[thm]{Lemma}

\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator{\B}{B}
\DeclareMathOperator{\vech}{vech}
\DeclareMathOperator{\vect}{vec}

\graphicspath{{plots/}}
\newcommand{\matt}[1]{{\color{red} Matt: #1}}
\newcommand{\jarad}[1]{{\color{red} Jarad: #1}}


\begin{document}


\title{Interweaving Markov chain Monte Carlo strategies for efficient
estimation of dynamic linear models}
\author{Matt Simpson, Jarad Niemi, Vivekananda Roy}
\maketitle

\begin{abstract}
In dynamic linear models (DLMs), Markov chain Monte Carlo (MCMC) sampling can often be very slow for accurately estimating the posterior density --- especially for longer time series. In particular, in some regions of the parameter space the standard data augmentation algorithm can mix very slowly. Using some of the insights from the data augmentation for multilevel models literature, we explore several alternative data augmentations for a general class of DLMs and we show that no ``practical'' centered parameterization (or sufficient augmentation in the terminology of \citeasnoun{yu2011center}) exists. In addition, we utilize these augmentations to construct several interweaving algorithms --- though we cannot construct an ancillary-sufficient interweaving algorithm (ASIS) since no sufficient augmentation exists, we find two ancillary augmentations and are able to construct a componentwise interweaving algorithm (CIS) that uses ASIS for each model parameter conditional on the rest. Using the local level DLM, we show how to construct several of these algorithms and conduct a simulation study in order to discern their properties. We find that several algorithms that outperform the usual ``state sampler'' for many values of the population parameters, though there is room for improvement.
\end{abstract}


\section{Introduction}\label{sec:Intro}

Ever since the seminal article by \citeasnoun{tanner1987calculation}, data augmentation has become a common strategy for constructing MCMC algorithms to sample from intractable probability distributions. Suppose $p(\phi|y)$ is the target density, in this case the posterior distribution of some parameter $\phi$ given data $y$. We use $p(.)$ to denote the probability density of the enclosed random variables. Then the data augmentation (DA) algorithm adds a data augmentation $\theta$ with joint distribution $p(\phi,\theta|y)$ such that $\int_{\Theta}p(\phi,\theta|y)d\theta = p(\phi|y)$. The DA algorithm is similar to a Gibbs sampler, except it constructs a Markov chain for $\phi$ instead of $(\phi, \theta)$. In the DA algorithm, the $k+1$'st state of $\phi$ is obtained from the $k$'th state as follows (we implicitly condition on the data $y$ in all algorithms and only superscript the previous and new draws of the model parameters of interest):
\begin{alg*}[DA]Data Augmentation\label{alg:DA}
  \begin{align*}
  [\theta|\phi^{(k)}] \to [\phi^{(k+1)}|\theta]
\end{align*}
\end{alg*} 
\noindent Here $[\theta|\phi^{(k)}]$ means a draw of $\theta$ from $p(\theta|\phi^{(k)},y)$ and $[\phi^{(k+1)}|\theta]$ means a draw from $p(\phi|\theta,y)$. The DA, $\theta$, need not be interesting in any scientific sense --- it can be viewed purely as a computational construct. However for cases where the DA is intrinsically interesting, the DA algorithm does incidentally obtain joint draws from $p(\phi,\theta|y)$ and in that sense can be viewed as a Gibbs sampler. For our purposes, $\theta$ is a nuisance parameter.

The EM algorithm of \citeasnoun{dempster1977maximum} and its variants are closely analogous to DA algorithms --- specifically the DA algorithm can be viewed as a stochastic version of the EM algorithm. In fact there is a long history of using methods typically used to speed up the EM algorithm to speed up DA algorithm and vice versa; \citeasnoun{van2010cross} shows how much overlap in the two literatures exists. The main advantage of DA and EM algorithms is their ease of implementation, but much of this work is necessary because DA and EM algorithms can often be prohibitively slow. One well known method of improving mixing and convergence in MCMC samplers is reparameterizing the model. Most of the work in some way focuses on what are called centered and noncentered parameterizations. For example \citeasnoun{papaspiliopoulos2007general} is a good summary. In our general notation where $\phi$ is the parameter, $\theta$ is the DA and $y$ is the data, the parameterization $(\phi,\theta)$ is a {\it centered parameterization} (CP) if $p(y|\theta,\phi)=p(y|\theta)$. The parameterization is a {\it noncentered parameterization} (NCP) if $p(\theta|\phi)=p(\theta)$. When $(\phi,\theta)$ is a CP, $\theta$ is called a {\it centered augmentation} (CA) for $\phi$ and when $(\phi,\theta)$ is a NCP, $\theta$ is called a {\it noncentered augmentation} (NCA) for $\phi$. A centered augmentation is sometimes called a {\it sufficient augmentation} (SA) and a noncentered augmentation is sometimes called an {\it ancillary augmentation} (AA)\cite{yu2011center}. Like \citeasnoun{yu2011center}, we prefer the latter terminology because it immediately suggests the intuition that a sufficient augmentation is like a sufficient statistic while an ancillary augmentation is like an ancillary statistic and hence Basu's theorem suggests that they are conditionally independent given $\phi$. 

The key reasoning behind the emphasis on SAs and AAs is that typically when the DA algorithm based on the SA has nice mixing and convergence properties the DA algorithm based on the AA has poor mixing and convergence properties and vice-versa. This property suggests that there might be a way to combine the two DA algorithms or the two underlying parameterizations in order to construct an improved sampler. Some work focuses on using partially noncentered parameterizations that are a sort of bridge between the CP and NCP, e.g. \citeasnoun{papaspiliopoulos2007general} for general hierarchical models and \citeasnoun{fruhwirth2004efficient} in the context of a particular DLM --- a dynamic univariate regression with a stationary AR(1) coefficient. Another suggestion by \citeasnoun{papaspiliopoulos2007general} is to alternate between the two augmentations within a Gibbs sampler. Suppose we have a second distinct DA $\gamma$ such that $\int_\Gamma p(\phi,\gamma|y)d\gamma = p(\phi|y)$. Then the {\it alternating} algorithm for sampling from $p(\phi|y)$ is as follows:
\begin{alg*}[Alt]Alternating\label{alg:Alt} \\
  \begin{center}
    \begin{tabular}{lllllll}
  $[\theta|\phi^{(k)}]$& $\to$& $[\phi|\theta]$& $\to$& $[\gamma|\phi]$& $\to$& $[\phi^{(k+1)}|\gamma]$
    \end{tabular}
  \end{center}
\end{alg*}
\noindent One iteration of the alternating algorithm consists of one iteration of the DA algorithm based on $\theta$ to obtain an intermediate value of $\phi$, followed by one iteration of the DA algorithm based on $\gamma$ started at the intermediate value of $\phi$. 

Recall that a typical problem with slow MCMC is that there is high autocorrelation in the Markov chain for $\phi$, $\{\phi^{(k)}\}_{k=1}^K$, leading to imprecise estimates of $\mathrm{E}[f(\phi)|y]$ for some function $f$ integrable with respect to the posterior of $\phi$. Our goal is to reduce this dependence. In the usual DA algorithm (Algorithm \nameref{alg:DA}) when $\phi$ and $\theta$ are highly dependent in the joint posterior the draws from $p(\theta|\phi,y)$ and then from $p(\phi|\theta,y)$ will hardly move the chain which results in high autocorrelation. In an alternating algorithm, there are essentially two chances to substantially move the chain -- one for $\theta$ in the draws from $p(\theta|\phi,y)$ and from $p(\phi|\theta,y)$ and one for $\gamma$ in the draws from $p(\gamma|\phi,y)$ and from $p(\phi|\gamma,y)$.  In particular, when $\theta$ is an SA and $\gamma$ is an AA or vice versa, then it is often the case that there is low dependence either between $\phi$ and $\theta$ or between $\phi$ and $\gamma$. As a result, either steps 1 and 2 or steps 3 and 4 will substantially move the chain in the alternating algorithm, which limits how poorly the algorithm can perform.

One recent advance that is similar to an alternating strategy is the notion of {\it interweaving} the two DAs together \cite{yu2011center}. Suppose that given $(\phi,\theta,\gamma,y)$ we further require that they have a full joint but possibly singular distribution and that the conditional distribution $\mu_y$ of $(\phi,\theta,\gamma|y)$ is defined almost everywhere such that for any measurable $A\in \Phi$, $\int_{\Theta \times \Gamma \times A}d\mu_y = \int_Ap(\phi|y)d\phi$. Then a general interweaving strategy (GIS) is an MCMC algorithm that obtains $\phi^{(k+1)}$ from $\phi^{(k)}$ as follows:
\begin{alg*}[GIS]General Interweaving Strategy\label{alg:GIS}
  \begin{align*}
    [\theta|\phi^{(k)}] \to [\gamma|\theta] \to [\phi^{(k+1)}|\gamma].
  \end{align*}
\end{alg*}
\noindent The GIS algorithm obtains the $k+1$st iteration of the parameter vector $\phi$ from the $k$th iteration in three steps. First, it draws the DA $\theta$ conditional on $\phi^{(k)}$ (and the data). Next, it draws the DA $\gamma$ conditional on $\theta$. Finally, it draws $\phi^{(k+1)}$ conditional on $\gamma$. This looks similar to the usual DA algorithm, except a second DA is ``weaved'' in between the draw of the first DA and of the parameter vector. Step two of the GIS algorithm is typically accomplished by sampling $\phi|\theta,y$ and then $\gamma|\theta,\phi,y$. In addition, $\gamma$ and $\theta$ are often, but not always, one-to-one transformations of each other conditional on $(\phi,y)$, i.e. $\gamma = M(\theta;\phi,y)$ where $M(.;\phi,y)$ is a one-to-one function. This is the source of the potential singularity in $\mu_y$. If we expand out step two, then the algorithm becomes:
\begin{alg*}[GIS-E]Expanded GIS\label{alg:GIS2}\\
  \begin{center}
    \begin{tabular}{lllllll}
      $[\theta|\phi^{(k)}]$& $\to$& $[\phi|\theta]$& $\to $&$[\gamma|\theta,\phi]$& $\to$& $[\phi^{(k+1)}|\gamma]$
    \end{tabular}
  \end{center}
\noindent \end{alg*}
When $\gamma$ is a one-to-one transformation of $\theta$, step three is an update $\gamma=M(\theta;\phi,y)$. The key difference between GIS and the correpsonding alternating algorithm (Algorithm \nameref{alg:Alt}) can be seen in step three of Algorithm \nameref{alg:GIS2}: instead of drawing from $p(\gamma|\phi,y)$, the GIS algorithm draws from $p(\gamma|\theta,\phi,y)$, ``weaving'' the two DAs together, while the alternating algorithm keeps them separate.

\citeasnoun{yu2011center} call a GIS approach where one of the DAs is an SA and the other is an AA an {\it ancillary sufficient interweaving strategy}, or an ASIS. They show that the GIS algorithm has a geometric rate of convergence no worse than the worst of the two underlying DA algorithms and in some cases better than the the corresponding alternating algorithm. In particular, their Theorem 1 suggests that the weaker the dependence between two data augumentations in the posterior, the more efficient the GIS algorithm. With a posteriori independent data augmentations, the GIS algorithm will even obtain iid draws from the posterior density of the model parameter. This helps motivate their focus on ASIS --- conditional on the model parameter, an SA and an AA are independent under the conditions of Basu's theorem \cite{basu1955statistics}, which suggests that the dependence between the two DAs will be limited in the posterior. In fact, when the prior on $\phi$ is nice in some sense, \citeasnoun{yu2011center} show that the ASIS algorithm is the same as the optimal parameter expanded data augmentation (PX-DA) algorithm of \citeasnoun{liu1999parameter}, which is closely related to certain reparameterization techniques  \cite{hobert2008theoretical}. Their results suggest that ASIS and interweaving generally is a promising approach to improve the speed of MCMC in a variety of models no matter what region of the parameter space the posterior is concentrated. 

To gain some intuition about why interweaving works, we can first make a direct comparison to the alternating algorithm through the expanded version of the GIS algorithm (Algorithm \nameref{alg:GIS2}). Like the alternating algorithm, there are two opportunities for the Markov chain to move in the GIS algorithm, one each for $\theta$ and $\gamma$. So when the two underlying DA algorithms perform poorly in opposite regions of the parameter space, like the alternating algorithm, either steps 1 and 2 or steps 3 and 4 will substantially move the chain, limiting how poor the GIS algorithm can perform. In addition, \citeasnoun{yu2011center} show that the GIS algorithm is often much more efficient than the alternating algorithm. The key is that when the posterior dependence between the two DAs is low, step 2 in Algorithm \nameref{alg:GIS} (i.e. steps 2 and 3 in Algorithm \nameref{alg:GIS2}) is enough to almost completely break the dependence in the chain. For the alternating algorithm, it is typically not feasible to find a data augmentation such that step 2 or step 3 of Algorithm \nameref{alg:Alt} completely breaks the dependence in the chain --- this would require finding a DA such that the model parameter and the DA are essentially independent which, in turn, would likely mean that drawing from the conditional posterior of the parameter given the DA is nearly as difficult as drawing from the marginal posterior of the model parameter.

The particular method of interweaving discussed above is called a GIS or a {\it global} interweaving strategy since interweaving occurs globally across the entire parameter vector. It is possible to define a {\it componentwise} interweaving strategy (CIS) that interweaves within specific steps of a Gibbs sampler as well. A CIS algorithm for $\phi=(\phi_1, \phi_2)$ essentially employs interweaving for each block of $\phi$ separately, e.g.
\begin{alg*}[CIS]Componentwise Interweaving Strategy\label{alg:CIS}\\
  \begin{center}
    \begin{tabular}{llllll}
      $[\theta_1|\phi_1^{(k)},\phi_2^{(k)}]$ & $\to$  & $[\gamma_1|\phi_2^{(k)},\theta_1]$ & $\to$ & $[\phi_1^{(k+1)}|\phi_2^{(k)},\gamma_1]$ &$\to$ \\
      $[\theta_2|\phi_1^{(k+1)},\phi_2^{(k)},\gamma_1]$ &$\to$ & $[\gamma_2|\phi_1^{(k+1)},\theta_2]$ & $\to$ & $[\phi_2^{(k+1)}|\phi_1^{(k+1)},\gamma_2]$ &
    \end{tabular}
  \end{center}
\noindent \end{alg*}
where $\theta_i$ and $\gamma_i$ are distinct data augmentations for $i=1$ and $i=2$, but potentially $\gamma_1=\theta_2$  or $\gamma_2=\theta_1$. The first line draws $\phi_1$ conditional on $\phi_2$ using interweaving in a Gibbs step, while the second line does the same for $\phi_2$ conditional on $\phi_1$. The algorithm can easily be extended to greater than two blocks within $\phi$. The main attraction of CIS is that it is often easier to find an AA--SA pair of DAs for $\phi_1$ conditional on $\phi_2$ and another pair for $\phi_2$ conditional on $\phi_1$ than it is to find and AA--SA pair for $\phi=(\phi_1,\phi_2)$ jointly. 

Most of the work on constructing and using DAs has focused on multilevel models --- e.g. \citeasnoun{van2001art} and \citeasnoun{papaspiliopoulos2007general}, but relatively little attention has been paid to time series models despite strong similarities between some time series models and the hierarchical models typically studied. We seek to improve DA schemes in a particular class of models --- linear, Gaussian statespace models, a.k.a. dynamic linear models (DLMs). Most of the existing literature focuses on non-Gaussian statespace models --- in particular the stochastic volatility model (see \citeasnoun{shephard1996statistical} for a summary), but few directly work with the class of DLMs we consider. In \citeasnoun{pitt1999analytic}, the authors analytically study convergence in the AR(1) plus noise model, but assume the observation and system variances are constant throughout. \citeasnoun{strickland2008parameterisation} considers reparameterization of the stochastic volatility and stochastic conditional duration models. \citeasnoun{fruhwirth2008heston} also considers reparameterizations of the stochastic volatility model while \citeasnoun{kastner2013ancillarity} applies ASIS in order to estimate the model. \citeasnoun{bos2006inference} consider a class of DLMs where the variances are time-dependent and follow a stochastic volatility process and show how a reparameterization can improve MCMC estimation. In the non-Gaussian Ornstein--Uhlenbeck stochastic volatility process, \citeasnoun{roberts2004bayesian} explores several alternate parameterizations. \citeasnoun{fruhwirth2003bayesian} directly applies several reparameterization techniques to a particular DLM -- a dynamic regression model with stationary AR(1) regression coefficient-- but focuses on estimation of the regression coefficient process.

The rest of the paper is organized as follows. In Section \ref{sec:DLM} we introduce the dynamic linear model, discuss the subclass of DLMs we consider, and explore some of the key properties of the model. Section \ref{sec:DAs} explores several possible DAs for our class of DLMs, including several new DAs, and shows that any SA for the DLM is likely to be difficult to use. Section \ref{sec:Algs} discusses the various MCMC strategies available for the DLM, including several DA algorithms, alternating algorithms, and interweaving algorithms. Section \ref{sec:LLM} applies these algorithms to a particular DLM --- the local level model --- and discusses some interesting problems which arise during the construction of these algorithms before using a simulation to empirically examine how well various algorithms perform across different regions of the parameter space. Finally, Section \ref{sec:Discuss} discusses these results and what they might mean for more general DLMs.

\section{Dynamic linear models} \label{sec:DLM} 

The general dynamic linear model is well studied \cite{harrison1999bayesian,petris2009dynamic,prado2010time} and is defined as
\begin{align}
y_t &= F_t\theta_t + v_t && v_t \stackrel{ind}{\sim} N_k(0,V_t) && (\mbox{observation equation}) \label{dlmtdobseq}\\
 \theta_t &= G_t\theta_{t-1} + w_t && w_t \stackrel{ind}{\sim} N_p(0,W_t) && (\mbox{system equation}) \label{dlmtdsyseq}
\end{align}
where $N_d(\mu,\Sigma)$ is a $d$-dimensional multivariate normal distribution with mean $\mu$ and covariance $\Sigma$ and the observation errors, $v_{1:T}$, and system disturbances, $w_{1:T}$, are assumed independent. The observed data is $y_{1:T} = (y_1',y_2,\cdots y_T')'$ while $\theta_{0:T}=(\theta_0',\theta_1',\theta_2',\cdots \theta_T')'$ is called the latent states and is the usual DA for this model. However, we will treat $\theta_0$ as a model parameter and $\theta_{1:T}$ as the DA. For each $t=1,2,\cdots,T$, $F_t$ is a $k\times p$ matrix and $G_t$ is a $p\times p$ matrix. Let $\phi$ denote the vector of unknown parameters in the model. Then possibly $F_{t}$, $G_{t}$, $V_{t}$, and $W_{t}$ are all functions of $\phi$ for $t=1,2,\cdots,T$. 

The subclass of DLMs we will focus on sets $V_t=V$ and $W_t=W$ and treats $F_{t}$ and $G_{t}$ as known for all $t$. Our results can be extended when $V_t$ or $W_t$ is time-varying or when $F_t$ or $G_t$ depend on unknown parameters, but we ignore those cases for simplicity. When $\phi=(\theta_0,V,W)$ is our unknown parameter vector and we can write the model as
\begin{align}
  y_t|\theta_{0:T},V,W \stackrel{ind}{\sim} & N(F_t\theta_t,V) &
  \theta_t|\theta_{0:t-1},V,W  \sim & N(G_t\theta_{t-1},W) \label{dlmbotheqs}
\end{align}
for $t=1,2,\cdots T$. To complete the model specification in a Bayesian context, we need priors on $\theta_0$, $V$, and $W$. We will use the standard conditionally conjugate approach and assume that they are mutually independent a priori and that $\theta_0 \sim N(m_0, C_0)$, $V \sim IW(\Lambda_V, \lambda_V)$ and $W \sim IW(\Lambda_W, \lambda_W)$ where $m_0$, $C_0$, $\Lambda_V$, $\lambda_V$, $\Lambda_W$, and $\lambda_W$ are known hyperparameters and $IW(\Lambda, \lambda)$ denotes the inverse Wishart distribution with degrees of freedom $\lambda$ and positive definite scale matrix $\Lambda$. Then we can write the full joint distribution of $(V,W,\theta_{0:T},y_{1:T})$ is
\begin{align}
  p(&V,W,\theta_{0:T},y_{1:T}) \propto \exp\left[-\frac{1}{2}(\theta_0-m_0)'C_0^{-1}(\theta_0-m_0)\right] \nonumber\\
  &\times   |V|^{-(\lambda_V + k + T + 2)/2}\exp\left[-\frac{1}{2}\tr\left(\Lambda_VV^{-1}\right)\right] \exp\left[-\frac{1}{2}\sum_{t=1}^T(y_t - F_t\theta_t)'V^{-1}(y_t - F_t\theta_t)\right] \nonumber\\
   & \times |W|^{-(\lambda_W + p + T + 2)/2}\exp\left[-\frac{1}{2}\tr\left(\Lambda_WW^{-1}\right)\right]\exp\left[-\frac{1}{2}\sum_{t=1}^T(\theta_t-G_t\theta_{t-1})'W^{-1}(\theta_t-G_t\theta_{t-1})\right]\label{dlmjoint}
 \end{align}
where $\tr(.)$ is the matrix trace operator.

From equation \eqref{dlmbotheqs} we can rewrite the model by recursive substitution:
\begin{align*}
  y_t &= v_t + F_t\left(w_t + G_tw_{t-1} + G_tG_{t-1}w_{t-2} + ... + G_tG_{t-1}\cdots G_{2}w_1 + G_tG_{t-1}\cdots G_1\theta_0\right).
\end{align*}
Here we see that $\theta_0$ is given a special status relative to the other elements of the data augmentation which helps motivate treating it as a model parameter rather than part of the DA. Now each $y_t$ is a linear combination of normal random variables conditional on $\phi=(\theta_0,V,W)$, so after marginalizing out $\theta_{1:T}$, $y_{1:T}$ has a normal distribution such that
\begin{align*}
  \mathrm{E}[y_t|\phi] =  F_t\left[\prod_{s=t}^1G_s\right]\theta_0,\qquad
  \mathrm{Var}[y_t|\phi] =  V + F_tH_tWH_t'F_t',\qquad
  \mathrm{Cov}[y_s,y_t|\phi] = F_sH_sWH_t'F_t'
\end{align*}
where $\prod_{s=t}^1G_s = G_tG_{t-1}\cdots G_1$ and $H_t = I_p + G_t + G_tG_{t-1} + \cdots + G_tG_{t-1}\cdots G_2$. Next define $D_t = F_tG_tG_{t-1}\cdots G_1$. Then let
\begin{align*}
D_{Tp\times Tk} &= \begin{bmatrix} 
D_1 & 0 & \ddots & 0\\
0 & D_2 & \ddots & 0\\
\ddots & \ddots & \ddots & \ddots\\
0 & 0 & \ddots & D_T 
\end{bmatrix}, &
\tilde{V}_{Tk\times Tk} & = \begin{bmatrix} 
V & 0 & \ddots & 0\\
0 & V & \ddots & 0\\
\ddots & \ddots & \ddots & \ddots\\
0 & 0 & \ddots & V 
\end{bmatrix},
\intertext{ }
\mu_{Tp\times 1} &= \begin{bmatrix} \theta_0 \\ \theta_0 \\ \vdots \\ \theta_0\end{bmatrix}, & \tilde{W}_{Tp\times Tp} &= \begin{bmatrix} F_1H_1 \\ F_2H_2 \\ \vdots \\ F_TH_T \end{bmatrix} W \begin{bmatrix} H_1'F_1' & H_2'F_2' & \hdots H_T'F_T' \end{bmatrix}.
\end{align*} 
Now we have the data model for $y_{1:T}$ without any data augmentation:
\begin{align}
  y_{1:T} \stackrel{ind}{\sim} N_{k}(D\mu, \tilde{V} + \tilde{W}) \label{margmodel}
\end{align}
for $t=1,2,\cdots,T$. Given a prior $p(\phi)$, the posterior density we are interested in is $p(\phi|y_{1:T})\propto p(y_{1:T}|\phi)p(\phi)$.

Equation \eqref{dlmbotheqs} motivates a strong analogy with a commonly studied hierarchical model:
\begin{align*}
  y_{ij}|\beta_{1:J} \stackrel{ind}{\sim} & N(X_{ij}\beta_j,V) &
  \beta_j \stackrel{ind}{\sim} & N(Z_j\lambda,W)
\end{align*}
for $i=1,2,\cdots,I_j$ and $j=1,2,\cdots,J$. Here, $ij$ indicates observation $i$ within group $j$. The response vector $y_{ij}$ is related to the matrix of covariates $X_{ij}$ through the group-specific regression coefficient $\beta_j$ while the group specific regression coefficient is related to the group-level matrix of covariates $Z_j$ through the group level regression coefficient $\lambda$. There are three key differences between this model and the class of DLMs we consider. First, in the DLM $I_j=1$ for $j=1,2,\cdots J$ so that each observation comes from its own group. Second, the $y_{1j}$'s are no longer exchangeable and instead exhibit a temporal ordering. Finally, the $\beta_j$'s are given a special kind of dependence by forcing the mean of the distribution of $\beta_j$ to depend on $\beta_{j-1}$ instead of $\lambda$, where we define $\beta_0=\lambda$. This combined with equation \eqref{margmodel} helps motiviate our decision to treat $\theta_0$ as a model parameter rather than part of the DA --- it is analogous to the top level mean parameter in a hierarchical regression model and in addition $\theta_0$ requires its own prior distribution rather than having an implicit prior in the construction of the model, like $\theta_{1:T}$ in the DLM or $\beta_{1:J}$ is the hierarchical model.

\section{Augmenting the DLM}\label{sec:DAs}
The latent states $\theta_{1:T}$ defined in the definition of the DLM form the usual DA for use in DA algorithms to estimate the model. The only restriction on any given DA is that the joint posterior of the model parameter and the DA is such that if we integrate out the DA, we obtain the desired marginal posterior for the parameter. This leaves wide range of possibilities for alternate DAs to use the the MCMC sampling algorithm, as long as the resulting full conditional distributions of the DA and the model parameter are both easy to sample from. We will explore several alternatives found through manipulating $\theta_{0:T}$ in intuitive ways. The purpose of these constructions is primarily to use as grist for the interweaving mill, but each new DA will also implicitly define a new base DA algorithm.

\subsection{The scaled disturbances}\label{sec:DAs:dist}

The next step is to apply the ideas of interweaving to sampling from the posterior of the dynamic linear model. \citeasnoun{papaspiliopoulos2007general} note that typically the usual parameterization results in an SA for the parameter $\phi$. All that would be necessary for an ASIS algorithm, then, is to construct an AA for $\phi$. We immediately run into a problem because the standard DA for a DLM is the latent states $\theta_{0:T}$. From equation \eqref{dlmbotheqs} and \eqref{dlmbotheqs} we see that $V$ is in the observation equation so that $\theta_{0:T}$ is not an SA for $(V,W)$ while $W$ is in the system equation so that $\theta_{0:T}$ is not an AA for $(V,W)$ either. In order to find an SA we need to somehow move $V$ from the observation equation to the system equation while leaving $W$ in the system equation. We also need to find an AA by somehow moving $W$ from the system equation to the observation equation while leaving $V$ in the observation equation. A naive thing to try is to condition on the disturbances instead of the states and see if the disturbances for an SA or an AA for $(V,W)$. The disturbances $w_{0:T}$ are defined by $w_t = \theta_t - G_t\theta_{t-1}$ for $t=1,,2,\cdots,T$ and and $w_0=\theta_0$. However it is easy to see that the conditional distributions $p(V,W|\theta_{0:T},y_{1:T})$ and $p(V,W|w_{0:T},y_{1:T})$ are identical (we omit these details) so the DA algorithm based on the $w_t$'s is identical to the algorithm based on the $\theta_t$'s.

\citeasnoun{papaspiliopoulos2007general} suggest that in order to obtain an ancillary augmentation for a variance parameter, we must center the sufficient augmentation and scale it  by the square root of that parameter. Based on this intuition, note that if we hold $V$ constant then $\theta_{0:T}$ is an SA for $W$ from equation \eqref{dlmbotheqs}, i.e. we say $\theta_{0:T}$ is an SA for $W$ given $V$, or for $W|V$. Similarly $\theta_{0:T}$ is an AA for $V|W$. This suggests that if we center and scale $\theta_{t}$ by $W$ appropriately for all $t$ we'll have an ancillary augmentation for $V$ and $W$ jointly. In fact this follows \citeasnoun{papaspiliopoulos2007general}'s suggestion to construct a pivotal quantity in order to find an ancillary augmentation. The upshot is that we need to appropriately scale the disturbances, $w_t = \theta_t - G_t\theta_{t-1}$, to create the scaled disturbances (SDs).

In the general DLM, the disturbances are vectors so to define the scaled disturbances let $L_W$ denote the Cholesky decomposition of $W$, i.e. the lower triangle matrix $L_W$ such that $L_WL_W' =W$. Then we will define the scaled disturbances $\gamma_{0:T}$ by $\gamma_0=\theta_0$ and $\gamma_t = L_W^{-1}(\theta_t-G_t\theta_{t-1})$ for $t=1,2,\cdots,T$. There are actually $p!$ different versions of the scaled disturbances depending on how we order the elements of $\theta_t$, as \citeasnoun{meng1998fast} note for EM algorithms in a different class of models. We will sidestep the issue of the best ordering of the latent states. No matter which ordering is chosen, we can confirm our intuition that the scaled disturbances are an AA for $V$ and $W$ jointly. The reverse transformation is defined recursively by $\theta_0=\gamma_0$ and $\theta_t=L_W\gamma_t + G_t\theta_{t-1}$ for $t=1,2,\cdots,T$. Then the Jacobian is block lower triangular with the identity matrix and $T$ copies of $L_W$ along the diagonal blocks, so $|J| = |L_W|^T=|W|^{T/2}$. Then from equation \eqref{dlmjoint} we can write the full joint distribution of $(V,W,\gamma_{0:T},y_{1:T})$ as
 \begin{align}
  p(&V,W,\gamma_{0:T},y_{1:T}) \propto \exp\left[-\frac{1}{2}(\gamma_0-m_0)'C_0^{-1}(\gamma_0-m_0)\right] \exp\left[-\frac{1}{2}\gamma_t'\gamma_t\right] \nonumber\\
  &\times |W|^{-(\lambda_W + p + T + 2)/2} |V|^{-(\lambda_V + k + T + 2)/2} \exp\left[-\frac{1}{2}tr\left(\Lambda_WW^{-1}\right)\right]  \nonumber\\
  &\times \exp\left[-\frac{1}{2}\left(tr\left(\Lambda_VV^{-1}\right) + \sum_{t=1}^T\left[y_t-F_t\theta_t(\gamma_{0:T},W)\right]'V^{-1}\left[y_t-F_t\theta_t(\gamma_{0:T},W)\right]\right)\right] \label{dlmdistjoint}
 \end{align}
where $\theta_t(\gamma_{0:T},W)$ denotes the recursive back transformation defined by the scaled disturbances. So ultimately under the scaled disturbance parameterization we can write the model as
\begin{align}
  y_t|\gamma_{0:T},V,W & \stackrel{ind}{\sim} N\left(F_t\theta_t(\gamma_{0:T},W), V\right)\nonumber\\
  \gamma_t & \stackrel{iid}{\sim}N(0,I_p) \label{dlmdistmodel}
\end{align}
for $t=1,2,\cdots,T$ where $I_p$ is the $p\times p$ identity matrix. Neither $V$ nor $W$ are in the system equation so the scaled disturbances are an AA for $(V,W)$. This parameterization is well known, e.g. \citeasnoun{fruhwirth2004efficient} use it in a dynamic regression model with stationary regression coefficient and the disturbance smoother of \citeasnoun{koopman1993disturbance} finds the conditional posterior of the scaled disturbances given the model parameters and the data. 

\subsection{The scaled errors}\label{sec:DAs:error}
The scaled disturbances immediately suggest an analogous augmentation using the scaled errors (SEs), i.e. $v_t=y_t - F_t\theta_t$ appropriately scaled by observation level covariance matrix $V$. Let $L_V$ denote the Cholesky decomposition of $V$, that is $L_VL_V'=V$, then we can define a version of the scaled errors (this time depending on how we order the elements of the vector $y_t$) as $\psi_t = L_V^{-1}(y_t - F_t\theta_t)$ for $t=1,2,\cdots,T$ and $\psi_0 = \theta_0$. 

It is not straightforward to write down the model in terms of $\psi_{0:T}$ instead of $\theta_{0:T}$ and determine $p(\psi_{0:T}|V,W)$ in general. When $dim(y_t)=k=p=dim(\theta_t)$, $F_t$ is $p\times p$ and is invertible for $t=1,2,\cdots,T$, $\psi_{0:T}$ is a one-to-one transformation of $\theta_{0:T}$ and the problem is easier. This restriction is not necessary --- $\theta_t$, $y_t$ or both could be augmented in order to construct an $\tilde{F}_t$ which is square and invertible using a more complicated data augmentation scheme, but we pass over this issue until the discussion section (Section \ref{sec:Discuss:F}) and assume that $F_t$ is $k\times k$ and invertible from now on. Given this assumption, $\theta_t = F_t^{-1}(y_t - L_V\psi_t)$ for $t=1,2,\cdots,T$ while $\theta_0=\psi_0$. The Jacobian of this transformation is block diagonal with a single copy of the identity matrix and the $F_t^{-1}L_V$'s along the diagonal, so $|J|=(\prod_{t=1}^T|F_t|^{-1})|V|^{T/2}$. Then from equation \eqref{dlmjoint} we can write the joint distribution of $(V, W, \psi_{0:T}, y_{1:T})$ as
\begin{align}
    p(&V,W,\psi_{0:T},y_{1:T}) \propto \exp\left[-\frac{1}{2}(\psi_0-m_0)'C_0^{-1}(\psi_0-m_0)\right] \exp\left[-\frac{1}{2}\sum_{t=1}^T\psi_t'\psi_t\right] \nonumber\\
  &\times |V|^{-(\lambda_V + p + 2)/2}\exp\left[-\frac{1}{2}tr\left(\Lambda_VV^{-1}\right)\right]  \times |W|^{-(\lambda_W + p + T + 2)/2} \nonumber\\
   & \exp\left[-\frac{1}{2}\left(tr\left(\Lambda_WW^{-1}\right) + (y_t - \mu_t)'(F_tWF_t')^{-1}(y_t-\mu_t)\right)\right]\label{dlmerrorjoint}
\end{align}
where we define $\mu_1 = L_V\psi_1 + F_1G_1\psi_0$ and for $t=2,3,\cdots,T$, $\mu_t =L_V\psi_t + F_tG_tF_{t-1}^{-1}(y_{t-1} - L_{V}\psi_{t-1})$. The $|F_t|^{-1}$'s have been absorbed into the normalizing constant, but if the $F_t$'s depended on some unknown parameter then we could not do this and as a result would have to take them into account in the Gibbs step for that parameter. Now we can write the model in terms of the scaled error parameterization:
\begin{align*}
  y_t|V,W,\psi_{0:T},y_{1:t-1} &\sim N(\mu_t, F_tWF_t')\\
  \psi_t & \stackrel{iid}{\sim} N(0,I_k)
\end{align*}
for $t=1,2,\cdots,T$ where $I_k$ is the $k\times k$ identity matrix. Now we see immediately that the scaled errors are also an AA for $(V,W)$ since neither $V$ nor $W$ are in the system equation of this model. However, both $V$ and $W$ are in the observation equation so that $\psi_{0:T}$ is not an SA for $(V,W)$ or for either covariance matrix conditional on the other.

\subsection{The ``wrongly-scaled'' DAs}
We can, however, find a couple more useful DAs to use as grist for the interweaving mill. The scaled disturbances are defined by $\gamma_t = L_W^{-1}(\theta_t - G_t\theta_{t-1})$  and the scaled errors are defined by $\psi_t = L_V^{-1}(y_t - \theta_t)$ for $t=1,2,\cdots,T$ where $L_WL_W' = W$ and $L_VL_V' = V$. Now define $\tilde{\gamma}_t=L_V^{-1}(\theta_t - G_t\theta_{t-1})$ and $\tilde{\psi}_t=L_W^{-1}(y_t - \theta_t)$ for $t=1,2,\cdots,T$ and $\tilde{\psi}_0=\tilde{\gamma}_0=\theta_0$. In other words, the ``tilde'' versions of the scaled disturbances and the scaled errors are scaled by the ``wrong'' Cholesky decomposition, hence we call them the wrongly-scaled disturbances (W-SDs) and the wrongly-scaled errors (W-SEs) respectively. 

First consider the wrongly-scaled disturbances, i.e. $\tilde{\gamma}_t = L_V^{-1}L_W\gamma_t= L_V^{-1}(\theta_t-G_t\theta_{t-1})$ for $t=1,2,\cdots,T$ and $\tilde{\gamma_0}=\gamma_0=\theta_0$. The reverse transformation is $\gamma_t = L_W^{-1}L_V\tilde{\gamma}_t$ and the Jacobian is block diagonal with $L_W^{-1}L_V$ along the diagonal. Thus $|J|=|L_W|^{-T}|L_V|^T=|W|^{-T/2}|V|^{T/2}$. Then from equation \eqref{dlmdistjoint} we can write the joint distribution of $(V,W,\tilde{\gamma}_{0:T},y_{1:T})$ as
 \begin{align}
  p(&V,W,\tilde{\gamma}_{0:T},y_{1:T}) \propto \exp\left[-\frac{1}{2}(\tilde{\gamma}_0-m_0)'C_0^{-1}(\tilde{\gamma}_0-m_0)\right] |V|^{-(\lambda_V + p + 2)/2}\exp\left[-\frac{1}{2}tr\left(\Lambda_VV^{-1}\right)\right]  \nonumber\\
  &\times  \exp\left[-\frac{1}{2}\sum_{t=1}^T\left(y_t - F_t\theta_t(\tilde{\gamma}_{0:T},L_V)\right)'V^{-1}\left(y_t - F_t\theta_t(\tilde{\gamma}_{0:T},L_V)\right)\right]\nonumber\\
   & \times |W|^{-(\lambda_W + p + T + 2)/2}\exp\left[-\frac{1}{2}tr\left(\Lambda_WW^{-1}\right)\right] \exp\left[-\frac{1}{2}\sum_{t=1}^T\tilde{\gamma}_t'(L_V^{-1}W(L_V^{-1})')^{-1}\tilde{\gamma}_t\right]\label{dlmdisttildejoint}
 \end{align}
where $\theta_t(\tilde{\gamma}_{0:T},L_V)$ denotes the transformation from $\tilde{\gamma}_{0:T}$ to $\theta_{0:T}$ defined by the wrongly-scaled disturbances. Then under $\tilde{\gamma}_{0:T}$ we can write the model as
\begin{align*}
  y_t|\tilde{\gamma}_{0:T},V,W & \stackrel{ind}{\sim} N\left(F_t\theta_t(\tilde{\gamma}_{0:T},L_V), V\right)\\
  \tilde{\gamma}_t & \stackrel{ind}{\sim}N(0,L_V^{-1}W(L_V^{-1})')
\end{align*}
for $t=1,2,\cdots,T$. Since $L_V$ is the Cholesky decomposition of $V$, the observation equation does not contain $W$. So $\tilde{\gamma}_{0:T}$ is an SA for $W|V$. Note also that since $W$ and $L_V$ are both in the system equation, $\tilde{\gamma}_{0:T}$ is not an AA for $V|W$ nor for $W|V$. 

Now consider the wrongly-scaled errors, i.e. $\tilde{\psi}_t=L_W^{-1}L_V\psi_t=L_W^{-1}(y_t - \theta_t)$ for $t=1,2,\cdots,T$ and $\tilde{\psi}_0=\psi_0=\theta_0$. Then $\psi_t = L_V^{-1}L_W\tilde{\psi}_t$ and the Jacobian is block diagonal with $L_V^{-1}L_W$ along the diagonal. So $|J|=|V|^{-T/2}|W|^{T/2}$ and from equation \eqref{dlmerrorjoint} we can write the joint distribution of $(V, W, \tilde{\psi}_{0:T}, y_{1:T})$ as
\begin{align}
    p(&V,W,\tilde{\psi}_{0:T},y_{1:T}) \propto \exp\left[-\frac{1}{2}(\tilde{\psi}_0-m_0)'C_0^{-1}(\tilde{\psi}_0-m_0)\right] \nonumber\\
   &\times |V|^{-(\lambda_V + p + T + 2)/2}\exp\left[-\frac{1}{2}tr\left(\Lambda_VV^{-1}\right)\right] \exp\left[-\frac{1}{2}\sum_{t=1}^T\tilde{\psi}_t'(L_W^{-1}V(L_W^{-1})')^{-1}\tilde{\psi}_t\right] \nonumber\\
    & \times |W|^{-(\lambda_W + p + 2)/2}\exp\left[-\frac{1}{2}tr\left(\Lambda_WW^{-1}\right)\right]\exp\left[-\frac{1}{2}\sum_{t=1}^T(y_t - \tilde{\mu}_t)'(F_tWF_t')^{-1}(y_t-\tilde{\mu}_t)\right]\label{dlmerrortildejoint}
 \end{align}
where we define $\tilde{\mu}_1 = L_W\tilde{\psi}_1 - F_1G_1\tilde{\psi_0}$ and for $t=2,3,\cdots,T$ $\tilde{\mu}_t =L_W\tilde{\psi}_t - F_tG_tF_{t-1}^{-1}(y_{t-1} - L_{W}\tilde{\psi}_{t-1})$ In terms of $\tilde{\psi}_{0:T}$, the model is then:
 \begin{align*}
   y_t|V,W,\tilde{\psi}_{0:T},y_{1:t-1} &\sim N(\tilde{\mu}_t, F_tWF_t')\\
   \tilde{\psi}_t & \stackrel{iid}{\sim} N(0,L_W^{-1}V(L_W^{-1})')
\end{align*}
for $t=1,2,\cdots,T$. Since $\tilde{\mu}_t$ only depends on $W$ (through $L_W$) and not on $V$, $V$ is absent from the observation equation. Thus $\tilde{\psi}_{0:T}$ is an SA for $V|W$. Once again, since both $W$ and $V$ are in the system equation $\tilde{\psi}_{0:T}$ is not an AA for either $V$ or $W$.

\subsection{The elusive search for a sufficient augmentation}

Having found two ancillary augmentations for the DLM, we would like to find a sufficient augmentation in order to construct an ASIS for sampling from the posterior distribution. It turns out that this is no easy task. The following lemma clarifies just where the difficulty lies.

\begin{lem}\label{noSA}
Suppose $\eta$ is an SA for the DLM such that conditional on $\phi$, $\eta$ and $y$ are joint normally distributed, that is 
\begin{align*}
 \left. \begin{bmatrix}\eta \\ y \end{bmatrix}\right|\phi \sim N\left(\begin{bmatrix} \alpha_\eta \\ D\mu \end{bmatrix}, \begin{bmatrix} 
   \Omega_\eta & \Omega_{y,\eta}' \\
   \Omega_{y,\eta} & \tilde{V} + \tilde{W} \end{bmatrix}\right).
\end{align*}
Then $\tilde{\eta}=\Omega_{y,\eta}'\Omega_{\eta}^{-1}\eta$ is also an SA and
\[
\tilde{\eta}|\phi \sim N(D\mu,\tilde{V} + \tilde{W} - \Sigma)
\]
where $\Sigma=\Omega_{y,\eta}'\Omega_{\eta}^{-1}\Omega_{y,\eta}$, $\tilde{V} + \tilde{W} - \Sigma$ is functionally independent of $\phi$, and conditional posterior of $\phi$ given $\tilde{\eta}$ can be written as
\[
p(\phi|\tilde{\eta},y) \propto p(\phi)\propto |\tilde{V} + \tilde{W} - \Sigma|^{-1/2}\exp\left[-\frac{1}{2}(\tilde{\eta} - D\mu + b)'(\tilde{V} + \tilde{W} - \Sigma)^{-1}(\tilde{\eta} - D\mu + b)\right].
\]
\end{lem}
To prove this lemma, first the normality assumption implies
\begin{align*}
  y|\eta,\phi &\sim N(D\mu + \Omega_{y,\eta}'\Omega_\eta^{-1}(\eta - \alpha_\eta), \tilde{V} + \tilde{W} - \Omega_{y,\eta}'\Omega_{\eta}^{-1}\Omega_{y,\eta})\\
  \eta|\phi &\sim N(\alpha_\eta, \Omega_\eta).
\end{align*}
Now for $\eta$ to be a sufficient augmentation we need $D\mu + \Omega_{y,\eta}'\Omega_\eta^{-1}(\eta - \alpha_\eta)$ and $\tilde{V} + \tilde{W} - \Omega_{y,\eta}'\Omega_{\eta}^{-1}\Omega_{y,\eta}$
to be independent of $\phi$. This requires that
\begin{align*}
  D\mu - \Omega_{y,\eta}'\Omega_\eta^{-1}\alpha_\eta + \Omega_{y,\eta}'\Omega_\eta^{-1}\eta  = b + A\eta
\end{align*}
where $A=\Omega_{y,\eta}'\Omega_\eta^{-1}$ and $b=D\mu - A\alpha_\eta$ must both be free of $\phi$. This also implies that $A\alpha_\eta = D\mu - b$.

Then using the second equation, we now require $\Sigma = \tilde{V} + \tilde{W} - A\Omega_{\eta}A'$ free of $\phi$ which in turn implies that $\Omega_{\eta,y}$ must not be the zero matrix. This gives $A\Omega_{\eta}A' = \tilde{V} + \tilde{W} - \Sigma$. Consider $\tilde{\eta}=A\eta$, which is also a sufficient augmentation since it is just a linear transformation by a constant matrix. Then we have
\begin{align*}
y|\tilde{\eta},\phi & \sim N(b + \tilde{\eta}, \Sigma)\\
\tilde{\eta}|\phi & \sim N(D\mu - b, \tilde{V} + \tilde{W} - \Sigma)
\end{align*}
with $b$ and $\Sigma$ free of $\phi$. Thus the posterior density of $\phi$ given $\tilde{\eta}$ can be written as
\begin{align*}
  p(\phi|\tilde{\eta}, y) &\propto p(y|\tilde{\eta},\phi)p(\tilde{\eta}|\phi)p(\phi) \propto p(\tilde{\eta}|\phi)p(\phi) \\
&\propto |\tilde{V} + \tilde{W} - \Sigma|^{-1/2}\exp\left[-\frac{1}{2}(\tilde{\eta} - D\mu + b)'(\tilde{V} + \tilde{W} - \Sigma)^{-1}(\tilde{\eta} - D\mu + b)\right]. \qed
\end{align*}
The posterior desity we wish to sample from is similar to $p(\phi|\tilde{\eta},y)$, except it has $\Sigma$ equal to the zero matrix and $b$ equal to the zero vector. Using $\eta$ instead of $\tilde{\eta}$ will not result in a simpler density $p(\phi|\eta,y)$. This conditional posterior can be written as
\begin{align*}
p(\phi|\eta,y) &\propto p(\phi) |\Omega_{\eta}|^{-1/2}\exp\left[-\frac{1}{2}(\eta - \alpha_{\eta})'(\Omega_{\eta})^{-1}(\eta - \alpha_{\eta})\right]\\
p(\phi|\eta,y) &\propto p(\phi) |A(\tilde{V} + \tilde{W} - \Sigma)A'|^{-1/2}\exp\left[-\frac{1}{2}(A\eta - D\mu + b)'A[A(\tilde{V} + \tilde{W} - \Sigma)A']^{-1}A'(A\eta - D\mu + b)\right]\\
\end{align*}
where again $A$, $\Sigma$ and $b$ are free of $\phi$. This density is even more complicated than $p(\phi|\tilde{\eta},y)$ unless $A=\Omega_{\eta,y}'\Omega_\eta^{-1}$ is invertible, in which case they are the same density. The upshot is that once we find an SA, in order to use it we must obtain draws from a density that appears just as hard to sample from as the posterior density we are already trying to approximate.

Lemma \ref{noSA} does not quite rule out the existence of a useful SA --- in particular relaxing the joint normality assumption might yield something worthwhile --- but the lemma does suggest that it will be difficult to find one. This result brings to mind \citeasnoun{van2001art}'s contention that there is an art to constructing data augmentation algorithms --- our goal is not only to find an MCMC algorithm that has nice convergence and mixing properties, but also one that is easy to implement. This second criteria is much more difficult to quantify. 

The problem we run into is unlikely to be unique to the time series setting but rather seems driven by trying to find an SA for a pair of variances, one on the data level and the other on the latent data level. For example, in a hierarchical model we expect there to be similar problems finding an SA when both the observational and hierarchical variance are unknown. There is a similar problem while trying to find two data augmentations that are independent in the posterior which, by \citeasnoun{yu2011center}'s Theorem 1, would guarantee an interweaving algorithm that yields iid draws from the posterior distribution of the model parameters. We omit the details, but unsurprisingly after making similar assumptions about the nature of the DAs in the DLM, the conditional posterior of $\phi$ ends of being either identical to or just as complicated as the marginal posterior of $\phi$. We also expect this problem to carry over to hierarchical models.

\section{MCMC Strategies for the DLM}\label{sec:Algs}

\subsection{Base algorithms}\label{sec:Algs:base}
Using any of the DAs introduced in Section \ref{sec:DAs}, we can construct several DA algorithms (Algorithm \nameref{alg:DA}), which we call {\it base algorithms}. A well known method to estimate the parameters in a DLM uses the DA algorithm using the latent states $\theta_{0:T}$ as the DA \cite{fruhwirth1994data,carter1994gibbs}. We are calling this algorithm the {\it state sampler}. In order to construct this algorithm, we need two pieces --- the conditional posterior of $V$ and $W$ given $\theta_{0:T}$ and the conditional posterior of $\theta_{0:T}$ given $V$ and $W$. The density $p(\theta_{0:T}|V,W,y_{1:T})$ is multivariate normal, and any algorithm that obtains a random draw from it is called a simulation smoother in the literature. One commonly used simulation smoother is the forward filtering, backward sampling algorithm (FFBS) \cite{fruhwirth1994data,carter1994gibbs} which uses the Kalman filter, but there are several alternatives including \citeasnoun{koopman1993disturbance} and \citeasnoun{de1995simulation}. The smoothers introduced in \citeasnoun{mccausland2011simulation} and \citeasnoun{rue2001fast}, dubbed ``all without a loop'' smoothing (AWOL) by \citeasnoun{kastner2013ancillarity} are particularly efficient. Both methods exploit the tridiagonal structure of the precision matrix of the joint normal distribution for $\theta_{0:T}$ in order to speed up matrix computations. 

The method of \citeasnoun{rue2001fast} exploits this structure in order to quickly compute a Cholesky decomposition of the precision matrix and as a result is also called the Cholesky factor algorithm (CFA). \citeasnoun{mccausland2011simulation}, on the other hand, exploits this structure in order to break up the random draw from $p(\theta_{0:T}|V,W,y_{1:T})$ into $T+1$ steps. The tridiagonal precision matrix ensures that $p(\theta_{t}|\theta_{t+1:T},V,W,y_{1:T}) = p(\theta_{t}|\theta_{t+1},V,W,y_{1:T})$ for $t=0,1,\cdots,T-1$. Then the algorithm initializes with a draw from $p(\theta_T|V,W,y_{1:T})$, then draws recursively from $p(\theta_{t}|\theta_{t+1:T}|V,W,y_{1:T})$ for $t=T-1,T-2,\cdots,0$. In effect, this algorithm takes the Cholesky decomposition and simulation steps of the CFA algorithm and mixes their sub-steps together.  As a result, we call this the mixed Cholesky factor algorithm (MCFA). The upshot for computational efficiency is that instead of working with a $(T+1)p\times (T+1)p$ precision matrix the MCFA works with $T+1$ distinct $p\times p$ precision matricies which often, but not always, speeds up the computation relative to the CFA \cite{mccausland2011simulation}. We omit the details of this algorithm in the context of the DLM, but they can be found in the supplementary materials.

\jarad{Maybe we need a better name for the MCFA. The original authors didn't name the algorithm and just want to refer to it with MMP, which is the first letters of each of their last names, but I'd like an intuitive name that points out the connection to and differences from the CFA algorithm.}

In order to complete the state sampler, we need to obtain a draw from $p(V,W|\theta_{0:T},y_{1:T})$. From equation \ref{dlmjoint} it is easy to see that $V$ and $W$ have independent inverse Wishart distributions conditional on $\theta_{0:T}$ and $y_{1:T}$. In particular
\begin{align*}
  V|\theta_{0:T},y_{1:T} &\sim IW\left(\Lambda_V + \sum_{t=1}^Tv_tv_t',\lambda_V + T\right), &
  W|\theta_{0:T},y_{1:T} &\sim IW\left(\Lambda_W + \sum_{t=1}^Tw_tw_t',\lambda_{W} + T\right) %\label{eq:VW|theta}
\end{align*}
where $v_t = y_t - F_t\theta_t$ and $w_t = \theta_t - G_t\theta_{t-1}$. Putting the pieces together, the state sampler is the following DA algorithm:
\begin{alg*}[State]State Sampler
\label{alg:DLMstate}
\begin{enumerate}
\item Use the MCFA to sample $\theta_{0:T} \sim p(\theta_{0:T}|V,W,y_{1:T})$.
\item Sample $V \sim IW\left(\Lambda_V + \sum_{t=1}^Tv_tv_t',\lambda_V + T\right)$ and $W \sim IW\left(\Lambda_W + \sum_{t=1}^Tw_tw_t',\lambda_{W} + T\right)$ independently. 
\end{enumerate}
\end{alg*}
\noindent As we will show in Section \ref{sec:LLM}, the Markov chain constructed using the state sampler can mix poorly in some regions of the parameter space. For example, in the univariate local level model ($F_t=G_t=1$ for $t=1,2,\cdots,T$) and similar models it is known that if the variance of the latent states is too small relative to the variance of the data, mixing will be poor for $W$ \cite{fruhwirth2004efficient}.

Next, we can use the scaled disturbances, $\gamma_{0:T}$, in order to construct a second DA algorithm called the {\it scaled disturbance sampler}. In the smoothing step, we need to obtain a draw from $p(\gamma_{0:T}|V,W,y_{1:T})$, which is proportional to equation \eqref{dlmdistjoint}. This density is also Gaussian but does not have a tridagonal precision matrix. As a result, in order to obtain a draw from the conditional posterior of $\gamma_{0:T}$, we use the MCFA to instead draw from $p(\theta_{0:T}|V,W,y_{1:T})$, then use the definition of the scaled disturbances in order to transform from $\theta_{0:T}$ to $\gamma_{0:T}$. The density $p(V,W|\gamma_{0:T},y_{1:T})$ is also proportional to \eqref{dlmdistjoint}, but it is rather complicated and does not appear easy to draw from. It is easy to see that $V|W,\gamma_{0:T},y_{1:T} \sim IW\left(\Lambda_V + \sum_{t=1}^Tv_tv_t',\lambda_V + T\right)$ where again $v_t = y_t - F_t\theta_t$. It is not easy to draw from $p(W|\gamma_{0:T},y_{1:T})$ so we abandon drawing $V$ and $W$ jointly. However, the density $p(W|V,\gamma_{0:T},y_{1:T})$ is simpler and, at least in the local level model, can be efficiently sampled from (Section \ref{sec:LLM}). As a result, the scaled disturbance sampler has three steps instead of the two of the usual DA algorithm (Algorithm \nameref{alg:DA}). In this algorithm, we draw $V$ before $W$, i.e. $[\gamma_{0:T}|V^{(k)},W^{(k)}] \to [V^{(k+1)}|W^{(k)},\gamma_{0:T}] \to [W^{(k+1)}|V^{(k+1)},\gamma_{0:T}]$. Note that in order to draw $\gamma_{0:T}$, we first draw $\theta_{0:T}$ and transform, and that the draw of $V$ is the same whether we condition on $\gamma_{0:T}$ or $\theta_{0:T}$. As a result, in the scaled disturbance sampler we wait to transform from $\theta_{0:T}$ to $\gamma_{0:T}$ until just before the $W$ step, which reduces the computational cost of the algorithm. Thus the scaled disturbance sampler is as follows:
\begin{alg*}[SD]Scaled Disturbance Sampler\label{alg:DLMdist}
\begin{enumerate}
\item Use the MCFA to sample $\theta_{0:T} \sim p(\theta_{0:T}|V,W,y_{1:T})$.
\item Draw $V \sim IW\left(\Lambda_V + \sum_{t=1}^Tv_tv_t',\lambda_V + T\right)$.
\item Transform $\theta_{0:T}$ to $\gamma_{0:T}$.
\item Draw $W \sim p(W|V,\gamma_{0:T},y_{1:T})$.
\end{enumerate}
\end{alg*}
Once again, this last step is difficult but we demonstrate how to accomplish it when $W$ is a scalar in the local level model in Section \ref{sec:LLM}.

The DA algorithm based on on the scaled errors, $\psi_{0:T}$, is called the {\it scaled error sampler} and is similar to the scaled disturbance sampler with a couple of key differences. The conditional densities we are interested in are all proportional to equation \eqref{dlmerrorjoint}. First, the simulation smoothing step the scaled error sampler can be accomplished directly with the MCFA because the precision matrix of the conditional posterior of $\psi_{0:T}$ retains the necessary tridiagonal structure. Once again, the draw of $V$ and $W$ has to be broken up into two steps. The full conditional distribution of $W$ is inverse Wishart, that is $W|V,\psi_{0:T},y_{1:T} \sim IW\left(\Lambda_W + \sum_{t=1}^Tw_tw_t',\lambda_{W} + T\right)$ where once again $w_t = \theta_t - G_t\theta_{t-1}$.The density of $V|W,\psi_{0:T},y_{1:T}$ is in the same class as that of $W|V,\gamma_{0:T},y_{1:T}$. In fact there is a strong symmetry here --- the joint conditional posterior of $(V,W)$ given $\gamma_{0:T}$ is from the same family of densities as that of $(W,V)$ given $\psi_{0:T}$ so that $V$ and $W$ essentially switch places when we condition of $\psi_{0:T}$ instead of $\gamma_{0:T}$. We again draw $V$ before $W$ so that the scaled-error sampler looks very similar to the scaled disturbance sampler: 
\begin{alg*}[SE]Scaled Error Sampler\label{alg:DLMerror}
\begin{enumerate}
\item Use the MCFA to sample $\psi_{0:T} \sim  p(\psi_{0:T}|V,W,y_{1:T})$
\item Draw $V \sim p(V|W,\psi_{0:T},y_{1:T})$.
\item Draw $W \sim IW\left(\Lambda_W + \sum_{t=1}^Tw_tw_t',\lambda_{W} + T\right)$.
\end{enumerate}
\end{alg*}
Here the second step is the difficult one, and we demonstrate how to accomplish it in the local level model in Section \ref{sec:LLM}.

The wrongly-scaled DA algorithms are close analogues to their correctly scaled cousins. Starting with the {\it wrongly-scaled disturbance sampler}, we can obtain the required full conditionals from equation \eqref{dlmdisttildejoint}. The simulation smoothing step to draw from $p(\tilde{\gamma}_{0:T}|V,W,y_{1:T})$ is similar to that of the scaled disturbance sampler --- the density is Gaussian, but the precision matrix is not tridiagonal, so we draw $\theta_{0:T}$ using the MCFA and trandform to obtain a draw of $\tilde{\gamma}_{0:T}$. The density of $V,W|\tilde{\gamma}_{0:T},y_{1:T}$ is too complicated to draw from directly, as was the case when we used the scaled disturbances. In this case, the full conditional distribution of $W$ is the same as its distribution when we condition on the states, i.e. $W|V,\tilde{\gamma}_{0:T},y_{1:T} \sim \sim IW\left(\Lambda_W + \sum_{t=1}^Tw_tw_t',\lambda_{W} + T\right)$ with $w_t = \theta_t - G_t\theta_{t-1}$ as before, and $\theta_{0:T}$ a function of $V$ and $\tilde{\gamma}_{0:T}$. The density for $V|\tilde{\gamma}_{0:T},y_{1:T}$ is once again difficult to draw from, but that of $V|W,\tilde{\gamma}_{0:T},y_{1:T}$ is easier to work with, especially in the local level example from Section \ref{sec:LLM}. So in the wrongly-scaled disturbance sampler, we also draw $(V,W)$ in two steps: 
\begin{alg*}[W-SD]Wrongly-Scaled Disturbance Sampler\label{alg:DLMwdist}
\begin{enumerate}
\item Use MCFA to draw $\theta_{0:T} \sim p(\theta_{0:T}|V,W,y_{1:T})$.
\item Transform $\theta_{0:T}$ to $\tilde{\gamma}_{0:T}$.
\item Draw $V \sim p(V|W,\tilde{\gamma}_{0:T},y_{1:T})$.
\item Draw $W \sim IW\left(\Lambda_W + \sum_{t=1}^Tw_tw_t',\lambda_{W} + T\right)$.
\end{enumerate}
\end{alg*}
Here the third step is difficult and, once again, we demonstrate how to accomplish it in the local level model in Section \ref{sec:LLM}.

The {\it wrongly-scaled error sampler} depends on equation \eqref{dlmerrortildejoint} for its full conditionals, and is closely related to both the wrongly-scaled disturbance sampler and the scaled error sampler. The density of $\tilde{\psi}_{0:T}|V,W,y_{1:T}$ is Gaussian with a tridiagonal precision matrix, so the simulation smoothing step can be accomplished using the MCFA. The density $p(V,W|\tilde{\psi}_{0:T},y_{1:T})$ is from the same class as $p(W,V|\tilde{\gamma}_{0:T},y_{1:T})$ so that $V$ and $W$ essentially switch places when we condition on $\tilde{\psi}_{0:T}$ instead of $\tilde{\gamma}_{0:T}$, much like in the correctly scaled case. In particular, $V|W,\tilde{\psi}_{0:T},y_{1:T} \sim IW\left(\Lambda_V + \sum_{t=1}^Tv_tv_t',\lambda_V + T\right)$ where $v_t = y_t - F_t\theta_t$ and $\theta_{0:T}$ is a function of $W$, $\tilde{\psi_{0:T}}$ and $y_{1:T}$. The density of $W|V,\tilde{\psi}_{0:T},y_{1:T}$ is from the same class as that of $V|W,\tilde{\gamma}_{0:T},y_{1:T}$. So we once again draw $V$ and $W$ separately, i.e. 
\begin{alg*}[WSE]Wongly-Scaled Error Sampler\label{alg:DLMwerror}
\begin{enumerate}
\item Use MCFA to draw $\tilde{\psi}_{0:T} \sim p(\theta_{0:T}|V,W,y_{1:T})$.
\item Draw $V \sim IW\left(\Lambda_V + \sum_{t=1}^Tv_tv_t',\lambda_V + T\right)$.
\item Draw $W \sim p(W|V,\tilde{\psi}_{0:T},y_{1:T})$
\end{enumerate}
\end{alg*}
Here the last step is the difficult one, which we show how to accomplish in the local level model in Section \ref{sec:LLM}.

The densities $p(V,W|\gamma_{0:T},y_{1:T})$ and $p(V,W|\tilde{\psi}_{0:T}$ are both complex to work with and both imply the same full conditional inverse Wishart distribution for $V$, but they differ in their treatment of $W$. Because of the symmetry between the correctly and wrongly scaled versions of each density, the same can be said for $p(V,W|\tilde{\gamma}_{0:T},y_{1:T})$ and $p(V,W|\psi_{0:T},y_{1:T})$. In Section \ref{sec:LLM}, we will show how closely the two distributions are related in the local level model. Now given these five DA algorithms, we can move on to alternating and interweaving algorithms which combine two or more of the various DAs in interesting ways.

\subsection{Alternating algorithms}\label{sec:Algs:alt}
Recall that an alternating algorithm is an MCMC algorithm in which one iteration is composed of a single iteration of one DA algorithm followed by a signle iteration of another DA algorithm, as in Algorithm \nameref{alg:Alt}. Using the full conditional distributions defined in Section \ref{sec:Algs:base}, we have enough information to construct several alternating algorithms based on any two of the DA algorithms defined there. For example, the {\it State-SD alternating sampler} which alternates between the states and the scaled disturbances, obtains the $k+1$'st iteration of $(V,W)$ from the $k$'th as follows:
\begin{align*}
&[\theta_{0:T}|V^{(k)},W^{(k)}] \to [V^{(k+0.5)},W^{(k+0.5)}|\theta_{0:T}] \to\\ 
&[\gamma_{0:T}|V^{(k+0.5)},W^{(k+0.5)}] \to [V^{(k+1)}|W^{(k+0.5)},\gamma_{0:T}] \to [W^{(k+1)}|V^{(k+1)},\gamma_{0:T}].
\end{align*}
The first line is an iteration of the state sampler while the second line is an iteration of the scaled disturbance sampler. No additional work is necessary to link up the two iterations --- we simply plug in the values of $V$ and $W$ obtained from the state sampler iteration into the draw of $\gamma_{0:T}$ from step one of the scaled disturbance sampler iteration.

Each other alternating algorithm is analogous and can be constructed without any additional complications. There is the question of what order to use the base algorithms within an alternating algorithm which, in principle, could affect the congergence properties of the alternating algorithm. In practice this typically is not important. There is one additional wrinkle added by consider alternating algorithms which combine more than two base samplers. This class of samplers is not any more comlicated other than adding a couple extra steps. For example, the {\it State-SD-SE alternating sampler} which alternates between the states, the scaled errors, and the scaled disturbances is as follows:
\begin{align*}
&[\theta_{0:T}|V^{(k)},W^{(k)}] \to [V^{(k+1/3)},W^{(k+1/3)}|\theta_{0:T}] \to\\ 
&[\gamma_{0:T}|V^{(k+1/3)},W^{(k+1/3)}] \to [V^{(k+2/3)}|W^{(k+1/3)},\gamma_{0:T}] \to [W^{(k+2/3)}|V^{(k+2/3)},\gamma_{0:T}]\to \\
&[\psi_{0:T}|V^{(k+2/3)},W^{(k+2/3)}] \to [V^{(k+1)}|W^{(k+2/3)},\psi_{0:T}] \to [W^{(k+1)}|V^{(k+1)},\psi_{0:T}].
\end{align*}
Once again, each of the required conditional distributions are defined in Section \ref{sec:Algs:base} so there is no real extra difficulty.

The naming convention we use for these algorithms is to list each DA in the order in which they appear in the alteranting sampler, separated by hyphens. The scaled disturbances we shorten to ``SD'', the scaled errors we shorten to ``SE'', and the wrongly-scaled version of each we write as ``WSD'' and ``WSE'' respectively. So, for example, the alternating sampler which alternates between the scaled disturbances and the wrongly-scaled disturbances, in that order, we call the {\it SD-WSD alternating sampler} or {\it SD-WSD Alt}. The main purpose of these algorithm is to use as a baseline for evaluating the GIS algorithms based on the same sets of DAs.

\subsection{GIS Algorithms}\label{sec:Algs:GIS}
We can use the various DAs of Section \ref{sec:DAs} in order to construct interweaving algorithms in addition to the alternating algorithms of the previous section. Recall that a general interweaving strategy (GIS) is an algorithm that draws first from the full conditional distribution of a DA, then draws from the conditional distribution of a new DA given the old DA and the data, then draws from the full conditional distribution of the model parameters given the new DA, in other words Algorithm \nameref{alg:GIS}. Given the full conditional distributions listed in Section \ref{sec:Algs:base}, the only additional ingredients we need are the densities of, for example, $p(\gamma_{0:T}|\theta_{0:T},y_{1:T})$ and $p(\psi_{0:T}|\theta_{0:T},y_{1:T})$. In practice, it is easier to obtain a joint draw of, e.g., $(V,W,\gamma_{0:T}|\theta_{0:T},y_{1:T})$, i.e. to use the extended version of the GIS algorithm, Algorithm \nameref{alg:GIS2}.

So the only additional requirement in order to construct a GIS algorithm is to use the definitions of the various available DAs in order to perform the one-to-one transformations from any one DA to anopther. For example, in the {\it State-SD GIS sampler} we obtain $(V^{(k+1)},W^{(k+1)})$ from $(V^{(k)},W^{(k)})$ as follows:
\begin{align*}
&[\theta_{0:T}|V^{(k)},W^{(k)}] \to [W^{(k+0.5)},V^{(k+0.5)}|\theta_{0:T}] \to\\
&[\gamma_{0:T}|V^{(k+0.5)},W^{(k+0.5)},\theta_{0:T}] \to [V^{(k+1)}|W^{(k+0.5)},\gamma_{0:T}] \to [W^{(k+1)}|V^{(k+1)},\gamma_{0:T}].
\end{align*}
Here, the first step of the second line is not a proper random draw --- rather, we transform $\theta_{0:T}$ to $\gamma_{0:T}$ by means of the defining equations for $\gamma_{0:T}$: $\gamma_0=\theta_0$ and $\gamma_t = L_W^{-1}(\theta_t - G_t\theta_{t-1})$ for $t=1,2,\cdots,T$ where $L_W$ is the Cholesky decomposition of $W$. 

There are often some small improvements that can be made simply by thinking clearly about what the GIS algorithm is doing. For example in the above version of the State-SD GIS sampler, the draw of $V$ in step two of line one and the draw of $V$ in step two of line two are redundant --- they come from the same distribution and only the last one is ever used in later steps. As a result, we can remove the second draw in order to save computational time so that the State-SD GIS sampler is as follows:
\begin{enumerate}
\item Use the MCFA to sample $\theta_{0:T} \sim p(\theta_{0:T}|V,W,y_{1:T})$.
\item Sample $V \sim IW\left(\Lambda_V + \sum_{t=1}^Tv_tv_t',\lambda_V + T\right)$ and $W \sim IW\left(\Lambda_W + \sum_{t=1}^Tw_tw_t',\lambda_{W} + T\right)$ independently.
\item Transform $\theta_{0:T}$ to $\gamma_{0:T}$.
\item Sample $W \sim p(W|V,\gamma_{0:T},y_{1:T})$.
\end{enumerate}
As another example, the {\it SD-SE GIS sampler} is as follows:
\begin{enumerate}
\item Use the MCFA to sample $\theta_{0:T} \sim p(\theta_{0:T}|V,W,y_{1:T})$.
\item Sample $V \sim IW\left(\Lambda_V + \sum_{t=1}^Tv_tv_t',\lambda_V + T\right)$.
\item Transform $\theta_{0:T}$ to $\gamma_{0:T}$.
\item Sample $W \sim p(W|V,\gamma_{0:T},y_{1:T})$.
\item Transform $\gamma_{0:T}$ to $\psi_{0:T}$.
\item Sample $V \sim p(V|W,\psi_{0:T},y_{1:T})$.
\item Sample $W \sim IW\left(\Lambda_W + \sum_{t=1}^Tw_tw_t',\lambda_{W} + T\right)$.
\end{enumerate}
Note that like in the scaled disturbance algorithm, we draw $V$ in step two before transforming in step three since the conditional distribution of $V$ is unaffected by this transformation, and it is less costly the compute the hyperparameters of that inverse Wishart distribution from $\theta_{0:T}$ instead of $\gamma_{0:T}$.

The naming convention for GIS algorithms is similar to that of alternating algorithms --- DAs appear in the name in the order that they appear in the algorithm, separated by hyphens, e.g. a GIS algorithm based on the states, scaled disturbances and scaled errors, in that order, would be called the {\it State-SD-SE GIS sampler}. There is no additional difficulty encountered by using a GIS with greater than two DAs --- the required conditional distributions are still defined in Section \ref{sec:Algs:base} and the definitions of the various DAs should allow for the one-to-one transformation from any DA to another DA to be defined.  Also like alternating algorithms, the performance of GIS algorithms may depend on the order in which the DAs are used. \citeasnoun{yu2011center} note that this tends not to make much difference, which is consistent with our own experience.

\subsection{CIS algorithms}\label{sec:Algs:CIS}
Recall that a component interweaving strategy (CIS) is an MCMC algorithm that uses GIS in a Gibbs step for part of the parameter vector and GIS in another Gibbs step for the other part of the parameter vector, i.e. Algorithm \nameref{alg:CIS}. The advantage of using CIS is that it is sometimes possible to find an AA-SA pair of DAs for each part of the parameter vector rather even when no such pair of DAs exist for the entire parameter vector. To wit, from Section \ref{sec:DAs} we know that the scaled disturbances and the wrongly-scaled disturbances form an AA-SA pair for $W|V$ while the scaled errors and the wrongly-scaled errors form an AA-SA pair for $V|W$. 

A CIS sampler based on these AA-SA pairs obtains $(V^{(k+1)},W^{(k+1)})$ from $(V^{(k)},W^{(k)})$ as follows:
\begin{align*}
&[\psi_{0:T}|V^{(k)},W^{(k)}] \to [V^{(k+0.5)}|W^{(k)},\psi_{0:T}] \to [\tilde{\psi}_{0:T}|V^{(k+0.5)},W^{(k)},\psi_{0:T}] \to [V^{(k+1)}|W^{(k)},\tilde{\psi}_{0:T}]\to\\
&[\tilde{\gamma}_{0:T}|V^{(k+1)},W^{(k)},\tilde{\psi}_{0:T}] \to [W^{(k+0.5)}|V^{(k)},\tilde{\gamma}_{0:T}] \to [\gamma_{0:T}|V^{(k+1)},W^{(k+0.5)},\tilde{\gamma}_{0:T}]\to [W^{(k+1)}|V^{(k+1)},\gamma_{0:T}].
\end{align*}
The first line is essentially a Gibbs step for drawing $V$. The first step of that line runs the usual simulation smoothing step for $\psi_{0:T}$ discussed in Section \ref{sec:Algs:base}. The second step draws from the complicated full conditional of $V$ given $\psi_{0:T}$. The third step is simply a transformation from $\psi_{0:T}$ to $\tilde{\psi}_{0:T}$ given by the definition of the two DAs. The last step is the same inverse Wishart draw as in the state sampler and in wrongly-scaled error sampler from Section \ref{sec:Algs:base}. The second line is essentially a Gibbs step for drawing $W$, but in this case we choose to use the SA before the AA. This will minimize the number of transformations we have to make in every iteration, which we will show momentarily. The first step is a transformation from $\tilde{\psi}_{0:T}$ to $\tilde{\gamma}_{0:T}$ given by the definitions of the two DAs. The second step draws $W$ from the same inverse Wishart distribution that shows up in the state sampler and in the wrongly-scaled disturbance sampler. The third step is once again a transformation step, obtained from the defintions of $\gamma_{0:T}$ and $\tilde{\gamma}_{0:T}$.   The last step draws $W$ from its complicated full conditional given $\gamma_{0:T}$.

Notice that each time one of the wrongly-scaled DAs appears in the CIS sampler above, it would make no difference if the states were used instead despite the fact that we know from Section \ref{sec:DAs} the states are only an SA for $W|V$ but not for $V|W$. Using this fact we obtain a slightly different version of the CIS sampler:
\begin{align*}
&[\psi_{0:T}|V^{(k)},W^{(k)}] \to [V^{(k+0.5)}|W^{(k)},\psi_{0:T}] \to [\theta_{0:T}|V^{(k+0.5)},W^{(k)},\psi_{0:T}] \to [V^{(k+1)}|W^{(k)},\theta_{0:T}]\to\\
&[W^{(k+0.5)}|V^{(k)},\theta_{0:T}] \to [\gamma_{0:T}|V^{(k+1)},W^{(k+0.5)},\theta_{0:T}]\to [W^{(k+1)}|V^{(k+1)},\gamma_{0:T}].
\end{align*}
Notice that there is no transformation step at the beginning of the second line since the DA is already in the correct form --- this reduces the computational cost per iteration and in both our and \citeasnoun{yu2011center}'s experience, changing the order of the steps does not substantially affect MCMC efficiency. Then we can write down this CIS algorithm as follows:
\begin{alg*}[CIS]Componenwise Interweaving Sampler\label{alg:DLMcis}
\begin{enumerate}
\item Use the MCFA to sample $\psi_{0:T} \sim p(\psi_{0:T}|V,W,y_{1:T})$.
\item Sample $V \sim p(V|W,\psi_{0:T},y_{1:T})$.
\item Transform $\psi_{0:T}$ to $\theta_{0:T}$.
\item Sample $V \sim IW\left(\Lambda_V + \sum_{t=1}^Tv_tv_t',\lambda_V + T\right)$.
\item Sample $W \sim IW\left(\Lambda_W + \sum_{t=1}^Tw_tw_t',\lambda_{W} + T\right)$.
\item Transform $\theta_{0:T}$ to $\gamma_{0:T}$.
\item Sample $W \sim p(W|V,\gamma_{0:T},y_{1:T})$.
\end{enumerate}
\end{alg*}

We can rearrange the order in which the Gibbs steps for $V$ and $W$ are taken within the CIS algorithm and change the order in which to AAs and SAs are used with the Gibbs steps to obtain another version of the CIS algorithm:
\begin{align*}
&[\gamma_{0:T}|V^{(k)},W^{(k)}] \to [W^{(k+0.5)}|V^{(k)},\gamma_{0:T}] \to [\theta_{0:T}|V^{(k)},W^{(k+0.5)},\gamma_{0:T}] \to [W^{(k+1)}|V^{(k)},\theta_{0:T}]\to \\
&[V^{(k+0.5)}|W^{(k+1)},\theta_{0:T}] \to [\psi_{0:T}|V^{(k+0.5)},W^{(k+1)},\theta_{0:T}] \to [V^{(k+1)}|W^{(k+1)},\psi_{0:T}].
\end{align*}
Since the draw of $V$ is from the same density whether we condition of $\theta_{0:T}$ or $\gamma_{0:T}$ and similar for $W$ given $\theta_{0:T}$ or $\psi_{0:T}$, we can move $V|W,\theta_{0:T}$ and $W|V,\theta_{0:T}$ without changing the MCMC properties of the algorithm in order to obtain the {\it SD-SE GIS sampler} which interweaves between the scaled disturbances and the scaled errors:
\begin{align*}
&[\gamma_{0:T}|V^{(k)},W^{(k)}] \to [V^{(k+0.5)}|W^{(k)},\gamma_{0:T}] \to[W^{(k+0.5)}|V^{(k+0.5)},\gamma_{0:T}] \to \\
&[\psi_{0:T}|V^{(k+0.5)},W^{(k+0.5)}]\to [V^{(k+1)}|W^{(k+0.5)},\psi_{0:T}]\to [W^{(k+1)}|V^{(k+1)},\psi_{0:T}].
\end{align*}
As a result, since in most cases simply rearranging the steps of an MCMC sampler does little to impact the convergence and mixing properties of the sampler, we expect the CIS and SD-SE GIS samplers to perform about the same along this axis so that computational cost per iteration and ease of implementation are the only real considerations involved in picking between the two.

In our original defintion of the CIS sampler for the DLM we used the scaled disturbances as the AA for $W$ and the scaled errors and the AA for $V$. We could have reversed this or use the same AA for both $V$ and $W$ since both the scaled errors and scaled disturbances are AAs for $(V,W)$. Consider the version where we reverse the Gibbs steps where AAs are used, as below:
\begin{align*}
&[\gamma_{0:T}|V^{(k)},W^{(k)}] \to [V^{(k+0.5)}|W^{(k)},\gamma_{0:T}] \to [\tilde{\psi}_{0:T}|V^{(k+0.5)},W^{(k)},\gamma_{0:T}] \to [V^{(k+1)}|W^{(k)},\tilde{\psi}_{0:T}]\to\\
&[\psi_{0:T}|V^{(k+1)},W^{(k)}]\to [W^{(k+0.5)}|V^{(k+1)},\psi_{0:T}] \to [\tilde{\gamma}_{0:T}|V^{(k+1)},W^{(k+0.5)},\psi_{0:T}] \to [W^{(k+1)}|V^{(k+1)},\tilde{\gamma}_{0:T}].
\end{align*}
Here steps two and four of the first line draw $V$ from the same inverse Wishart distribution --- as if we conditioned on $\theta_{0:T}$ isntead of $\gamma_{0:T}$ or $\tilde{\psi}_{0:T}$. Similarly, steps two and four of the second line draw $W$ from the same inverse Wishart distribution, again as if we conditioned on $\theta_{0:T}$. So we can remove the extraneous steps and write this CIS sampler like so:
\begin{enumerate}
\item Use the MCFA to sample $\theta_{0:T} \sim p(\theta_{0:T}|V,W,y_{1:T})$.
\item Sample $V \sim IW\left(\Lambda_V + \sum_{t=1}^Tv_tv_t',\lambda_V + T\right)$.
\item Sample $W \sim IW\left(\Lambda_W + \sum_{t=1}^Tw_tw_t',\lambda_{W} + T\right)$.
\end{enumerate}
There is no transormation step between $V$ and $W$ since both draws are conditional on $\theta_{0:T}$, so this algorithm is simply the state sampler from Section \ref{sec:Algs:base}. In addition, there are two more CIS samplers that either use scaled disturbances or the scaled errors as the AA for both $V$ and for $W$. Since from Section \ref{sec:DAs} we know that the states, $\theta_{0:T}$, are an AA for $V|W$, we could also use $\theta_{0:T}$ as the AA for $V$ to give two more possible CIS algorithms, depending on what is used as the AA for $W$. However, this is no different from using the scaled disturbances as the AA for $V$ since in both cases the full conditional distribution of $V$ is the same inverse Wishart distribution (Section \ref{sec:Algs:base}).

If we use the scaled disturbances as the AA for both $V$ and $W$, the resulting sampler is similar to the CIS sampler earlier in this section except the Gibbs step for $V$ is obtained by drawing from the full conditional of $\theta_{0:T}$, then the full conditional of $V$ given $\theta_{0:T}$ just like the Gibbs step for $V$ in the staggered state sampler. Similarly in the case of the scaled errors, the sampler is the same as the CIS sampler earlier in this section, except the Gibbs step for $W$ is obtained by drawing from the full conditional of $\theta_{0:T}$, then the full conditional of $W$ given $\theta_{0:T}$ again just like the Gibbs step for $W$ in the staggered state sampler. Without the knowledge that the reduced $\theta_{0:T}$ steps in both of these algorithms come from an AA-SA pair with extraneous steps removed, we would call these {\it partial CIS} algorithms to use the language of \citeasnoun{yu2011center} -- a partial CIS algorithm is a CIS algorithm which uses an ordinary DA step instead of an interweaving step in one of the Gibbs steps. So while it appears there are up to size CIS samplers, only one of them is truly a CIS sampler. Another one is simply a complicated way of writing down the state sampler, and the other four consist of two partial CIS samplers and a dupilcate of each.

In sum, we one CIS sampler and two partial CIS samplers to go along with 5 base samplers and a large number of GIS and alternating samplers. We now desire to characterize the efficiency of these samplers, both in terms of computational cost and in terms of the mixing and convergence of the Markov chain. We will do this in the next section using a particularly simple example of a DLM --- the local level model.

\section{Application: The Local Level Model}\label{sec:LLM}

\subsection{The model and its DAs}

In order to illustrate how these algorithms work, we will focus on the local level model for simplicity. The local level model (LLM) is a DLM with univariate data $y_t$ for $t=1,2,\cdots,T$ and a univariate latent state $\theta_t$ for $t=0,2,\cdots,T$. In the general DLM notation, $F_t=1$ and $G_t=1$ for all $t$. As a result, $V$ and $W$ are scalar variances. We can write the model as
\begin{align}
  y_t |\theta_{0:T},V,W& \stackrel{ind}{\sim} N(\theta_t,V) & 
  \theta_t |\theta_{0:t-1},V,W& \sim N(\theta_{t-1},W) 
\end{align}
for $t=1,2,\cdots,T$. Here $\theta_t=E[y_t|\theta_{0:T},V,W]$. The priors on $(\theta_0,V,W)$ from section \ref{sec:DLM} simplify to $\theta_0\sim N(m_0,C_0)$, $V\sim IG(\alpha_V,\beta_V)$ and $W\sim IG(\alpha_W,\beta_W)$ with $\theta_0$, $V$ and $W$ mutually independent and $IG(\alpha,\beta)$ is the inverse gamma distribution with shape parameter $\alpha$ and scale parameter $\beta$. 

Now we can define the various DAs from Section \ref{sec:DAs} in the context of the local level model. The usual DA, the states, are simply $\theta_{0:T}$. From the states we obtain the scaled disturbances as $\gamma_0=\theta_0$ and $\gamma_t = (\theta_t - \theta_{t-1})/\sqrt{W}$ for $t=1,2,\cdots,T$. Similarly, the scaled errors are $\psi_0=\theta_0$ and $\psi_t = (y_t - \theta_t)/\sqrt{V}$ for $t=1,2,\cdots,T$. The wrongly-sccaled disturbances are then $\tilde{\gamma}_{0}=\theta_0$ and $\tilde{\gamma}_t = (\theta_t - \theta_{t-1})/\sqrt{V}$ while the wrongly-scaled erros are $\tilde{\psi}_0=\theta_0$ with $\tilde{\psi}_t = (y_t - \theta_t)/\sqrt{W}$ for $t=1,2,\cdots,T$. As in previous sections, we will drop the subscript whenever we refer to the entire vector, i.e. $\theta=\theta_{0:T}$ and $y=y_{1:T}$.

\subsection{Full conditionals}\label{sec:LLM:fullcond}

Here we list the full conditional distributions required to contruct each of the MCMC samplers in Section \ref{sec:Algs} for the local level model. Derivations of these conditionals can be found in the supplementary materials. In the state sampler, Algorithm \nameref{alg:DLMstate}, we need $p(\theta|V,W,y)$ and $p(V,W|\theta,y)$. The former is still Gaussian in the local level model so we still use the MCFA mentioned in Section \ref{sec:Algs:base} in order to obtain a draw of $\theta$. The supplementary materials explain how to perform this step in the general DLM and code is provided for accomplishing it in the local level model. As in the more general DLM, $V$ and $W$ are conditionally independent in the posterior given $\theta$. The independent inverse Wishart distributions of Section \ref{sec:Algs:base} turn into inverse gamma distributions, to wit $V\sim IG(a_V,b_V)$  and $W\sim IG(a_W, b_W)$ where $a_V = \alpha_V + T/2$, $b_V = \beta_V + \sum_{t=1}^T(y_t - \theta_t)^2/2$, $a_W = \alpha_W + T/2$, and $b_W = \beta_W + \sum_{t=1}^T(\theta_t - \theta_{t-1})^2/2$.

In order to construct the scaled disturbance sampler, Algorithm \nameref{alg:DLMdist}, we need $p(\gamma|V,W,y)$, $p(V|W,\gamma,y)$ and $p(W|V,\gamma,y)$. Like in the general DLM, $p(V|W,\gamma,y)=p(V|W,\theta,y)$ and we draw $\gamma$ by using the MCFA to draw $\theta$ and transforming, so we simply draw $\theta$, draw $V|W,\theta,y$, then transform to $\gamma$. The only remaining draw is from $p(W|V,\gamma,y)$. In the supplementary materials we show that this density has the form
\begin{align*}
p(W|V,\gamma_{0:T},y_{1:T}) \propto& W^{-\alpha_W - 1}\exp\left[-a_\gamma W + b_\gamma \sqrt{W} -\frac{\beta_W}{W}\right]. 
\end{align*}
where $a_\gamma =\sum_{t=1}^T(\sum_{j=1}^t\gamma_j)^2/2V$ and $b_\gamma =\sum_{t=1}^T(y_t-\gamma_0)(\sum_{j=1}^t\gamma_j)/V$. 


The construction of the scaled error sampler in the local level model, Algorithm \nameref{alg:DLMerror} is similar to that of the scaled disturbance sampler. The MCFA is used to draw $\psi|V,W,y$, like in the general DLM. Again, $p(W|V,\psi,y)=p(W|V,\theta,y)$ so this step can be accomplished by transforming $\psi$ to $\theta$, then computing $a_W$ and $b_W$ as in the local level model version of the state sampler. The density of $V|W,\psi,y$ is
\begin{align*}
 p(V|W,\psi,y) \propto V^{-\alpha_V - 1}\exp\left[ -a_{\psi}V + b_{\psi}\sqrt{V} -\frac{\beta_V}{V}\right] 
\end{align*}
where $a_{\psi}=\sum_{t=1}^T(L\psi_t)^2/2W$ and $b_{\psi}=\sum_{t=1}^T(L\psi_tLy_t)/W$, and we define $Ly_t=y_t-y_{t-1}$ for $t=2,3,\cdots,T$, $Ly_1=y_1 - \psi_0$, $L\psi_t = \psi_t - \psi_{t-1}$ for $t=2,3,...,T$ and $L\psi_1=\psi_1-0$. In other words, the form of $p(V|W,\psi,y)$ is the same as $p(W|V,\gamma,y)$. The general form of these two densities is $p(x)\propto x^{-\alpha-1}\exp\left[ -ax + b\sqrt{x} -\beta/x\right]$. In the appendix (Section \ref{sec:Append:scale}) we show that this density is often log concave, in which case adaptive rejection sampling \cite{gilks1992adaptive} works well. When the density is not log concave, we use a $t$ approximation in a rejection sampler for $\log(x)$ (Section \ref{sec:Append:wscale}).

The construction of the wrongly-scaled disturbance and wrongly-scaled error samplers, Algorithms \nameref{alg:DLMwdist} and \nameref{alg:DLMwerror}, is similar. The local level model version of these algorithms closely tracks the general DLM version --- the draws of $\tilde{\gamma}$ and $\tilde{\psi}$ are exactly as in Algorithm \nameref{alg:DLMwdist} and Algorithm \nameref{alg:DLMwerror} respectively. In addition, $p(V|W,\tilde{\psi},y)=p(V|W,\theta,y)$ and $p(W|V,\tilde{\gamma},y)=p(W|V,\theta,y)$ so both draws are simply the inverse gamma draws as in the LLM version of the state sampler. Here, $p(W|V,\tilde{\psi},y)$ and $p(V|W,\tilde{\gamma},y)$ have the form $p(x)\propto x^{-\alpha-1}\exp\left[ -ax + b/\sqrt{x} -c/x\right]$, which is closely related to the difficult density from the correctly scaled samplers above. Again, this density is the same as the generalized inverse Gaussian density when $b=0$. For $p(V|W,\tilde{\gamma},y)$ we show in the supplemental materials that $\alpha=\alpha_V$, $a = a_{\tilde{\gamma}} = \frac{1}{2W}\sum_{t=1}^T\tilde{\gamma}_t^2$, $b = b_{\tilde{\gamma}} = \sum_{t=1}^T(y_t - \tilde{\gamma}_0)\sum_{s=1}^t\tilde{\gamma}_s$, and $c = c_{\tilde{\gamma}} = \beta_V + \frac{1}{2}\sum_{t=1}^T(y_t - \tilde{\gamma}_0)^2$ while for $p(W|V,\tilde{\psi},y)$ we show that $\alpha=\alpha_W$,   $a = a_{\tilde{\psi}} = \frac{1}{2V}\sum_{t=1}^T\tilde{\psi}_t^2$,  $b = b_{\tilde{\psi}} = \sum_{t=1}^TL\tilde{y}_tL\tilde{\psi}_t$, and $c = c_{\tilde{\psi}} = \beta_W + \frac{1}{2}\sum_{t=1}^TL\tilde{y}_t^2$. This density is harder to sampler from because adaptive rejection sampling does not work very well, so we construct a rejection sampler for $\log(x)$ using a $t$ approximation in the appendix (Section \ref{sec:Append:wscale}).

Given the densities discussed above, all of the pieces are in place to construct each of the base, alternating and interweaving algorithms from Section \ref{sec:Algs} for the LLM. In the next secion, we explore the efficacy of each of these algorithms through simulations.

\subsection{Simulation Setup}

In order to test these algorithms, we simulated data from the local level model for various choices of $V$, $W$, and $T$. We created a full factorial design with $V$ and $W$ each taking the values $10^{i}$ where $i=-2,-1.5,1,\cdots,2$ and $T$ taking the values $10, 100, 1000$. Then for each dataset, we fit the local level model using a variety of the algorithms discussed in this paper. We used the same rule for constructing priors for each model: $\theta_0\sim N(0,10^7)$, $V\sim IG(5, 4V^*)$, and $W\sim IG(5, 4W^*)$, mutually independent where $(V^*,W^*)$ are the true values of $V$ and $W$ used to simulate the time series. So the prior mean is equal to the true values of $V$ and $W$ so that both the prior and likelihood and thus the posterior roughly agree about the likely values of $V$ and $W$. Ultimately, the reason for varying the prior with the true parameter values is that the results are more interesting --- intuitively, the behavior of each of these samplers depends on where in the parameter space the posterior distribution puts most of its mass. Varying the prior as the true values of the parameters vary ensure that both the prior and likelihood agree on where this mass should be.

For each dataset and each sampler we obtained $n=3000$ draws and threw away the first $500$ as burn in. The chains were started at the true values used to simulated the time series, so we can examine the behavior of the chains to determine how well they mix but not how quickly they converge. Define the effective sample proportion (ESP) for a scalar component of the chain as the effective number of independent draws, i.e. effective sample size \cite{gelman2003bayesian} of the component divided by the actual sample size, i.e. $ESP=ESS/n$. An $ESP=1$ indicates that the Markov chain is behaving as if it obtains iid draws from the posterior. It is possible to obtain $ESP>1$ if the draws are negatively correlated and occasionally for some of our samplers our estimates of $ESP$ are greater than one, but we round this down to one for plotting purposes.

\subsection{Base sampler results}

\begin{figure}[!ht]
\centering
\includegraphics[width=0.7\textwidth]{baseESplot1}
%\includegraphics[width=0.7\textwidth]{baseESplot2}
\caption{Effective sample proportion in the posterior sampler for a time series of length $T=100$, for $V$ and $W$ in the base samplers. $X$ and $Y$ axes indicate the true values of $V$ and $W$ respectively for the simulated data. Note that the signal-to-noise ratio is constant moving up any diagonal. In the upper left the signal is high, in the lower right the noise is high. For plotting purposes, effective sample proportions larger than $1$ were rounded down to $1$.}
\label{baseESplot}
\end{figure}

Figure \ref{baseESplot} contains plots of ESP for $V$ and $W$ in each chain of each base sampler for $T=100$ --- we omit the $T=10$ and $T=1000$ plots for brevity, but they can be found in the supplementary materials. The state sampler has a low ESP for $V$ and a high ESP for $W$ when the true signal-to-noise ratio, $R^*=W^*/V^*$, is larger than one. In contrast, when $R^*<1$ the state sampler has a low ESP for $W$ and a high ESP for $V$. When $R^*\approx 1$, the state sampler has a modest to low ESP for both $V$ and $W$. To summarize, the state sampler has mixing issues for whichever of $V$ or $W$ is smaller. The wrongly-scaled disturbance and wrongly-scaled error samplers are similar to the state sampler except WSD has lower ESP for $V$ and WSE has lower ESP for $W$. The scaled disturbance sampler has low ESP for both $V$ and $W$ when $R^*>1$, and it is paricularly low for $W$. The scaled error sampler behaves almost exactly opposite ---it has low ESP for both when $R^*<1$ and in particular for $V$. We omit the results here, but as the length of the time series, $T$, increases, in all of these samplers the region of the parameter space with high ESP shrinks and in the low ESP regions, ESP drops closer to zero. We summarize some of the above results for convenience in Table \ref{tab:stnmix}.
\begin{table}
  \centering
  \begin{tabular}{|l|ccccc|}\hline
    Parameter & State & SD & SEr & WSD & WSE \\\hline
    V & $R^* < 1$ & $R^* < 1$ & $R^* > 1$ & $R^* < 1$ & $R^* < 1$\\
    W & $R^* > 1$ & $R^* < 1$ & $R^* > 1$ & $R^* > 1$ & $R^* > 1$ \\\hline
  \end{tabular}
  \caption{Rule of thumb for when each base algorithm has a high ESP for each variable as a function of the true signal-to-noise ratio, $R^*=W^*/V^*$. Note that as the length of the time series increases, the farther away from one $R^*$ has to be for the sampler to have a high ESP.}
  \label{tab:stnmix}
\end{table}

Most of the patterns of Figure \ref{baseESplot} and Table \ref{tab:stnmix} can be explained by Figure \ref{corplot}, which contains the estimated posterior correlations between various functions of parameters estimated using the simulations from the Triple-Alt sampler for a time series with $T=100$. The state sampler consists of two steps --- a draw of $\theta$ given $V$ and $W$, and a draw of $(V,W)$ given $\theta$. From Section \ref{sec:LLM:fullcond} we have that conditional on $\theta$, $V$ and $W$ are independent in the posterior and each has an inverse gamma distribution that depends on the states only through the second parameter:
\begin{align*}
  b_V &= \beta_V + \sum_{t=1}^T(y_t - \theta_t)^2/2 &
  b_W &= \beta_W + \sum_{t=1}^T(\theta_t - \theta_{t-1})^2/2.
\end{align*}
So we can view $(b_V,b_W)$ as the data augmentation instead of $\theta$ and thus the state sampler is
\begin{align*}
  [b_V, b_W|V^{(k)},W^{(k)}] \to [V^{(k+1)},W^{(k+1)}|b_V,b_W].
\end{align*}
Thus the dependence between $(V,W)$ and $(b_V,b_W)$ in the posterior will determine how much the state sampler moves in a given iteration and, in particular, it is possible that $V$ and $W$ have very different serial dependence from each other since we are drawing them jointly. When the dependence between $V$ and $b_V$ is high, the $(V,W)$ step will hardly move $V$ even if it drastically moves $W$ since $V$ and $W$ are independent. However, the $(b_V,b_W)$ step may move both elements a moderate amount since they both depend on $(V,W)$.

In Figure \ref{corplot} we see that the posterior correlation between $V$ and $b_V$ is high in magnitude and positive when $R^*>1$ while the posterior correlation between $V$ and $b_W$ is moderate to low and negative. When $R^*$ is large enough though, the posterior correlation between $V$ and $b_W$ evaporates. Similarly when $R^*<1$ the posterior correlation between $W$ and $b_W$ is high and positive and the posterior correlation between $W$ and $b_V$ is high and negative. Again as $R^*$ becomes large enough the correlation between $W$ and $b_V$ goes to zero. So when $R^*>1$, the draw of $(b_V, b_W)$ is unlikely to move $b_V$ much since $b_V$ is so highly correlated with $V$ and essentially uncorrelated with $b_W$, but $b_W$ is essentially uncorrelated with $W$ and negatively correlated with $V$ so $b_W$ is likely to move a fair amount. Furthermore the draw of $V$ is highly correlated with $b_V$ while the draw of $W$ is essentially independent of $b_W$ (and the draws of $V$ and $W$ are independent conditional on $b_V$ and $b_W$). Thus when $R^*>1$ we should expect high serial dependence for $V$ and low serial dependence for $W$, and so low ESP for $V$ and high ESP for $W$, which is exactly what we see in Figure \ref{baseESplot}. By similar reasoning when $R^*<1$, we should expect low serial dependence for $V$ and high serial dependece for $W$ and thus high ESP for $V$ and low ESP for $W$, which is again precisely what we see in Figure \ref{baseESplot}.

For the scaled disturbance sampler, things are a bit more complicated. The draw of $V|W,\gamma$ still depends on $b_V$ since it is the same inverse gamma draw as in the state sampler, but the draw of $W|V,\gamma$ now depends on $a_\gamma$ and $b_\gamma$ defined in the previous section as 
\begin{align*}
  a_\gamma & = \sum_{t=1}^T\left(\sum_{j=1}^t\gamma_j\right)^2/2V\\
  b_\gamma &=\sum_{t=1}^T(y_t-\gamma_0)\left(\sum_{j=1}^t\gamma_j\right)/V
\end{align*}
(Section \ref{sec:LLM:fullcond}). So the dependence between $V$ and $b_V$ determines how much the chain moves in the $V$ step, and the dependence between $W$ and $(a_\gamma , b_\gamma)$ determines how much it moves in the $W$ step. The dependence between $(V,W)$ and $\gamma$ determines how much the chain moves in the DA step, but we can view this step instead as a draw of $b_V$ in which case the dependence between $W$ and $b_V$ determines how much the chain moves. So if any one of these steps has high dependence, we should expect every element of the chain, and $(V,W)$ in particular, to have high serial dependence in the chain. The scaled error sampler is analogous to the scaled disturbance sampler except with $b_W$, $a_\psi$ and $b_\psi$ where again
\begin{align*}
  a_\psi&=\sum_{t=1}^T(L\psi_t)^2/2W\\
  b_\psi&=\sum_{t=1}^T(L\psi_tLy_t)/W.
\end{align*}
(Section \ref{sec:LLM:fullcond}).

\begin{figure}[!ht]
\centering
\includegraphics[width=0.24\textwidth]{corplot1}
\includegraphics[width=0.24\textwidth]{corplot2}
\includegraphics[width=0.24\textwidth]{corplot3}
\includegraphics[width=0.24\textwidth]{corplot4}
\includegraphics[width=0.24\textwidth]{corplot5}
\includegraphics[width=0.24\textwidth]{corplot6}
\includegraphics[width=0.24\textwidth]{corplot7}
\includegraphics[width=0.24\textwidth]{corplot8}
\caption{Posterior correlation between $V$ or $W$ and $b_V$, $b_W$, $a_\gamma$, $b_\gamma$, $a_\psi$ or $b_\psi$. $X$ and $Y$ axes indicate the true values of $V$ and $W$ respectively for the simulated data with $T=100$.}
\label{corplot}
\end{figure}

In order to analyze the scaled disturbance sampler, we can look at each step separately and combine them together. First, suppose $R^*>1$. Then from Figure \ref{corplot} $b_V$ has high correlation with $V$ and low correlation with $W$, so the draw of $b_V$ should not move the chain much. Next, the draw of $V$ should again not move the chain much because of the high correlation between $V$ and $b_V$. Finally the draw of $W$ has a fair chance to move the chain because it has low correlation with both $a_\gamma$ and $b_\gamma$. But this has little impact on $b_V$ and thus the entire chain since $b_V$ is so hignhly correlated with $V$ but hardly correlated with $W$. So when $R^*>1$, we should expect high serial dependence and low ESP for $V$. We should also expect similar behavior for $W$ since the entire chain is hardly moving so $W$'s hyperparameters are hardly moving. This is roughly what we see in Figure \ref{baseESplot}, though this reasoning does not allow us to predict which of $V$ and $W$ will have lower ESP. When $R^*<1$ the posterior correlation in each of the steps is broken though in the $W$ step the correlation between $W$ and both $a_\gamma$ and $b_\gamma$ becomes negative and somewhat high. Here we should expect much less serial dependence in both $V$ and $W$ and indeed, we see ESP's near one for both variances in Figure \ref{baseESplot}.

The scaled error sampler is analogous to the scaled disturbance sampler and a similar analysis applies --- the posterior correlations between $V$ \& $W$ and $b_W$, $a_\psi$ \& $b_\psi$ in Figure \ref{corplot} roughly predict the ESP of the scaled error sampler in Figure \ref{baseESplot}. When one or more of the correlations are high, ESPs for $V$ and $W$ are low while when all of the correlations are low, both ESPs are high. We omit a similar analysis of the wrongly-scaled samplers for brevity.

\subsection{GIS and CIS Results}

We fit the LLM to the simulated datasets using several GIS samplers and a CIS sampler as well. Since the wrongly-scaled samplers behaved similarly to the state sampler and neither of the underlying DAs were a SA for $V$ and $W$ jointly, we ignored them in the construction of the GIS samplers. Instead, we constructed the State-SD, State-SE, SD-SE, and Triple (State-SD-SE) GIS samplers, as well as the CIS sampler, Algorithm \nameref{alg:DLMcis}. 

Based on the intuition in Section \ref{sec:Intro}, both the GIS and alternating algorithms should work best when at least one of the underlying base algorithms has a high ESP --- when least one of the underlying algorithms has low serial dependence in the chain, the we should have low serial dependence in the GIS and alternating algorithms since the serial dependence in the bad DA algorithm is broken by adding a lower dependence step before the next iteration. This suggests that the SD-SE GIS and alternating algorithms will have the best performance of the GIS and alternating algorithms using two DAs for both $V$ and $W$, especially for $R^*$ far away from one. When $R^*$ is near one it may offer no improvement however, especially for large $T$.

There are a couple of ways to gain some intuition about what we expect the CIS algorithm to do before seeing the results. First, we showed in Section \ref{sec:Algs:CIS} that the CIS and the SD-SE GIS algorithm consist of the same steps, just rearranged. This suggests that they should perform similarly so that we expect the CIS algorithm to have good mixing for both $V$ and $W$ when $R^*$ is sufficiently different from one. We can draw the same conclusion in a different way by noticing that in the Gibbs step for $V$, the CIS algorithm interweaves between the states and the scaled errors and in the Gibbs step for $W$ it interweaves between the states and the scaled disturbances. Since the state sampler has a high ESP for $V$ when $R^*<1$ and the scaled disturbance sampler has a high ESP for $V$ when $R^*>1$ we should expect the CIS sampler to have a high ESP for $V$ when $R^*$ is different from one. Similarly, since the state sampler has a high ESP for $W$ when $R^*>1$ and the scaled error sampler has a high ESP for $W$ when $R^*<1$, we should expect the CIS sampler to have a high ESP for $W$ when $R$ is different from one.

\begin{figure}[!ht]
\centering
\includegraphics[width=0.7\textwidth]{intESplot1}
%\includegraphics[width=0.7\textwidth]{intESplot2}
\caption{ESP in the posterior sampler for $V$ and $W$ in for $T=100$ in all four GIS samplers based on any two or three of the states, scaled disturbances and scaled errors as well as the CIS sampler.}
\label{intESplot}
\end{figure}

We can verify most of these intuitions in Figure \ref{intESplot}. First, the State-SD GIS algorithm has high ESP for $W$ except for a narrow band where $R^*$ is near one. The State-SD GIS algorithm's mixing behavior for $V$ appears identical to the original state sampler --- high ESP when $R^* < 1$ and poor ESP when $R^* > 1$. So this algorithm behaves as expected --- it takes advantage of the fact that the state and scaled disturbance DA algorithms make up a ``beauty and the beast'' pair for $W$ and thus improves mixing in the marginal chain for $W$. However, the two underlying DA algorithms behave essentially identically for $V$ so there is no improvement in that marginal chain. Similarly the State-SE GIS algorithm's ESP for $W$ is essentially identical to the state and scaled error algorithms' ESP for $W$ --- high when $R^*$ large and low when $R^*$ small. For $V$, the State-SE algorithm has a high ESP when $R^*$ is far enough away from one, especially when $T$ is small. The SD-SE GIS algorithm also behaves as predicted --- when $R^*$ is not too close to one it has high ESP for both $V$ and $W$, though it has extra trouble with $W$ when $R^*$ is less than one but not small enough. The SD-SE GIS algorithm behaves apparently identically to the CIS and triple GIS algorithms. The first of these is not surprising --- based on the intuition that the SD-SE GIS and CIS algorithms are the same up to a reordering of each of their steps, we expected little if any difference. However, we had some hope that the Triple GIS algorithm would improve upon the SD-SE GIS algorithm somewhat by further breaking the correlation between iterations in the Markov chain. 

\begin{figure}[!ht]
\centering
\includegraphics[width=0.7\textwidth]{altESplot1}
%\includegraphics[width=0.7\textwidth]{altESplot2}
\caption{ESP in the posterior sampler for $V$ and $W$ in for $T=100$ in all four alternating samplers based on any two or three of the states, scaled disturbances and scaled errors.}
\label{altESplot}
\end{figure}


We also fit each alternating sampler that corresponds to one of the GIS samplers we fit, that is the State-SD, State-SE, SD-SE and Triple (State-SD-SE) Alt samplers. Figure \ref{altESplot} contains the ESP of these samplers for both $V$ and $W$. There appears to be little practical difference between the alternating and interweaving versions of a given algorithm based on any two or three of the base DAs --- both take advantage of the beauty and the beast nature of their underlying DAs, but apparently dependence between the two DAs prevents the GIS version of the sampler from improving on the alternating version. All of these results are summarized in Table \ref{tab:stnmix2} without distinguishing between the interweaving and alternating versions of an algorithm. We include simulations with differing sizes of $T$ using these samplers in the supplementary materials, but the upshot is that, like with the base samplers, increasing the length of the time series worsens ESP for both $V$ and $W$ in all samplers and shrinks the area of the parameter space in which ESP is high.

\begin{table}
  \centering
  \begin{tabular}{|l|ccccc|}\hline
    Parameter & State-SD        & State-SE       & SD-SE        & Triple            & Full CIS \\\hline
    V         & $R^* < 1$           & $R^* \not\approx 1$ & $R^* \not\approx 1$ & $R^* \not\approx 1$ & $R^* \not\approx 1$ \\
    W         & $R^* \not\approx 1$ & $R^* > 1$           & $R^* \not\approx 1$ & $R^* \not\approx 1$ & $R^* \not\approx 1$\\\hline
  \end{tabular}
  \caption{Rule of thumb for when each interweaving or alternating algorithm has a high ESP for each variable as a function of the true signal-to-noise ratio, $R^*=W^*/V^*$. Note that as the length of the time series increases, the farther away from one $R^*$ has to be for the sampler to have a high ESP.}
  \label{tab:stnmix2}
\end{table}

\matt{Any chance we can change the figures to avoid using scientific notation for V and W?}

\subsection{Computational time}\label{sec:LLM:time}

A more important question than how well the chain mixes from a practical standpoint is the full computational time required to adequately characterize the targer posterior distribution. In order to investigate this, we compute the natural log of the average time in minutes required for each sampler to achieve an effective sample size of 1000 --- in other words the log minutes per 1000 effective draws. All simulations were performed on a university cluster with Intel Xeon X5675 3.07 GHz processors. While different systems will yield different absolute times, the relative times should at least be similar. Figure \ref{baseinttimeplot} contains plots of the log minutes per 1000 effective draws for both $V$ and $W$ and for each of the base and interweaving samplers.

For $T=100$ we see that the pattern we saw for ESP begins also appears for time per 1000 effective draws. The state sampler becomes slow to reach 1000 effective draws for $V$ when $R^*>1$ and for $W$ when $R^*<1$. The scaled disturbance and scaled error samplers behave as expected --- the scaled disturbance sampler is slow for both $V$ and $W$ when $R^*>1$ while the scaled disturbance sampler is slow for both $V$ and $W$ when $R^*<1$. The SD-SE GIS, Triple GIS and Full CIS algorithms appear to be the big winners here and are almost indistinguishable. All three algorithms are slightly slower for both $V$ and $W$ when $R^*$ is near one, though for larger $T$ (plots available in the supplemental materials) when $R^*$ is near or below one all three are slow for $W$. Compared to the state sampler though, all three offer large gains over most of the parameter space. When we compare the GIS algorithms to their alternating counterparts in terms of log minutes per 1000 effective draws there is little difference. Figure \ref{altinttimeplot} shows the log time per 1000 effective draws for the alternating algorithms and we see essentially the same pattern as we saw for the GIS algorithms with no clear advantage to the alternating or interweaving version of any algorithm.


\begin{figure}[!ht]
\centering
\includegraphics[width=0.8\textwidth]{baseinttimeplot1}
%\includegraphics[width=0.8\textwidth]{baseinttimeplot2}
\caption{Log of the time in minutes per 1000 effective draws in the posterior sampler for $V$ and $W$, for $T=100$ in the state, scaled disturbance and scaled error samplers and for all five interweaving samplers.}
\label{baseinttimeplot}
\end{figure}


\begin{figure}[!ht]
\centering
\includegraphics[width=0.7\textwidth]{altinttimeplot1}
%\includegraphics[width=0.8\textwidth]{altinttimeplot2}
\caption{Log of the time in minutes per 1000 effective draws in the posterior sampler for $V$ and $W$, for $T=100$ in the alternating samplers.}
\label{altinttimeplot}
\end{figure}

\section{Discussion}\label{sec:Discuss}

\subsection{Applicability to other DLMs}\label{sec:Discuss:F}

In Section \ref{sec:DAs:error} we assumed that $F_t$ is square and invertible for all $t$ which made the construction of the scaled error sampler and other samplers that use the scaled errors easier. However, most DLMs do not have $F_t$'s which are square, let alone invertible. The samplers we constructed can still be used in this case with one tweak: an additional DA is required in order to ensure that $F_t$ is square and invertible for all $t$. The basic strategy is to add elements to $y_t$ or $\theta_t$ or both until $F_t$ is invertible, then add an additional step to the sampler in order to draw the new augmentation. A second issue is that often $G_t$ or $F_t$ or both depend on some unknown parameter which must also be sampled from in the various MCMC samplers. The second case is easily dealt with simply by adding another sampling step for the unknown parameters in $F_t$ and $G_t$. The following example shows how to deal with the first case.

Consider the dynamic regression model
\begin{align*}
y_t & = \alpha_t + x_t\beta_t + v_t\\
\alpha_t & = \alpha_{t-1} + w_{1,t}\\
\beta_t & = \beta_{t-1} + w_{2,t}\\
\end{align*}
for $t=1,2,\cdots,T$ with $v_{1:T}$ independent of $w_{1:T} = (w_{1,1:T},w_{2,2:T})$, $v_t\stackrel{iid}{\sim} N(0,V)$ and $w_t \stackrel{iid}{\sim}N_2(0,W)$.  Here$\theta_t=(\alpha_t,\beta_t)'$ denotes the latent state for period $t$. The problem $F_t=[1,x_t]$ is not square nor invertible. But notice that the matrix
\[
F^*_t = \begin{bmatrix} 1 & x_t \\ 0 & 1 \end{bmatrix}
\]
is invertible. Now we add an additional DA $z_t$ to $y_t$ to construct $y_t^* = (y_t, z_t)'$ so that now the model is
\begin{align*}
y_t^* &= F_t^*\theta_t + v_t^*
\theta_t = \theta_{t-1} + w_t
\end{align*}
where $v_t^* = (v_t, u_t)$ where $u_{1:T}$ is independent of $(v_{1:T}, w_{1:T})$ and $u_t\stackrel{iid}{\sim} N(0,1)$. By construction $v_t^*\stackrel{iid}{\sim} N_2(0,V^*)$ where $V^*=diag(V,1)$ and the full conditional distribution of $z_t$ is $N(\beta_t,1)$. Then we define the scaled errors as $\psi_0 = \theta_0$ and $\psi_t=L_{V^*}^{-1}(y_t^* - F_t^*\theta_t)$. Let $z=z_{1:T}$ and $y^*=y^*_{1:T}$ for brevity.

In any of the samplers we constructed, before drawing the scaled errors, $\psi$, a draw of $z$ is required to complete $y$. Then $F_t^*$, $V^*$ and $y_t^*$ replace $F_t$, $V$ and $y_t$ wherever they appear in the full conditional distributions of $\psi_{0:T}$ and $W$ from Section \ref{sec:Algs}. Similarly, before transforming to or from the scaled errors in any of the interweaving algorithms, $y^*$ needs is required so a draw of $z$ is necessary. This is best handled by an update of $z$ from its full conditional at the beginning of every iteration of the sampler so that $y^*$ can be treated as the full data vector throughout the iteration.

\subsection{Improving computational efficiency}

A major computational bottleneck in most of our algorithms occurs when we have to draw from $p(W|V,\gamma,y)$, $p(V|W,\psi,y)$, $p(V|W,\tilde{\gamma},y)$ or $p(W|V,\tilde{\psi},y)$. The densities $p(W|V,\gamma,y)$ and $p(V|W,\psi,y)$ have the form
\[
p(x)\propto x^{-\alpha-1}\exp\left[-ax + b\sqrt{x} - \beta/x\right]
\]
where $\alpha,\beta,a>0$, while the densities $p(W|V,\tilde{\psi},y)$ and $p(V|W,\tilde{\gamma},y)$ have the form
\[
p(x)\propto x^{-\alpha-1}\exp\left[ -ax + b/\sqrt{x} -c/x\right]
\]
where $\alpha,a,c>0$. When $b=0$, both of these densities are special cases of the generalized inverse Gaussian (GIG) distribution so perhaps the methods used to speed up draws from the GIG can be used here \cite{jorgensen1982statistical,dagpunar1989easily,devroye2012random}. On the other hand, it might be worth putting effort into drawing $V$ and $W$ jointly conditional on the (wrongly) scaled disturbances or the (wrongly) scaled errors. Using the scaled disturbances, the conditional distribution of $V$ given $W$ is inverse gamma in the LLM and inverse Wishart in the general DLM, so it is easy to derive the marginal density $p(W|\gamma,y)$. In our LLM example, this density turns out to be very difficult to sample from and, in particular, it is not easy to come up with a generally good approximation for rejection sampling or for a Metropolis step. 

The main problem is the interaction between the augmented data likelihood and the prior for the variance we used to scale the states, e.g. $p(y,\gamma|V,W)$ and $p(W)$. We initially chose inverse Wishart priors for $V$ and $W$ partially because they are standard and partially for computational convenience, i.e. they are conditional conjugate with the states which results in full Gibbs steps in the state sampler. But in this case, the may be a more convenient prior. In addition, there are well known inferential problems with this prior \matt{Can reference my paper with Ignacio} in the hierarchical model literature, e.g. \citeasnoun{gelman2006prior}, though it is unclear how much transfers over to the time series case. An alternative is to use the conditionally conjugate prior conditional on the scaled disturbances, or whichever DA we prefer.

The conditionally conjugate prior for $\sqrt{W}$ using the scaled disturbances as the DA is a Gaussian distribution --- strictly speaking this prior is on $\pm \sqrt{W}$. If we use this prior for $\pm\sqrt{V}$ as well, the $V$ step in the scaled disturbance sampler becomes a draw from the generalized inverse Gaussian distribution. This prior has been used by \citeasnoun{fruhwirth2011bayesian} and \citeasnoun{fruhwirth2008bayesian} to speed up computation while using the scaled disturbances in hierarchical models and by \citeasnoun{fruhwirth2010stochastic} for time series models with a DA similar to the scaled disturbances (the latent states are scaled, but not centered). We omit the results here, but using this prior on both variances does not alter our mixing results for any of the MCMC samplers --- effective sample sizes were basically the same with either prior. There is a trade-off in computation time to consider, however. For example when using the scaled disturbances, the draw of $W|V,\gamma,y$ is sped up by using the Gaussian prior on $\pm\sqrt{W}$ since it becomes a Gaussian draw while the $V|W,\gamma,y$ is slower since it becomes a generalized inverse Gaussian draw instead of an inverse gamma. The gains outweigh the costs, at least in the local level model.

In the general DLM, however, it is unclear whether this will hold. In particular in the scaled disturbance sampler, when $V$ is a matrix its full conditional becomes a matrix analogue of the generalized inverse Gaussian distribution. On the other hand, with the inverse Wishart priors, when $W$ is a matrix the full conditional of $W$ becomes a matrix analogue of the density in Section \ref{sec:LLM:fullcond} --- which is more general than the GIG distribution. It is not clear how efficiently either of these distributions can be sampled from.

\section{Appendix}\label{sec:Append}

\subsection{Efficiently drawing from $p(W|V,\gamma,y)$ and $p(V|W,\psi,y)$}\label{sec:Append:scale}
Both of these two densities are of the form
\begin{align*}
\log p(x) =  & -ax + b\sqrt{x} - (\alpha + 1)\log x -\beta/x + C 
\end{align*}
for $x>0$ where $C$ is some constant, $\alpha$ and $\beta$ are the hyperparameters for $x$, and $a>0$ and $b\in \Re$ are parameters that depend on the data, $y$, the relevant data augmentation ($\psi$ or $\gamma$), and the other variable ($W$ or $V$). This density is not a known form and is difficult to sample from. We provide two different rejection sampling strategies below that work well under different circumstances, and combine them into a single strategy.

\subsubsection{Adaptive rejection sampling}
One nice strategy is to use adaptive rejection sampling, e.g. \citeasnoun{gilks1992adaptive}. This requires $\log p(x)$ to be concave, which is easy enough to check. The second derivative of $\log p(x)$ is:
\begin{align*}
\frac{\partial^2 \log p(x)}{\partial x^2} &= -\frac{1}{4}bx^{-3/2} +(\alpha + 1)x^{-2} -2 \beta x^{-3}.
\end{align*}
Then we have
\begin{align*}
  &\frac{\partial^2 \log p(x)}{\partial x^2} < 0 \iff \\
  &-\frac{b}{4}x^{3/2} + (\alpha + 1)x - 2\beta < 0
\end{align*}
which would imply that $\log p(x)$ is concave. We can maximize the left hand side of the last equation very easily. When $b\leq 0$ the max occurs at $x=\infty$ such that $LHS > 0$, but when $b > 0$:
\begin{align*}
  \frac{\partial LHS}{\partial x} &= -\frac{3}{8}bx^{1/2} + \alpha + 1 = 0\\
  \implies & x^{max} = \frac{(\alpha + 1)^2}{b^2}\frac{64}{9}.
\end{align*}
Then we have
\begin{align*}
  LHS \leq LHS|_{x=x^{max}} = \frac{(\alpha + 1)^3}{b^2}\frac{64}{27} - 2\beta
\end{align*}
so that
\begin{align*}
  LHS|_{x=x^{max}} < 0 &\iff  \frac{(\alpha + 1)^3}{b^2}\frac{64}{27} < 2\beta\\
    &\iff b > \left(\frac{(\alpha + 1)^3}{\beta}\right)^{1/2}\frac{4\sqrt{2}}{3\sqrt{3}}.
\end{align*}
This last condition is necessary and sufficient for $\log p(x)$ to be globally (for $x>0$) concave since $b < 0$ forces $LHS > 0$ for some $x$. When the condition is satisfied, we can use adaptive rejection sampling --- which is already implemented in the \verb0R0 package \verb0ars0. We input the initial evalutions of $\log p(x)$ at the mode $x^{mode}$ and at $2x^{mode}$ and $0.5x^{mode}$ in order to get the algorithm going.

\subsubsection{Rejection sampling on the log scale}
When $b \leq \left(\frac{(\alpha + 1)^3}{\beta}\right)^{1/2}\frac{4\sqrt{2}}{3\sqrt{3}}$, which happens often --- especially for small $T$ --- we need to rely on a different method to sample from $p(x)$. A naive approach would be to construct a normal or $t$ approximation to $p(x)$ and use that as a proposal in a rejection sampler. It turns out that this is often very inefficient, but for $y=\log(x)$ the approach works well. Note that
\begin{align*}
  p_y(y) = p_x(e^y)e^y
\end{align*}
so that we can write the log density of $y$ as (dropping the subscripts):
\begin{align*}
  \log p(y) = -ae^y + be^{y/2} - \alpha y - \beta e^{-y}.
\end{align*}
The mode of this density $y^{mode}$ can be easily found numerically, and the second derivative is:
\begin{align*}
  \frac{\partial^2 \log p(y)}{\partial y^2} = -ae^y + \frac{b}{4}e^{y/2} - \beta e^{-y}.
\end{align*}
The $t$ approximation then uses the proposal distribution 
\begin{align*}
  t_{v}\left(y^{mode}, \left[-\left.\frac{\partial^2 \log p(y)}{\partial y^2}\right|_{y=y^{mode}}\right]^{-1}\right).
\end{align*}
In practice choosing degrees of freedom $v=1$ works very well over the region of the parameter space where adaptive rejection sampling cannot be used. We can easily use this method when adaptive rejection sampling does not work, then transform $y$ back to $x$. It remains to check that the tails of $t$ distribution dominate the tails of our target distribution. Let $\log q(y)$ denote the log density of the proposoal distribution. Then we need
\begin{align*}
  \log p(y) - \log q(y) \leq M\\
  \intertext{for some constant M, i.e.}
  -ae^y + be^{y/2} - \alpha y - \beta e^{-y} -\left(\frac{v+1}{2}\right)\log\left[1 + \frac{1}{v}\left(\frac{y-\mu}{\sigma}\right)\right]\leq M
\end{align*}
where $a>0$, $\alpha>0$, $\beta>0$, $v>0$, $\sigma>0$, and $b,\mu\in \Re$. We can rewrite the LHS as
\begin{align*}
    e^{y/2}(b-ae^{y/2}) - \alpha y - \beta e^{-y} -\left(\frac{v+1}{2}\right)\log\left[1 + \frac{1}{v}\left(\frac{y-\mu}{\sigma}\right)\right].
\end{align*}
So as $y\to\infty$ this quantity goes to $-\infty$ since the first term will eventually become negative no matter the value of $b$, and all other terms are always negative. Similarly as $y\to\-\infty$ this quantity goes to $-\infty$. Now pick any interval $(y_1,y_2)$ such that outside of the interval, $LHS<\epsilon$. Since treated as a function of $y$ the LHS is clearly continuous, it attains a maximum on this interval, and thus is bounded.

\subsubsection{Intelligently choosing a rejection sampler}
In practice, adaptive rejection sampling is relatively efficient for $p_x(x)$ but inefficient for $p_y(y)$ --- so much so that rejection sampling with the $t$ approximation for $p_y(y)$ is more efficient. To minimize computation time, it is best to use adaptive rejection sampling for $p_x(x)$ when the concavity condition is satisfied. When it is not, the $t$ approximation works well enough.

\subsection{Efficiently drawing from $p(W|V,\tilde{\gamma},y)$ and $p(V|W,\tilde{\psi},y)$ in the LLM}\label{sec:Append:wscale}

Both the density of $\log(W)|V,\tilde{\gamma}_{0:T},y_{1:T}$ and the density of $\log(V)|W,\tilde{\psi}_{0:T},y_{1:T}$ have the following form:
\begin{align*}
  p(y)\propto \exp\left[-\alpha y - ae^{-y} + be^{-y/2} - ce^y\right].
\end{align*}
where $\alpha>0$, $a>0$, $c>0$, and $b\in \Re$. The log density is:
\begin{align*}
  \log p(y) = -\alpha y - ae^{-y} + be^{-y/2} - ce^y + C
\end{align*}
where $C$ is some constant. We only provide one strategy for rejection sampling from this density: the $t$ approximation. Similar reasoning to above shows that we can use a $t$ distribution as a proposal in a rejection sampler. Now we choose the location parameter by maximizing $\log p(y)$ in $y$ numerically to find the mode, $y^{mode}$. Next the second derivative of $\log p(y)$ is given by
\begin{align*}
  \frac{\partial^2 \log p(y)}{\partial y^2} = -ae^{-y} + \frac{b}{4}e^{-y/2}-ce^y.
\end{align*}
We then set the scale parameter to be
\begin{align*}
  -\left[\left.\frac{\partial^2 \log p(y)}{\partial y^2}\right|_{y=y^{mode}}\right]^{-1}
\end{align*}
as in the normal approximation, and the degrees of freedom parameter to $v=1$. This rejection sampler is tolerably efficient for our purposes, but it is not fast.



\clearpage
\bibliographystyle{ECA_jasa}  % proper bibliography style for ASA
\bibliography{dlmasis}
\end{document}

