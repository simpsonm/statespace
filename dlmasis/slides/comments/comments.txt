From Jarad:

For future talks, I suggest you start with the simple example from Yu
and Meng as it provides a simple scenario that everybody will
understand with a pretty impressive result.

Then, you can talk about the different algorithms/augmentations,
although I would probably leave out description of the CIS since it
looks pretty complicated. I actually liked when you pointed out that
the CIS is just two GIS's put together conditioning on part of the
parameter vector for each part. I think that was enough explanation.

Then turn to DLMs and discuss how these different
algorithms/augmentations would be implemented in these models. And
show results for how well they work. There is no reason to explain
effective sample size and effective sample proportion is pretty
obvious.

With that being said, the results were a little underwhelming since
much of the T=1000 figures were red. Somehow I thought we were doing
better than this in particular with the Error-Disturbance interweaving
sampler. This is one reason why I want the document written up is so
that I have a context for the results we have.

One comment you made was that it is hard to construct a sampler for
p(\phi|y). In DLMs this may not so hard since, conditional on \phi,
you can integrate out \theta. So at least when \phi is low
dimensional, you should be able to construct a sampler for it. This
brings up a computational aspect of the problem (that is not solvable
by parallelization) since integrating out \theta is computationally
expensive especially for large T.

In general (from everyone):

Start slower with more examples. Vivek says I should give a really simple example of the data augmentation algorithm - model the lowest common denomenator in the talk: make sure s/he is up to speed with really simple examples; then move quickly if necessary.

In my context: 
   simple example for interweaving
   simple example for data augmentation
   

Vivek: is the joint distribution of (theta, theta~, phi) really needed? Look at the discussion paper of the original interweaving paper to see (Jim Hobert's discussion in particular)

Note: ASIS is the optimal PX-DA in a particular class (make sure I say that)

Jarad has some good comments: read them.
