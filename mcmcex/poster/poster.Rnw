%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% a0poster Portrait Poster
% LaTeX Template
% Version 1.0 (22/06/13)
%
% The a0poster class was created by:
% Gerlinde Kettl and Matthias Weiser (tex@kettl.de)
% 
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[a0,portrait]{a0poster}

\usepackage{multicol} % This is so we can have multiple columns of text side-by-side
\columnsep=100pt % This is the amount of white space between the columns in the poster
\columnseprule=0pt % This is the thickness of the black line between the columns in the poster

\usepackage[svgnames]{xcolor} % Specify colors by their 'svgnames', for a full list of all colors available see here: http://www.latextemplates.com/svgnames-colors

\usepackage{times} % Use the times font
%\usepackage{palatino} % Uncomment to use the Palatino font

\usepackage{graphicx} % Required for including images
\graphicspath{{figures/}} % Location of the graphics files
\usepackage{booktabs} % Top and bottom rules for table
\usepackage[font=small,labelfont=bf]{caption} % Required for specifying captions to tables and figures
\usepackage{amsfonts, amsmath, amsthm, amssymb} % For math fonts, symbols and environments
\usepackage{wrapfig} % Allows wrapping text around tables and figures
\usepackage[authoryear]{natbib} %numbers instead of authoryear for [1] instead of [1980]
\usepackage{float}

\newtheorem{alg}{Algorithm}

\usepackage[framemethod=tikz]{mdframed}
\newmdenv[innerlinewidth=6pt, roundcorner=12pt,linecolor=DarkSlateGrey,
innerleftmargin=6pt,innerrightmargin=6pt,innertopmargin=6pt,
innerbottommargin=6pt,backgroundcolor=White]{mybox}

%\pagecolor{Gold!20}

<<setup, include=FALSE, cache=FALSE>>=
options(replace.assign=TRUE,width=90)
opts_knit$set(eval.after = "fig.cap")
opts_chunk$set(dev="pdf",
               fig.lp = "",
               fig.keep="high",
               fig.show="hold",
               fig.align="center",
               fig.pos="H",
               fig.env="figure")
@ 


<<plotsetup, echo=FALSE, message=FALSE>>=
library(ggplot2)
library(scales)
library(plyr)
library(xtable)
library(reshape2)
library(gridExtra)
load("../mixing/samout.RData")
load("../mixing/postcors.RData")
samouttemp <- samout
load("../cis/cissamout.RData")
samout1 <- samout
samout <- rbind(samout1,samouttemp)
base <- c("error", "state", "dist")
alts <- c("sdalt", "sealt", "dealt", "trialt")
ints <- c("sdint", "seint", "deint", "triint")
kerns <- c("sdkern", "sekern", "dekern", "trikern")
cis <- c("fullcis", "partialcis")
samout$V.ES[samout$sampler %in% kerns] <- samout$V.ES[samout$sampler %in% kerns]*2
samout$W.ES[samout$sampler %in% kerns] <- samout$W.ES[samout$sampler %in% kerns]*2
samout$V.ES[samout$sampler == "trikern"] <- samout$V.ES[samout$sampler == "trikern"]*(3/2)
samout$W.ES[samout$sampler == "trikern"] <- samout$W.ES[samout$sampler == "trikern"]*(3/2)
samout$type <- "Base" #$
samout$type[samout$sampler %in% alts] <- "Alt" 
samout$type[samout$sampler %in% ints] <- "GIS" 
samout$type[samout$sampler %in% kerns] <- "RKern" 
samout$type[samout$sampler %in% cis] <- "CIS" 
samout$samplers <- "Base"
samout$samplers[substr(samout$sampler, 1, 2)=="sd"] <- "State-Dist" 
samout$samplers[substr(samout$sampler, 1, 2)=="se"] <- "State-Error" 
samout$samplers[substr(samout$sampler, 1, 2)=="de"] <- "Dist-Error" 
samout$samplers[substr(samout$sampler, 1, 3)=="tri"] <- "Triple" 
samout$samplers[samout$sampler=="fullcis"] <- "FullCIS"
samout$samplers[samout$sampler=="partialcis"] <- "PartialCIS"
samout$samplers[samout$sampler=="error"] <- "Error"
samout$samplers[samout$sampler=="dist"] <- "Dist"
samout$samplers[samout$sampler=="state"] <- "State"
samlevels <- c("State", "Dist", "Error", "State-Dist", "State-Error", "Dist-Error", 
               "Triple", "FullCIS", "PartialCIS")
samout$samplers <- factor(samout$samplers, levels=samlevels)
meltedsam <- melt(samout, id=c("type", "samplers", "sampler", "V.T", "W.T", 
                            "T.T"))
Vs <- unique(meltedsam$V.T)[1:9] #$
Ws <- Vs
breaks <- Vs[seq(1,9,2)]
label_both_parsed <- function(variable, value){
  llply(as.character(paste(variable, value, sep = ": ")), function(x) parse(text = x))
}
label_both_parsed_split <- function(variable, value){
  llply(as.character(paste(variable, value, sep = ": ")), 
        function(x) parse(text = strsplit(x, "\\.")[[1]][1]))
}
label_parsed_split <- function(variable, value){
  llply(as.character(value), function(x) parse(text = strsplit(x, "\\.")[[1]][1]))
}
meltedcors <- melt(postcors, id=c("V.T", "W.T", "T.T"))
## opts_chunk$set(fig.width=7, fig.height=4, out.width='1\\textwidth', 
##               fig.pos='!ht') #$
plotfun <- function(meltedsam, vars, sams, T, title){
  castedsam <- dcast(meltedsam, formula=sampler + V.T + W.T + variable + samplers ~ ., 
                     subset=.(variable %in% vars  & T.T==T & sampler %in% sams &
                       V.T<=10^2 & W.T<=10^2))
  colnames(castedsam)[6] <- "value"
  out <- ggplot(data=castedsam, aes(x=V.T, y=W.T, fill=value/2500)) + #$
         geom_tile() +
         scale_fill_gradient("ESP", low=muted("red"), high="white",
           guide=guide_colorbar(barheight=10),
           limits=c(0,1), na.value="white") +
         facet_grid(variable~samplers, scales="free", labeller=label_parsed_split) +
         scale_x_log10("V = noise", breaks=breaks) + scale_y_log10("W = signal", breaks=breaks) +
         ggtitle(paste(title, T, sep="")) +
         theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust=0.5))
  return(out)
}
plotfun2 <- function(vars, sams, T){
  var <- substr(vars[1], 1, 1)
  castedsam <- dcast(meltedsam, 
                     formula=samplers + V.T + W.T + variable + type ~ ., 
                     subset=.(variable %in% vars  & T.T==T & 
                       sampler %in% sams & V.T<=10^2 & W.T<=10^2))
  colnames(castedsam)[6] <- "value"
  out <- ggplot(data=castedsam, aes(x=V.T, y=W.T, fill=value/2500)) + #$
          geom_tile() +
          scale_fill_gradient("ESP", low=muted("red"), high="white",
                        guide=guide_colorbar(barheight=7),
                        limits=c(0,1), na.value="white") +
          facet_grid(type~samplers, scales="free", labeller=label_parsed_split) +
          scale_x_log10("V = noise", breaks=breaks) + 
          scale_y_log10("W = signal", breaks=breaks) +
          ggtitle(paste("ESP for ", var, "; T=",T,sep="")) +
          theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust=0.5))
  return(out)
}
@

\begin{document}

%----------------------------------------------------------------------------------------
%	POSTER HEADER 
%----------------------------------------------------------------------------------------

% The header is divided into two boxes:
% The first is 75% wide and houses the title, subtitle, names, university/organization and contact information
% The second is 25% wide and houses a logo for your university/organization or a photo of you
% The widths of these boxes can be easily edited to accommodate your content as you see fit

\begin{minipage}[b]{0.75\linewidth}
\veryHuge \color{DarkRed} \textbf{Ancillarity--Sufficiency or not} \color{Black}\\ % Title
\Huge\textit{Interweaving to improve MCMC estimation of DLMs}\\[2cm] % Subtitle
\huge \textbf{Matthew Simpson}\\[0.5cm] % Author(s)
\huge Iowa State University, Departments of Statistics and Economics\\[0.4cm] % University/organization
\Large \texttt{themattsimpson@gmail.com} \\
\end{minipage}
\begin{minipage}[b]{0.25\linewidth}
\includegraphics[width=15cm]{logo.png}\\
\end{minipage}

\vspace{1cm} % A bit of extra whitespace between the header and poster content

%----------------------------------------------------------------------------------------

\begin{multicols}{2} % This is how many columns your poster will be broken into, a portrait poster is generally split into 2 columns

%----------------------------------------------------------------------------------------
%	ABSTRACT
%----------------------------------------------------------------------------------------

\color{Red} % color for the abstract

\begin{abstract}
In dynamic linear models (DLMs), MCMC sampling can often be very slow for estimating the posterior density --- especially for longer time series. In particular, in some regions of the parameter space the standard data augmentation algorithm can mix very slowly. Recently ancillarity-sufficiency interweaving has been introduced as a method to take advantage of alternate parameterizations in multilevel models in order to improve the mixing and convergence properties of the chain. Focusing on the local level DLM, we explore alternate parameterizations and various interweaving algorithms through simulation in order to improve mixing. 
\end{abstract}

\color{DarkSlateGrey}

\section*{Model and priors}

The local level model is a univariate DLM with data $y_t$ for $t=1,2,\cdots,T$ and univariate latent state $\theta_t$ for $t=0,2,\cdots,T$ that satisfies
\begin{align*}
  y_t |\theta_{0:T}& \stackrel{ind}{\sim} N(\theta_t,V) \\
  \theta_t |\theta_{0:t-1}& \sim N(\theta_{t-1},W).
\end{align*}
The unknown parameter vector is $\phi=(V,W)$. For priors, we'll take $\theta_0\sim N(m_0,C_0)$, $V\sim IG(\alpha_V, \beta_V)$, and $W\sim IG(\alpha_W, \beta_W)$ where $(\theta_0,V,W)$ are mutually dependent, and $m_0$, $C_0>0$, $\alpha_V>0$, $\beta_V>0$, $\alpha_W>0$, and $\beta_W>0$ are some known constants.

\section*{The standard MCMC approach and its limitations}
The standard MCMC sampling algorithm for the local level model and DLMs generally is a data augmentation (DA) algorithm that uses $\theta_{0:T}$ as an augmented data vector and forward filtering backward sampling (FFBS) in order to draw from $p(\theta_{0:T}|V,W,y_{1:T})$, see \citet{fruhwirth1994data} and \citet{carter1994gibbs}. Call this algorithm the {\it \color{red} state sampler}. One problem with this algorithm is that in some regions of the parameter space the Markov chain mixes poorly for some of the parameters. A well known method of improving mixing and convergence in MCMC samplers is reparameterizing the model, e.g. \citet{papaspiliopoulos2007general}. A recent approach that builds on reparameterizing is the interweaving strategy of \citet{yu2011center}.

\section*{Interweaving --- GIS, ASIS, and CIS}
Interweaving samplers are a class of algorithms for MCMC by \citeauthor{yu2011center} that rely on using multiple DAs within one iteration. In the general case, let $y$ denote the data vector, $\phi$ the parameter vector, $\theta$ a DA, and $\gamma$ another DA. Global interweaving strategy (GIS) samplers obtain $\phi^{(k+1)}$ from $\phi^{(k)}$ by:
\[
[\theta|\phi^{(k)},y] \rightarrow [\phi^{(k+0.5)}|\theta,y] \rightarrow [\gamma|\theta,\phi^{(k+0.5)},y] \rightarrow [\phi^{(k+1)}|\gamma,y]
\]
When $\gamma$ is a one-to-one transformation of $\theta$, step 3 is an update using that transformation. The GIS algorithm is directly comparable to an alternating algorithm that draws $\gamma$ from $p(\gamma|\phi,y)$ in step 3 but is otherwise identical. If necessary, each of these steps can be broken down into separate Gibbs steps.

An ancillary sufficient interweaving strategy (ASIS) uses, in \citeauthor{yu2011center}'s words, a sufficient augmentation (SA) and an ancillary augmentation (AA). The DA $\theta$ is a SA for $\phi$ if $p(y|\theta,\phi)=p(y|\theta)$, while $\theta$ is an AA for $\phi$ if $p(\theta|\phi)=p(\theta)$. The advantage of ASIS over a generic GIS is that the SA and the AA are typically a ``beauty and the beast'' pair -- in all regions of the parameter space, the DA algorithm based on either the SA or the AA will have good mixing and convergence properties, allowing the ASIS algorithm to take advantage and have good properties.

Sometimes it's hard to find a SA or an AA or a given model. In that case, a componentwise inteweaving strategy (CIS) may be superior. Suppose $\phi=(\phi_1, \phi_2)$. A CIS algorithm uses a GIS algorithm in a Gibbs step for $\phi_1$, and another GIS algorithm in a Gibbs step for $\phi_2$, potentially using a different pair of DAs. In this setting, componentwise ASIS is possible --- we need a SA--AA pair of DAs for $\phi_1$, and another pair for $\phi_2$.

\section*{New DAs and algorithms for the local level model}
The states, $\theta_{0:T}$, are a SA for $V$ and an AA for $W$. We construct two more DAs for the local level model. Define the scaled disturbances as $\gamma_0=\theta_0$ and $\gamma_t=(\theta_t - \theta_{t-1})/\sqrt{W}$ for $t=1,2,\cdots,T$. The {\it \color{red} scaled disturbance sampler} is the DA algorithm based on the scaled disturbances, except it draws $V$ and $W$ in separate Gibbs steps instead of jointly like in the state sampler. It turns out that $\gamma_{0:T}$ is an AA for $(V,W)$. \citeauthor{fruhwirth2004efficient} uses the analogue of this augmentation in the context of a dynamic regression model.

Similarly, define the scaled errors as $\psi_0 = \theta_0$ and $\psi_t = (y_t - \theta_t)/\sqrt{V}$ for $t=1,2,\cdots,T$. The {\it \color{red} scaled error sampler} is the DA algorithm based on the scaled errors. The scaled error sampler also draws $V$ and $W$ in separate Gibbs steps and, like the scaled disturbances, it turns out that the scaled errors are also an AA for $(V,W)$. We aren't able to find a SA for $(V,W)$ however, so as far as we can tell there is no ASIS algorithm available.

This gives four separate GIS algorithms --- the {\it \color{red} state -- disturbance GIS algorithm} based on the states and the scaled disturbances, the {\it \color{red} state -- error GIS algorithm} based on the states and the scaled errors, the {\it \color{red} disturbance -- error GIS algorithm}, based on the scaled disturbances and the scaled errors, and the {\it \color{red} triple GIS algorithm} based on all three augmented data vectors. In all four algorithms, we use the various agumented data vectors in the order $\theta_{0:T}$, $\gamma_{0:T}$, then $\psi_{0:T}$. Other orders could change the properties of the algorithms, but \citeauthor{yu2011center} report that this choice doesn't seem to matter much in general.

We also construct a full CIS algorithm that uses $\theta_{0:T}$ and $\gamma_{0:T}$ in the Gibbs step for $W$ while using $\theta_{0:T}$ and $\psi_{0:T}$ in the Gibbs step for $V$. This full CIS algorithm can be shown to be identical to a componentwise ASIS algorithm and is also the same as the disturbance -- error GIS algorithm except with the order of some of the steps changed.

\section*{Simulation setup}
In order to investigate these algorithms, we simulated time series with length $T=10, 100, 1000$ over a grid of $V$--$W$ space. Then for each dataset, we fit the local level model using each algorithms mentioned above. We used the same priors for each dataset: $\theta_0\sim N(0,10^7)$, $V\sim IG(5, 4\tilde{V})$, and $W\sim IG(5, 4\tilde{W})$, mutually independent where $(\tilde{V},\tilde{W})$ are the true values of $V$ and $W$ used to simulate the time series. 

For each model and each sampler, we obtained $2500$ draws after a burn in of $500$ with each chain started at the true values used to simulate the time series. Define the effective sample proportion (ESP) for a scalar component of the chain as the effective sample size (ESS) of the component divided by the actual sample size, i.e. $ESP=ESS/n$. An $ESP=1$ indicates that the Markov chain is behaving as if it obtains iid draws from the posterior. 



\begin{mybox}
\color{DarkRed}
\section*{Results}
  
<<baseintESplot, fig.cap=cap, echo=FALSE, fig.width=10, fig.height=3.25, outwidth=".48\\textwidth">>=
cap <- ""
## Effective sample proportion in the posterior sampler for $V$ and $W$ in for $T=10$, $T=100$, and $T=1000$, in the state, scaled disturbance and scaled error samplers and for all three GIS samplers based on any two of these. Horizontal and vertical axes indicate the true values of $V$ and $W$ respectively for the simulated data. Note that the signal-to-noise ratio is constant moving up any diagonal. In the upper left the signal is high, in the lower right the noise is high. Note that for plotting purposes, effective sample proportions larger than one were rounded down to one.

vars <- c("V.ES", "W.ES")
sams <- c("dist", "error", "deint", "state", "seint", "sdint", "triint", "fullcis")
title <- "ESP for V and W in the base, GIS, and CIS algorithms, T="
p2 <- plotfun(meltedsam, vars, sams, 100, title)
p3 <- plotfun(meltedsam, vars, sams, 1000, title)
p2
p3
@ 

Figure \ref{baseintESplot} contains plots of ESP for $V$ and $W$ in each chain of each of the samplers for $T=100$, and $T=1000$. We'll focus on $T=100$ first. The state sampler has a low ESP for $V$ and a high ESP for $W$ when the signal-to-noise ratio, $W/V$, is larger than one and a low ESP for $W$ and a high ESP for $V$ when $W/V$ is less than one. The particular values of $V$ and $W$ don't seem to matter at all --- just their relative values. Moving up any diagonal on the plots for $V$ and $W$ in the state sampler, $W/V$ is constant and the ESS appears roughly constant. The basic lesson here is that the state sampler has mixing issues for whichever of $V$ or $W$ is smaller. 

The figure tells a different story for the scaled disturbance sampler. When $W/V$ is less than one, ESPs for both $V$ and $W$ are nearly one while when $W/V$ is greater than one ESPs for both $V$ and $W$ become small. The scaled error sampler has essentially the opposite properties. When $W/V$ is large, it has ESP near one for both $V$ and $W$. On the other hand, when $W/V$ is small is has a low ESP for both $V$ and $W$. None of these conclusions change as $T$ increases, though this exacerbates all mixing problems.

This suggests that the disturbance--error GIS will be better than any of the other two DA GIS algorithms because it has the ``beauty and the beast'' property over a wide ranger of the parameter space. This is true and in fact, the triple GIS and full CIS algorithms don't seem to do any better in any region of the parameter space. For all three of these samplers, ESPs for both $V$ and $W$ are high when $W/V$ is farther away from one, but lower when $W/V$ is near one.


<<hybridESplot, fig.cap=cap, echo=FALSE, fig.height=3, fig.width=5.5, out.width=".48\\textwidth">>=
cap <- ""
sams <- c(alts, ints)
plotfun2("V.ES", sams, 100)
plotfun2("W.ES", sams, 100)
@ 

Figure \ref{hybridESplot} shows the same plots for the full set of GIS algorithms and for their corresponding alternating algorithms, but only for $T=100$ in order to illustrate that the interweaving algorithm doesn't improve mixing over the corresponding alternating algorithm. However, GIS is a bit less computationally costly since the third step is a transformation instead of a draw from the joint distribution of a full augmented data vector.
\end{mybox}

\color{DarkSlateGrey}

\section*{Implications for general DLMs}
The scaled disturbances always exist as a possible DA in any DLM as a one-to-one transformation of the states. The scaled errors, on the other hand, are only a one-to-one transformation of the states in some special models. In other models they can be defined, but determining the relevant conditional distributions may be more difficult. So the disturbance -- error GIS algorithm can be defined, but it is not entirely clear at this point what quantity will play the role of the signal-to-noise ratio when $V$ and $W$ are (possibly time dependent) covariance matricies.

%\nocite{*} % Print all references regardless of whether they were cited in the poster or not
\bibliographystyle{plainnat} % Plain referencing style
\bibliography{mcmcex} % Use the example bibliography file sample.bib

\section*{Acknowledgements}
Jarad Niemi, Vivekananda Roy

\end{multicols}
\end{document}
