<<set-parent-disc, echo=FALSE, cache=FALSE>>=
set_parent('../mcmcex.Rnw')
@ 

\section{Discussion}\label{sec:Discussion}
Our results on computational time in Section \ref{sec:LLMtime} should be taken with a grain of salt because we did not put much effort into efficiently sampling from $p(W|V,\gamma_{0:T},y_{1:T}$ or $p(V|W,\psi_{0:T},y_{1:T})$. Both densities have the form
\[
p(x)\propto x^{-\alpha-1}\exp\left[-ax + b\sqrt{x} - \frac{\beta}{x}\right]
\]
where $\alpha,\beta,a>0$. This density is the same as the generalized inverse Gaussian distribution (see e.g. \citet{jorgensen1982statistical} for its properties; \citet{dagpunar1989easily} and \citet{devroye2012random} for generating random draws) when $b=0$, this is almost surely not the case in our application. It is possible that sampling from this density can be significantly improved in which case, the relative speed of the algorithms based on either the scaled errors or the scaled disturbances will improve significantly. On the other hand, it might be worth putting effort into drawing $V$ and $W$ jointly conditional on the scaled disturbances or the scaled errors. The conditional distribution of $V$ given $W$, $p(V|W,\gamma_{0:T},y_{1:T})$, is inverse gamma in our example and inverse Wishart in general, so it is easy to derive the marginal density $p(W|\gamma_{0:T},y_{1:T})$. In our local level model example, this density turns out to be very difficult to sample from and, in particular, is not easily approximated by a Gaussian distribution for rejection sampling or for a Metropolis step. 

We initially chose inverse Wishart priors for $V$ and $W$ partially because they are standard and partially for computational convenience. There are well known problems with this prior in the hierarchical model literature, e.g. \citet{gelman2006prior}, though less is known about the time series case. Given that the prior has potential problems and is inconvenient for the scaled disturbances and the scaled errors, a better choice of prior is probably out there. In particular, the conditionally conjugate prior for $\sqrt{W}$ using the scaled disturbances as the DA is a Gaussian distribution --- strictly speaking this prior is on $\pm \sqrt{W}$. If we use this prior for $\pm\sqrt{V}$ as well, the $V$ step in the Gibbs sampler becomes a draw from the generalized inverse Gaussian distribution. This prior has been used by \citet{fruhwirth2011bayesian} and \citet{fruhwirth2008bayesian} to speed up computation while using the scaled disturbances in hierarchical models and by \citet{fruhwirth2010stochastic} for time series models with a DA similar to the scaled disturbances (the latent states are scaled, but not centered). This prior seems particularly useful for variable selection problems, as evidenced by the papers which use it. We omit the results here, but using this prior does not alter our mixing results --- effective sample sizes were basically the same with either prior. There is a trade-off in computation time to consider, however. For example when using the scaled disturbances, the draw of $W|V,\gamma_{0:T},y_{1:T}$ is sped up by using the Gaussian prior on $\pm\sqrt{W}$ since it becomes a Gaussian draw while the $V|W,\gamma_{0:T},y_{1:T}$ is slower since it becomes a generalized inverse Gaussian draw instead of an inverse gamma. The gains outweigh the costs at least until a better way of sampling from $W$'s full conditional from the inverse gamma case is invented, but this only applies when $V$ is a scalar. When $V$ is a matrix, its full conditional becomes the matrix analogue of the generalized inverse Gaussian distribution and it is not clear how efficiently this density can be sampled from.

In our simulations with the original inverse gamma priors and the with the normal prior on the standard deviations we mentioned above, we varied the prior so that the prior mean was the true value of the parameters used to simulate the datasets. This may seem suspect at first glance, but there is a method to our madness. In the data augmentation for multilevel models literature, a key quantity is called the fraction of missing information (\citet{van2001art}, for example). When $\phi$ is the model parameter, $\theta$ is the data augmentation and $y$ is the data, the Bayesian fraction of missing information is defined as
\begin{align*}
  \mathcal{F}_B = I - [var(\phi|y)]^{-1}E[var(\phi|\theta,y)|y]
\end{align*}
while the EM fraction of missing information is defined as
\begin{align*}
  \mathcal{F}_{EM} = I - I_{obs}I_{aug}^{-1}
\end{align*}
where 
\begin{align*}
  I_{aug}=& \left.\mathrm{E} \left[-\left.\frac{\partial^2 \log p(\phi|\theta,y)}{\partial \phi \dot \partial \phi}\right| y,\phi\right]\right|_{\phi=\phi^*}\\
  \intertext{is the expected augmented Fisher information matrix and}
  I_{obs} =& -\left.\frac{\partial^2\log p(\phi|y)}{\partial\phi \dot \partial\phi}\right|_{\phi=\phi^*}
\end{align*}
is the observed fisher information matrix while $\phi^*$ is the posterior mode. The rate of convergence of the EM algorithm is governed by $\mathcal{F}_{EM}$ while the maximum lag-1 autocorrelation in the Gibbs sampler for any linear function of the model parameters is governed by $\mathcal{F}_{B}$ --- the larger the spectral radius of $\mathcal{F}$, the high the autocorrelation. While $\mathcal{F}_{B}$ is difficult to compute, $\mathcal{F}_{EM}$ is often easier and is a decent approximation to $\mathcal{F}_{B}$ to the degree that the posterior distribution is Gaussian. We currently cannot analytically compute either of these quantities in our model, but the significance of the signal-to-noise ratio in our results is likely related. In particular, the EM fraction of missing information requires the expected and observed information matrices at the posterior mode. So the behavior of the samplers likely depends on the posterior model signal-to-noise ratio, or perhaps the ratio of the posterior model signal to the posterior mode ratio (depending on whether we take the mode of $R$, of $V$ and $W$ separately or of $V$ and $W$ together). Given the way we choose our priors, the posterior mode of $(V,W)$ is likely to be close to the true values of $V$ and $W$ used to simulate the data, especially for longer time series. If we used the same prior for each simulation, the posterior mode and the true values of $V$ and $W$ are less likely to be close for some true values of $V$ and $W$. In fact, in simulations with a constant prior (details not reported here), plots such as Figure \ref{baseESplot} look somewhat similar but with a much less stark difference in ESP over different regions of the parameter space.

Some previous work has been done in choosing data augmentations for time series models. In the AR(1) plus noise model, \citet{pitt1999analytic} find that the signal to noise ratio along with the AR(1) coefficient determine the convergence rate of a Gibbs sampler. In addition, they find that as the length of the time series increases, the convergence rate slows down and compute asymptotic convergence rates for an infinite time series. Both of these results are consistent with our findings and further suggest that the signal-to-noise ratio will play a key role in the fraction of missing information, Bayesian or EM, however, \citeauthor{pitt1999analytic} assume that both of the variances are fixed for simplicity. In a continuous time model, \citet{roberts2004bayesian} find that the Gibbs sampler based on a NCP is at least as efficient as the Gibbs sampler based on the CP and sometimes it is much more efficient, depending on the true values of the parameters. It is unclear whether the time series dependence or something unique to the model is driving this, but it is interesting that the NCP is essentially always better. The dynamic regression model with a stationary AR(1) process on the regression coefficient has been studied in \citet{fruhwirth2004efficient}. They use both the states and the scaled disturbances and several other DAs motivated by some results for Gibbs samplers in the hierarchical model literature. When they examine the behavior of the resulting DA algorithms, \citeauthor{fruhwirth2004efficient} find that the relative behavior of the scaled disturbance (in their language, the ``noncentered disturbances'') and state samplers are similar to our own results in the local level model, though now the signal-to-noise ratio is no longer the crucial quantity, but rather some function of it that also depends on the distribution of the covariate and the autocorrelation parameter in some currently unknown way. \citeauthor{fruhwirth2004efficient} also find that none of the other DA algorithms they consider are more efficient than both the state sampler and the scaled disturbance sampler --- one of these always ends up being faster. This holds true both when they assume that the autorcorrelation parameter is known but when it is assumed unknown. This is encouraging since the extra complexity from adding a new parameter to the model (in our general DLM notation, this is in the form of $G_t$ depending on an additional unknown parameter) could drastically change the properties of the DA algorithms based on an AA (e.g. the scaled disturbances), but it appears the differences are relatively small.
